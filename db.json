{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"8ca07c6d7b4ff1dd8ab4f14fde521ea3ce4eb84a","modified":1551185328000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1544263526000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1544263526000},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1544263526000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1544263526000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1544263526000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1544263526000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1544263526000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1544263526000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1544263526000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1544263526000},{"_id":"themes/next/README.cn.md","hash":"58ffe752bc4b7f0069fcd6304bbc2d5ff7b80f89","modified":1544263526000},{"_id":"themes/next/README.md","hash":"898213e66d34a46c3cf8446bf693bd50db0d3269","modified":1544263526000},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1544263526000},{"_id":"themes/next/_config.yml","hash":"86cec1604a18bf1e79c59f1b74568a7ea69a8876","modified":1551866588000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1544263526000},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1544263526000},{"_id":"source/_posts/docker-introduces.md","hash":"1499579f0d3f70c3ec41c4828fcc4e51cab6396c","modified":1544265473000},{"_id":"source/_posts/etcd-backup.md","hash":"07bb8e8ddcfaac251a5b7fe3613044445de08dff","modified":1544265125000},{"_id":"source/_posts/k8s-audit-webhook.md","hash":"a5ea8f5a7299c010c2e46cc07d3557bf8f79b48e","modified":1548837015000},{"_id":"source/_posts/etcd-enable-https.md","hash":"b6d41d23d296a277615372f297f498e808fbf53f","modified":1544265218000},{"_id":"source/_posts/k8s-crontab.md","hash":"0d883567cac92795a73d88e54ba87608f5bae5be","modified":1550326610000},{"_id":"source/_posts/k8s_leader_election.md","hash":"689cec51488d3b0a06137f34baa8a2dd23a0b091","modified":1552434871000},{"_id":"source/_posts/k8s_metrics_server.md","hash":"247f3694017e47ff7b08724fa95c35998360bca2","modified":1555248656000},{"_id":"source/_posts/k8s_events.md","hash":"60b45270ab92599beb3613de8dbc023f90b45854","modified":1551191848000},{"_id":"source/_posts/k8s_v1.12.md","hash":"5aa00b0807a14ca1d52fba344ce7653b4292ba39","modified":1551775270000},{"_id":"source/_posts/kubeconfig.md","hash":"8dff92301fa78234d0a28bacb4a5fdac7ae746e6","modified":1547033504000},{"_id":"source/_posts/kubeadm.md","hash":"31a7c68204a348f17927bc649a6b2bbefbf0b647","modified":1547693212000},{"_id":"source/_posts/kubelet-modules.md","hash":"29d34b26a70044302f50d8251405ff92a43bd3eb","modified":1544953670000},{"_id":"source/_posts/kubelet_create_pod.md","hash":"f913ad3c691bd70ecaae8582684e15c8cfb7553d","modified":1546478106000},{"_id":"source/_posts/kubernetes-api.md","hash":"c491c2945893e1dd5865eda08bc7e5a91de85a70","modified":1544265321000},{"_id":"source/_posts/kubelet_init.md","hash":"9860aeea547d740d78962e99e4eb33f647a02f39","modified":1546325723000},{"_id":"source/_posts/kubernetes-learn.md","hash":"c834d1dea6ccbd81fbf9b23048b8fce2ad471d32","modified":1544264940000},{"_id":"source/about/index.md","hash":"7994a74983a24343c6b5991bcf80d81436fbcba8","modified":1551749830000},{"_id":"source/categories/index.md","hash":"812daa9e1c97a2c72ee357ad92f4de335db3c177","modified":1544263526000},{"_id":"source/tags/index.md","hash":"5118f5301c54915b86d4e92b56a2fa9a9395abfc","modified":1544263526000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1544263526000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1544263526000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"352093a1b210c72136687fd2eee649244cee402c","modified":1544263526000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1544263526000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1544263526000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1544263526000},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1544263526000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1544263526000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1544263526000},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1544263526000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1544263526000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1544263526000},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1544263526000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1544263526000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1544263526000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1544263526000},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1544263526000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1544263526000},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1544263526000},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1544263526000},{"_id":"themes/next/layout/_layout.swig","hash":"da0929166674ea637e0ad454f85ad0d7bac4aff2","modified":1544263526000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1544263526000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1544263526000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1544263526000},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1544263526000},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1544263526000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1544263526000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1544263526000},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1544263526000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1544263526000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1544263526000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1544263526000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1544263526000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1544263526000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1544263526000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1544263526000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1544263526000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1544263526000},{"_id":"themes/next/layout/_macro/post.swig","hash":"446a35a2cd389f8cfc3aa38973a9b44ad0740134","modified":1544263526000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1544263526000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1544263526000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1544263526000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"c4d6181f5d3db5365e622f78714af8cc58d7a45e","modified":1544263526000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1544263526000},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1544263526000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1544263526000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1544263526000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1544263526000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1544263526000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1544263526000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1544263526000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1544263526000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1544263526000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1544263526000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1544263526000},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1544263526000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1544263526000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1544263526000},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1544263526000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1544263526000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1544263526000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1544263526000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1544263526000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1544263526000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1544263526000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1544263526000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1544263526000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1544263526000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1544263526000},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1544263526000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1544263526000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1544263526000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1544263526000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1544263526000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1544263526000},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1544263526000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1544263526000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1544263526000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1544263526000},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1544263526000},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1544263526000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1544263526000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1544263526000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1544263526000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1544263526000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1544263526000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544263526000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1544263526000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1544263526000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1544263526000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1544263526000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1544263526000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1544263526000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1544263526000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1544263526000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1544263526000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1544263526000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1544263526000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1544263526000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1544263526000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1544263526000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1544263526000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1544263526000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1544263526000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1544263526000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1544263526000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1544263526000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1544263526000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1544263526000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1544263526000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1544263526000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1544263526000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1544263526000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1544263526000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1544263526000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1544263526000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1544263526000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1544263526000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1544263526000},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1544263526000},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1544263526000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1544263526000},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1544263526000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1544263526000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1544263526000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1544263526000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1544263526000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1544263526000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1544263526000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1544263526000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1544263526000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1544263526000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1544263526000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1544263526000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1544263526000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1544263526000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1544263526000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1544263526000},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1544263526000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1544263526000},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1544263526000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1544263526000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1544263526000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1544263526000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1544263526000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1544263526000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1544263526000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1544263526000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1544263526000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1544263526000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1544263526000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1544263526000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1544263526000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1544263526000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1544263526000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1544263526000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1544263526000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1544263526000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1544263526000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"02fb8fa6b6c252b6bed469539cd057716606a787","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1544263526000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1544263526000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1544263526000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1544263526000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1544263526000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1544263526000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1544263526000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1544263526000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1544263526000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1544263526000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1544263526000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1544263526000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1544263526000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1544263526000},{"_id":"public/search.xml","hash":"7327546e0ca1c692b576f986d20de2538ec04d3a","modified":1555944380886},{"_id":"public/about/index.html","hash":"69fc53622162d8c2efdf3e26b05c6df0d18de830","modified":1555944381083},{"_id":"public/categories/index.html","hash":"e5c2771220d1576e6981efafbe656e6c94ca740f","modified":1555944381083},{"_id":"public/tags/index.html","hash":"53c54ef5e29d4886f22a37d19f183709db4b3bc7","modified":1555944381084},{"_id":"public/2019/04/14/k8s_metrics_server/index.html","hash":"b90961b7a99d1479e7ce5052e215f3b3c9150077","modified":1555944381084},{"_id":"public/2019/03/13/k8s_leader_election/index.html","hash":"71f72a2a7374bdeb15a02c736d5210131e5308fa","modified":1555944381084},{"_id":"public/2019/03/05/k8s_v1.12/index.html","hash":"0dbf48478866ea4999f03d6fb4d8ac26d9081b0a","modified":1555944381084},{"_id":"public/2019/02/26/k8s_events/index.html","hash":"704d8218644a81a35b41137db8dba416ee102854","modified":1555944381084},{"_id":"public/2019/02/16/k8s-crontab/index.html","hash":"7c6e755cc792f3809cd1f8f0f13103678085c0c9","modified":1555944381085},{"_id":"public/2019/01/30/k8s-audit-webhook/index.html","hash":"e8cdbd224e0544daf6569e0335c5e3110eae6919","modified":1555944381085},{"_id":"public/2019/01/17/kubeadm/index.html","hash":"058f26b1e2f46c67e05537ee4850cee01d0beca0","modified":1555944381085},{"_id":"public/2019/01/09/kubeconfig/index.html","hash":"baf976a16cb0f5a059eb9d237841ee6f6ea77867","modified":1555944381085},{"_id":"public/2019/01/03/kubelet_create_pod/index.html","hash":"f958728d1df907aea3f34bfa9fe9a0818f822dbd","modified":1555944381085},{"_id":"public/2018/12/23/kubelet_init/index.html","hash":"65ae1039da96c50934d2593ed19424210682f976","modified":1555944381086},{"_id":"public/2018/12/16/kubelet-modules/index.html","hash":"01b5599f0b66fec649ae55f367e68c6d1650828b","modified":1555944381086},{"_id":"public/2018/12/05/docker-introduces/index.html","hash":"20568f57568f8aaf25464794e414be71cac3cd50","modified":1555944381086},{"_id":"public/2018/09/02/kubernetes-api/index.html","hash":"9b5b052a140fd71a410cf4d9f19de550fc91963c","modified":1555944381087},{"_id":"public/2017/03/15/etcd-enable-https/index.html","hash":"3e493f08461a6a8c142d2a199f42f228fb2aa730","modified":1555944381087},{"_id":"public/2017/03/02/etcd-backup/index.html","hash":"e46c7cfe56f1bb24fad2670f810a5d6e29e62fc3","modified":1555944381087},{"_id":"public/2017/02/12/kubernetes-learn/index.html","hash":"0b4c4fb8df66b8198acaf93866f1ccddaa1a7378","modified":1555944381087},{"_id":"public/archives/index.html","hash":"3b43d67af712643900d458d31ab961b385b34a1d","modified":1555944381087},{"_id":"public/archives/page/2/index.html","hash":"d2b5f28432343ce9c050925d0112c3542029ce57","modified":1555944381087},{"_id":"public/archives/2017/index.html","hash":"fbbe8e22895d1b3dd7f3371a1467461630219328","modified":1555944381088},{"_id":"public/archives/2017/02/index.html","hash":"24d561fe6dfca6fb7eb19778f99a0e7f667f8ae9","modified":1555944381088},{"_id":"public/archives/2017/03/index.html","hash":"b405535c236ddf243a84061eb63c5a736761aa4e","modified":1555944381088},{"_id":"public/archives/2018/index.html","hash":"64f6e5db8652928ffbf09079e867275588a07b52","modified":1555944381088},{"_id":"public/archives/2018/09/index.html","hash":"3ccf48fab2de290db548713da259ede92c517277","modified":1555944381088},{"_id":"public/archives/2018/12/index.html","hash":"5e885b703b7030cfcbc018e81d20306d616b2528","modified":1555944381088},{"_id":"public/archives/2019/index.html","hash":"76a4f37267b020916cffeaa188a7f5a05c6d9af3","modified":1555944381088},{"_id":"public/archives/2019/01/index.html","hash":"bbf50dfcb08d13db5f4f6f0ab0d385f2978ae3b5","modified":1555944381088},{"_id":"public/archives/2019/02/index.html","hash":"8dd4ac76f1e575bc40a3d360c331bead9e231283","modified":1555944381088},{"_id":"public/archives/2019/03/index.html","hash":"d57f06be490916d0e4fd55aceba960253b079fcb","modified":1555944381089},{"_id":"public/archives/2019/04/index.html","hash":"0df06f25ac68f071711396be5cbc48c32d867517","modified":1555944381089},{"_id":"public/index.html","hash":"41a18442cf8de7fc12738807c14dd0399ddba63c","modified":1555944381089},{"_id":"public/page/2/index.html","hash":"b1f444f39f8c9bc95c0ee12f28684acb6cdb5994","modified":1555944381089},{"_id":"public/tags/crontab/index.html","hash":"702e0ea5284aef1fcb060ae4901babf573f908cf","modified":1555944381089},{"_id":"public/tags/wait/index.html","hash":"82f82fca6dde7b79853318fd52e63af8fea0d46d","modified":1555944381089},{"_id":"public/tags/k8s/index.html","hash":"a8b82f104aefd66dd5470421c960fc6e9316c8ee","modified":1555944381089},{"_id":"public/tags/metrics-server/index.html","hash":"6171e3a6d95df8d4334313396e7b1010f87e8c37","modified":1555944381089},{"_id":"public/tags/kubernetes-v1-12/index.html","hash":"514260eee1cb6ce65d95ccb0223cefd7d1959cfb","modified":1555944381089},{"_id":"public/tags/kubeconfig/index.html","hash":"2cacbd4a92e8a17bda06848d9fdf30db0e402a64","modified":1555944381089},{"_id":"public/tags/audit/index.html","hash":"c0f25a0de2f4c7dd8d809e4d2c7f994f8d6ac0e6","modified":1555944381089},{"_id":"public/tags/log/index.html","hash":"f18b8c8ba2ed041099d8f34af1e6942056601d3c","modified":1555944381090},{"_id":"public/tags/kubeadm/index.html","hash":"3667fa548ad6bbdd28da260d02b431660834830c","modified":1555944381090},{"_id":"public/tags/kubelet/index.html","hash":"6e19a3862d2db2ebefcbcbac74fe36cb7cb5cd12","modified":1555944381090},{"_id":"public/tags/leader-election/index.html","hash":"7d58ba5aaa4b7327d0c778003d8a311cb9b06501","modified":1555944381090},{"_id":"public/tags/component/index.html","hash":"59fa8ed6eebc7b5caaea2f0f204126de65bd1a52","modified":1555944381090},{"_id":"public/tags/events/index.html","hash":"f3a9ab314fa839508ced64e462f774f0e231b4d1","modified":1555944381090},{"_id":"source/_posts/k8s_dashboard_prometheus.md","hash":"6ff65831c4edc87dbf94926b24555ff3ff838937","modified":1555944284000},{"_id":"public/2019/04/22/k8s_dashboard_prometheus/index.html","hash":"78fb35327e8190f7d8bfb0f4d9031071c9b92af1","modified":1555944381093},{"_id":"public/tags/kube-dashboard/index.html","hash":"1e36f160136620babeba3fe915dba21c2f6d4cfd","modified":1555944381093},{"_id":"public/tags/prometheus/index.html","hash":"6d611226d03c95146c73cd9348060381319f319c","modified":1555944381093}],"Category":[],"Data":[],"Page":[{"title":"About","date":"2018-12-08T08:46:18.000Z","_content":"\n###   KubernetesDockerIstio \n\n<!--\n\n![kubeCon.jpg](https://upload-images.jianshu.io/upload_images/1262158-92e245b5b1b41335.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/600) -->\n","source":"about/index.md","raw":"---\ntitle: About\ndate: 2018-12-08 16:46:18\n---\n\n###   KubernetesDockerIstio \n\n<!--\n\n![kubeCon.jpg](https://upload-images.jianshu.io/upload_images/1262158-92e245b5b1b41335.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/600) -->\n","updated":"2019-03-05T01:37:10.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjugyyss20001tadv9iplllqm","content":"<h3 id=\"-KubernetesDockerIstio-\"><a href=\"#-KubernetesDockerIstio-\" class=\"headerlink\" title=\" KubernetesDockerIstio \"></a> KubernetesDockerIstio </h3><!--\n\n![kubeCon.jpg](https://upload-images.jianshu.io/upload_images/1262158-92e245b5b1b41335.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/600) -->\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"-KubernetesDockerIstio-\"><a href=\"#-KubernetesDockerIstio-\" class=\"headerlink\" title=\" KubernetesDockerIstio \"></a> KubernetesDockerIstio </h3><!--\n\n![kubeCon.jpg](https://upload-images.jianshu.io/upload_images/1262158-92e245b5b1b41335.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/600) -->\n"},{"title":"categories","date":"2018-12-08T08:52:49.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-12-08 16:52:49\n---\n","updated":"2018-12-08T10:05:26.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjugyyss50003tadvdwpzhvsl","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-12-08T08:46:27.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-12-08 16:46:27\n---\n","updated":"2018-12-08T10:05:26.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjugyyss70005tadv2em675sp","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Docker ","date":"2018-12-05T12:57:00.000Z","type":"docker","_content":"\n\n## Docker \n\n2015  6  docker  libcontainer  runC  runC  OCI\n\n2016  4 docker 1.11  containerd  runCDocker  containerd  runC containerd  OCI  OCI  containerd \n\n 2017 Docker  Docker Containerd CNCF Docker  Docker  Moby\n\n\n## Docker \n\n![docker ](https://upload-images.jianshu.io/upload_images/1262158-eee83eb356fccdb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n![docker ](https://upload-images.jianshu.io/upload_images/1262158-3f74443f956fa132.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### \n\ndocker 1.13 \n```\n$ docker --version\nDocker version 1.13.1, build 092cba3\n\n$ docker\ndocker             docker-containerd-ctr   dockerd      docker-proxy\ndocker-containerd  docker-containerd-shim  docker-init  docker-runc\n```\n\n#### 1docker \ndocker  docker daemon \n\n#### 2dockerd \ndockerd  docker  docker daemondockerd  containerd  api rpc ,docker daemon \n\n-  docker client \n-  docker \n\n containerd dockerd  dockerd \n\n#### 3containerd\n\ncontainerd  dockerd  runc docker  containerd containerd \n- \n- \n- \n- \n- \n\n#### 4containerd-shim\n\ncontainerd-shim containerd-shim idboundlecontainerd /var/run/docker/libcontainerd/containerIDrunC runc  api  docker \n\n- ( runC)(runC)\n-  containerd  dockerd  IO \n-  containerd \n\n dockerd\n\n#### 5runC\nrunC  Docker  OCI  libcontainer runC  libcontainer  OCI\n\n runC  busybox :\n```\n# mkdir /container\n# cd /container/\n# mkdir rootfs\n\n, busybox \n# docker export $(docker create busybox) | tar -C rootfs -xvf -    \n# ls rootfs/\nbin  dev  etc  home  proc  root  sys  tmp  usr  var\n\nrootfs OCI  config.json \nrunc \n# docker-runc spec\n# ls\nconfig.json  rootfs\n# docker-runc run simplebusybox    #\n/ # ls\nbin   dev   etc   home  proc  root  sys   tmp   usr   var\n/ # hostname\nrunc\n```\n---\n\n[Use of containerd-shim in docker-architecture](https://groups.google.com/forum/#!topic/docker-dev/zaZFlvIx1_k)\n[ docker  runC](https://www.cnblogs.com/sparkdev/p/9129334.html)\n[OCI  runc docker](http://cizixs.com/2017/11/05/oci-and-runc/)\n[Open Container Initiative](https://github.com/opencontainers)\n","source":"_posts/docker-introduces.md","raw":"---\ntitle: Docker \ndate: 2018-12-05 20:57:00\ntype: \"docker\"\n\n---\n\n\n## Docker \n\n2015  6  docker  libcontainer  runC  runC  OCI\n\n2016  4 docker 1.11  containerd  runCDocker  containerd  runC containerd  OCI  OCI  containerd \n\n 2017 Docker  Docker Containerd CNCF Docker  Docker  Moby\n\n\n## Docker \n\n![docker ](https://upload-images.jianshu.io/upload_images/1262158-eee83eb356fccdb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n![docker ](https://upload-images.jianshu.io/upload_images/1262158-3f74443f956fa132.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### \n\ndocker 1.13 \n```\n$ docker --version\nDocker version 1.13.1, build 092cba3\n\n$ docker\ndocker             docker-containerd-ctr   dockerd      docker-proxy\ndocker-containerd  docker-containerd-shim  docker-init  docker-runc\n```\n\n#### 1docker \ndocker  docker daemon \n\n#### 2dockerd \ndockerd  docker  docker daemondockerd  containerd  api rpc ,docker daemon \n\n-  docker client \n-  docker \n\n containerd dockerd  dockerd \n\n#### 3containerd\n\ncontainerd  dockerd  runc docker  containerd containerd \n- \n- \n- \n- \n- \n\n#### 4containerd-shim\n\ncontainerd-shim containerd-shim idboundlecontainerd /var/run/docker/libcontainerd/containerIDrunC runc  api  docker \n\n- ( runC)(runC)\n-  containerd  dockerd  IO \n-  containerd \n\n dockerd\n\n#### 5runC\nrunC  Docker  OCI  libcontainer runC  libcontainer  OCI\n\n runC  busybox :\n```\n# mkdir /container\n# cd /container/\n# mkdir rootfs\n\n, busybox \n# docker export $(docker create busybox) | tar -C rootfs -xvf -    \n# ls rootfs/\nbin  dev  etc  home  proc  root  sys  tmp  usr  var\n\nrootfs OCI  config.json \nrunc \n# docker-runc spec\n# ls\nconfig.json  rootfs\n# docker-runc run simplebusybox    #\n/ # ls\nbin   dev   etc   home  proc  root  sys   tmp   usr   var\n/ # hostname\nrunc\n```\n---\n\n[Use of containerd-shim in docker-architecture](https://groups.google.com/forum/#!topic/docker-dev/zaZFlvIx1_k)\n[ docker  runC](https://www.cnblogs.com/sparkdev/p/9129334.html)\n[OCI  runc docker](http://cizixs.com/2017/11/05/oci-and-runc/)\n[Open Container Initiative](https://github.com/opencontainers)\n","slug":"docker-introduces","published":1,"updated":"2018-12-08T10:37:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyysry0000tadvikguzccv","content":"<h2 id=\"Docker-\"><a href=\"#Docker-\" class=\"headerlink\" title=\"Docker \"></a>Docker </h2><p>2015  6  docker  libcontainer  runC  runC  OCI</p>\n<p>2016  4 docker 1.11  containerd  runCDocker  containerd  runC containerd  OCI  OCI  containerd </p>\n<p> 2017 Docker  Docker Containerd CNCF Docker  Docker  Moby</p>\n<h2 id=\"Docker-\"><a href=\"#Docker-\" class=\"headerlink\" title=\"Docker \"></a>Docker </h2><p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-eee83eb356fccdb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"docker \"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-3f74443f956fa132.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"docker \"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>docker 1.13 <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker --version</span><br><span class=\"line\">Docker version 1.13.1, build 092cba3</span><br><span class=\"line\"></span><br><span class=\"line\">$ docker</span><br><span class=\"line\">docker             docker-containerd-ctr   dockerd      docker-proxy</span><br><span class=\"line\">docker-containerd  docker-containerd-shim  docker-init  docker-runc</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"1docker\"><a href=\"#1docker\" class=\"headerlink\" title=\"1docker\"></a>1docker</h4><p>docker  docker daemon </p>\n<h4 id=\"2dockerd\"><a href=\"#2dockerd\" class=\"headerlink\" title=\"2dockerd\"></a>2dockerd</h4><p>dockerd  docker  docker daemondockerd  containerd  api rpc ,docker daemon </p>\n<ul>\n<li> docker client </li>\n<li> docker </li>\n</ul>\n<p> containerd dockerd  dockerd </p>\n<h4 id=\"3containerd\"><a href=\"#3containerd\" class=\"headerlink\" title=\"3containerd\"></a>3containerd</h4><p>containerd  dockerd  runc docker  containerd containerd </p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h4 id=\"4containerd-shim\"><a href=\"#4containerd-shim\" class=\"headerlink\" title=\"4containerd-shim\"></a>4containerd-shim</h4><p>containerd-shim containerd-shim idboundlecontainerd /var/run/docker/libcontainerd/containerIDrunC runc  api  docker </p>\n<ul>\n<li>( runC)(runC)</li>\n<li> containerd  dockerd  IO </li>\n<li> containerd </li>\n</ul>\n<p> dockerd</p>\n<h4 id=\"5runC\"><a href=\"#5runC\" class=\"headerlink\" title=\"5runC\"></a>5runC</h4><p>runC  Docker  OCI  libcontainer runC  libcontainer  OCI</p>\n<p> runC  busybox :<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># mkdir /container</span><br><span class=\"line\"># cd /container/</span><br><span class=\"line\"># mkdir rootfs</span><br><span class=\"line\"></span><br><span class=\"line\">, busybox </span><br><span class=\"line\"># docker export $(docker create busybox) | tar -C rootfs -xvf -    </span><br><span class=\"line\"># ls rootfs/</span><br><span class=\"line\">bin  dev  etc  home  proc  root  sys  tmp  usr  var</span><br><span class=\"line\"></span><br><span class=\"line\">rootfs OCI  config.json </span><br><span class=\"line\">runc </span><br><span class=\"line\"># docker-runc spec</span><br><span class=\"line\"># ls</span><br><span class=\"line\">config.json  rootfs</span><br><span class=\"line\"># docker-runc run simplebusybox    #</span><br><span class=\"line\">/ # ls</span><br><span class=\"line\">bin   dev   etc   home  proc  root  sys   tmp   usr   var</span><br><span class=\"line\">/ # hostname</span><br><span class=\"line\">runc</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p><br><a href=\"https://groups.google.com/forum/#!topic/docker-dev/zaZFlvIx1_k\" target=\"_blank\" rel=\"noopener\">Use of containerd-shim in docker-architecture</a><br><a href=\"https://www.cnblogs.com/sparkdev/p/9129334.html\" target=\"_blank\" rel=\"noopener\"> docker  runC</a><br><a href=\"http://cizixs.com/2017/11/05/oci-and-runc/\" target=\"_blank\" rel=\"noopener\">OCI  runc docker</a><br><a href=\"https://github.com/opencontainers\" target=\"_blank\" rel=\"noopener\">Open Container Initiative</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Docker-\"><a href=\"#Docker-\" class=\"headerlink\" title=\"Docker \"></a>Docker </h2><p>2015  6  docker  libcontainer  runC  runC  OCI</p>\n<p>2016  4 docker 1.11  containerd  runCDocker  containerd  runC containerd  OCI  OCI  containerd </p>\n<p> 2017 Docker  Docker Containerd CNCF Docker  Docker  Moby</p>\n<h2 id=\"Docker-\"><a href=\"#Docker-\" class=\"headerlink\" title=\"Docker \"></a>Docker </h2><p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-eee83eb356fccdb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"docker \"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-3f74443f956fa132.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"docker \"></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>docker 1.13 <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ docker --version</span><br><span class=\"line\">Docker version 1.13.1, build 092cba3</span><br><span class=\"line\"></span><br><span class=\"line\">$ docker</span><br><span class=\"line\">docker             docker-containerd-ctr   dockerd      docker-proxy</span><br><span class=\"line\">docker-containerd  docker-containerd-shim  docker-init  docker-runc</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"1docker\"><a href=\"#1docker\" class=\"headerlink\" title=\"1docker\"></a>1docker</h4><p>docker  docker daemon </p>\n<h4 id=\"2dockerd\"><a href=\"#2dockerd\" class=\"headerlink\" title=\"2dockerd\"></a>2dockerd</h4><p>dockerd  docker  docker daemondockerd  containerd  api rpc ,docker daemon </p>\n<ul>\n<li> docker client </li>\n<li> docker </li>\n</ul>\n<p> containerd dockerd  dockerd </p>\n<h4 id=\"3containerd\"><a href=\"#3containerd\" class=\"headerlink\" title=\"3containerd\"></a>3containerd</h4><p>containerd  dockerd  runc docker  containerd containerd </p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h4 id=\"4containerd-shim\"><a href=\"#4containerd-shim\" class=\"headerlink\" title=\"4containerd-shim\"></a>4containerd-shim</h4><p>containerd-shim containerd-shim idboundlecontainerd /var/run/docker/libcontainerd/containerIDrunC runc  api  docker </p>\n<ul>\n<li>( runC)(runC)</li>\n<li> containerd  dockerd  IO </li>\n<li> containerd </li>\n</ul>\n<p> dockerd</p>\n<h4 id=\"5runC\"><a href=\"#5runC\" class=\"headerlink\" title=\"5runC\"></a>5runC</h4><p>runC  Docker  OCI  libcontainer runC  libcontainer  OCI</p>\n<p> runC  busybox :<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># mkdir /container</span><br><span class=\"line\"># cd /container/</span><br><span class=\"line\"># mkdir rootfs</span><br><span class=\"line\"></span><br><span class=\"line\">, busybox </span><br><span class=\"line\"># docker export $(docker create busybox) | tar -C rootfs -xvf -    </span><br><span class=\"line\"># ls rootfs/</span><br><span class=\"line\">bin  dev  etc  home  proc  root  sys  tmp  usr  var</span><br><span class=\"line\"></span><br><span class=\"line\">rootfs OCI  config.json </span><br><span class=\"line\">runc </span><br><span class=\"line\"># docker-runc spec</span><br><span class=\"line\"># ls</span><br><span class=\"line\">config.json  rootfs</span><br><span class=\"line\"># docker-runc run simplebusybox    #</span><br><span class=\"line\">/ # ls</span><br><span class=\"line\">bin   dev   etc   home  proc  root  sys   tmp   usr   var</span><br><span class=\"line\">/ # hostname</span><br><span class=\"line\">runc</span><br></pre></td></tr></table></figure></p>\n<hr>\n<p><br><a href=\"https://groups.google.com/forum/#!topic/docker-dev/zaZFlvIx1_k\" target=\"_blank\" rel=\"noopener\">Use of containerd-shim in docker-architecture</a><br><a href=\"https://www.cnblogs.com/sparkdev/p/9129334.html\" target=\"_blank\" rel=\"noopener\"> docker  runC</a><br><a href=\"http://cizixs.com/2017/11/05/oci-and-runc/\" target=\"_blank\" rel=\"noopener\">OCI  runc docker</a><br><a href=\"https://github.com/opencontainers\" target=\"_blank\" rel=\"noopener\">Open Container Initiative</a></p>\n"},{"title":"etcd ","date":"2017-03-02T10:04:00.000Z","type":"etcd","_content":"\n**[etcd](https://github.com/coreos/etcd)** , CoreOS \n\netcd  v3.1.1 API  v3  v2  v3  v2  API  etcd 2.3  v3  API v2  v3 API \n\n    # etcdctl --version\n    etcdctl version: 3.0.4\n    API version: 2\n\n\n etcd v2  v3 [support backup of v2 and v3 stores](https://github.com/coreos/etcd/issues/7002) \n\n\n** v3  v2 \n v2  v3 **\n\n###  API 2    \n[ v2 admin guide](https://github.com/coreos/etcd/blob/master/Documentation/v2/admin_guide.md#disaster-recovery)\n\n\netcd\n* snap: ,etcdWALetcd\n\n* wal: ,etcdWAL\n\n\n    # etcdctl backup --data-dir /home/etcd/ --backup-dir /home/etcd_backup\n\n    # etcd -data-dir=/home/etcd_backup/  -force-new-cluster\n\n\n snapshot (member ID  cluster ID)\n\n###  API 3   \n[ v3 admin guide](https://github.com/coreos/etcd/blob/master/Documentation/op-guide/recovery.md)\n\n API 3  ETCDCTL_API \n\n\n\n\t# export ETCDCTL_API=3\n\t\n\n\n\t# etcdctl --endpoints localhost:2379 snapshot save snapshot.db\n\n\n\n\t# etcdctl snapshot restore snapshot.db --name m3 --data-dir=/home/etcd_data\n\n>  etcd:etcd\n> --name: default.etcd\n> --data-dir\n>  name  data-dir data-dir  etcd  data-dir\n\netcd  3  (N-1)/2 gitlab  \n\n[](https://skyao.gitbooks.io/leaning-etcd3/content/documentation/op-guide/recovery.html)\n","source":"_posts/etcd-backup.md","raw":"---\ntitle: etcd \ndate: 2017-03-02 18:04:00\ntype: \"etcd\"\n\n---\n\n**[etcd](https://github.com/coreos/etcd)** , CoreOS \n\netcd  v3.1.1 API  v3  v2  v3  v2  API  etcd 2.3  v3  API v2  v3 API \n\n    # etcdctl --version\n    etcdctl version: 3.0.4\n    API version: 2\n\n\n etcd v2  v3 [support backup of v2 and v3 stores](https://github.com/coreos/etcd/issues/7002) \n\n\n** v3  v2 \n v2  v3 **\n\n###  API 2    \n[ v2 admin guide](https://github.com/coreos/etcd/blob/master/Documentation/v2/admin_guide.md#disaster-recovery)\n\n\netcd\n* snap: ,etcdWALetcd\n\n* wal: ,etcdWAL\n\n\n    # etcdctl backup --data-dir /home/etcd/ --backup-dir /home/etcd_backup\n\n    # etcd -data-dir=/home/etcd_backup/  -force-new-cluster\n\n\n snapshot (member ID  cluster ID)\n\n###  API 3   \n[ v3 admin guide](https://github.com/coreos/etcd/blob/master/Documentation/op-guide/recovery.md)\n\n API 3  ETCDCTL_API \n\n\n\n\t# export ETCDCTL_API=3\n\t\n\n\n\t# etcdctl --endpoints localhost:2379 snapshot save snapshot.db\n\n\n\n\t# etcdctl snapshot restore snapshot.db --name m3 --data-dir=/home/etcd_data\n\n>  etcd:etcd\n> --name: default.etcd\n> --data-dir\n>  name  data-dir data-dir  etcd  data-dir\n\netcd  3  (N-1)/2 gitlab  \n\n[](https://skyao.gitbooks.io/leaning-etcd3/content/documentation/op-guide/recovery.html)\n","slug":"etcd-backup","published":1,"updated":"2018-12-08T10:32:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyss30002tadvuohmsnu7","content":"<p><strong><a href=\"https://github.com/coreos/etcd\" target=\"_blank\" rel=\"noopener\">etcd</a></strong> , CoreOS </p>\n<p>etcd  v3.1.1 API  v3  v2  v3  v2  API  etcd 2.3  v3  API v2  v3 API </p>\n<pre><code># etcdctl --version\netcdctl version: 3.0.4\nAPI version: 2\n</code></pre><p> etcd v2  v3 <a href=\"https://github.com/coreos/etcd/issues/7002\" target=\"_blank\" rel=\"noopener\">support backup of v2 and v3 stores</a> </p>\n<p><strong> v3  v2 <br> v2  v3 </strong></p>\n<h3 id=\"-API-2-\"><a href=\"#-API-2-\" class=\"headerlink\" title=\" API 2 \"></a> API 2 </h3><p><a href=\"https://github.com/coreos/etcd/blob/master/Documentation/v2/admin_guide.md#disaster-recovery\" target=\"_blank\" rel=\"noopener\"> v2 admin guide</a></p>\n<p>etcd</p>\n<ul>\n<li><p>snap: ,etcdWALetcd</p>\n</li>\n<li><p>wal: ,etcdWAL</p>\n</li>\n</ul>\n<pre><code># etcdctl backup --data-dir /home/etcd/ --backup-dir /home/etcd_backup\n\n# etcd -data-dir=/home/etcd_backup/  -force-new-cluster\n</code></pre><p> snapshot (member ID  cluster ID)</p>\n<h3 id=\"-API-3-\"><a href=\"#-API-3-\" class=\"headerlink\" title=\" API 3 \"></a> API 3 </h3><p><a href=\"https://github.com/coreos/etcd/blob/master/Documentation/op-guide/recovery.md\" target=\"_blank\" rel=\"noopener\"> v3 admin guide</a></p>\n<p> API 3  ETCDCTL_API </p>\n<p></p>\n<pre><code># export ETCDCTL_API=3\n</code></pre><p></p>\n<pre><code># etcdctl --endpoints localhost:2379 snapshot save snapshot.db\n</code></pre><p></p>\n<pre><code># etcdctl snapshot restore snapshot.db --name m3 --data-dir=/home/etcd_data\n</code></pre><blockquote>\n<p> etcd:etcd<br>name: default.etcd<br>data-dir<br> name  data-dir data-dir  etcd  data-dir</p>\n</blockquote>\n<p>etcd  3  (N-1)/2 gitlab  </p>\n<p><a href=\"https://skyao.gitbooks.io/leaning-etcd3/content/documentation/op-guide/recovery.html\" target=\"_blank\" rel=\"noopener\"></a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong><a href=\"https://github.com/coreos/etcd\" target=\"_blank\" rel=\"noopener\">etcd</a></strong> , CoreOS </p>\n<p>etcd  v3.1.1 API  v3  v2  v3  v2  API  etcd 2.3  v3  API v2  v3 API </p>\n<pre><code># etcdctl --version\netcdctl version: 3.0.4\nAPI version: 2\n</code></pre><p> etcd v2  v3 <a href=\"https://github.com/coreos/etcd/issues/7002\" target=\"_blank\" rel=\"noopener\">support backup of v2 and v3 stores</a> </p>\n<p><strong> v3  v2 <br> v2  v3 </strong></p>\n<h3 id=\"-API-2-\"><a href=\"#-API-2-\" class=\"headerlink\" title=\" API 2 \"></a> API 2 </h3><p><a href=\"https://github.com/coreos/etcd/blob/master/Documentation/v2/admin_guide.md#disaster-recovery\" target=\"_blank\" rel=\"noopener\"> v2 admin guide</a></p>\n<p>etcd</p>\n<ul>\n<li><p>snap: ,etcdWALetcd</p>\n</li>\n<li><p>wal: ,etcdWAL</p>\n</li>\n</ul>\n<pre><code># etcdctl backup --data-dir /home/etcd/ --backup-dir /home/etcd_backup\n\n# etcd -data-dir=/home/etcd_backup/  -force-new-cluster\n</code></pre><p> snapshot (member ID  cluster ID)</p>\n<h3 id=\"-API-3-\"><a href=\"#-API-3-\" class=\"headerlink\" title=\" API 3 \"></a> API 3 </h3><p><a href=\"https://github.com/coreos/etcd/blob/master/Documentation/op-guide/recovery.md\" target=\"_blank\" rel=\"noopener\"> v3 admin guide</a></p>\n<p> API 3  ETCDCTL_API </p>\n<p></p>\n<pre><code># export ETCDCTL_API=3\n</code></pre><p></p>\n<pre><code># etcdctl --endpoints localhost:2379 snapshot save snapshot.db\n</code></pre><p></p>\n<pre><code># etcdctl snapshot restore snapshot.db --name m3 --data-dir=/home/etcd_data\n</code></pre><blockquote>\n<p> etcd:etcd<br>name: default.etcd<br>data-dir<br> name  data-dir data-dir  etcd  data-dir</p>\n</blockquote>\n<p>etcd  3  (N-1)/2 gitlab  </p>\n<p><a href=\"https://skyao.gitbooks.io/leaning-etcd3/content/documentation/op-guide/recovery.html\" target=\"_blank\" rel=\"noopener\"></a></p>\n"},{"title":"k8s ","date":"2019-02-16T13:59:30.000Z","type":"wait","_content":"k8s  k8s k8s  wait wait  k8s  wait  kubelet \n\n\n```\t\t\nfunc run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh <-chan struct{}) (err error) {\n\t\t...\n\t\t// kubelet 5 apiserver \n\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t\n\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t...\n}\n\n...\n\nfunc startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration,   kubeDeps *kubelet.Dependencies, enableServer bool) {\n    //  pod \n    go wait.Until(func() {\n        k.Run(podCfg.Updates())\n    }, 0, wait.NeverStop)\n    ...\n}\n```\n\ngolang  time.Ticker  k8s  time.Timer time.Ticker  time.Timer \n\n- ticker \n- timer \n-  timer  ticker  `func (t *Timer) Reset(d Duration) bool`\n \n\n\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\n\ttimer1 := time.NewTimer(2 * time.Second)\n\tticker1 := time.NewTicker(2 * time.Second)\n\n\twg.Add(1)\n\tgo func(t *time.Ticker) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\t<-t.C\n\t\t\tfmt.Println(\"exec ticker\", time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\t}\n\t}(ticker1)\n\n\twg.Add(1)\n\tgo func(t *time.Timer) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\t<-t.C\n\t\t\tfmt.Println(\"exec timer\", time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\t\tt.Reset(2 * time.Second)\n\t\t}\n\t}(timer1)\n\t\n\twg.Wait()\n}\n\n```\n\n### wait \n\n\nk8s.io/apimachinery/pkg/util/wait/wait.go\n\n\n```\nfunc JitterUntil(f func(), period time.Duration, jitterFactor float64, sliding bool, stopCh <-chan struct{}) {\n\tvar t *time.Timer\n\tvar sawTimeout bool\n\n\tfor {\n\t\tselect {\n\t\tcase <-stopCh:\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\tjitteredPeriod := period\n\t\tif jitterFactor > 0.0 {\n\t\t\tjitteredPeriod = Jitter(period, jitterFactor)\n\t\t}\n\n\t\tif !sliding {\n\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)\n\t\t}\n\n\t\tfunc() {\n\t\t\tdefer runtime.HandleCrash()\n\t\t\tf()\n\t\t}()\n\n\t\tif sliding {\n\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)\n\t\t}\n\n\t\tselect {\n\t\tcase <-stopCh:\n\t\t\treturn\n\t\tcase <-t.C:\n\t\t\tsawTimeout = true\n\t\t}\n\t}\n}\n\n...\n\nfunc resetOrReuseTimer(t *time.Timer, d time.Duration, sawTimeout bool) *time.Timer {\n    if t == nil {\n        return time.NewTimer(d)\n    }\n    if !t.Stop() && !sawTimeout {\n        <-t.C\n    }\n    t.Reset(d)\n    return t\n}\n```\n\n\n\n- 1 sliding  true f()  false period  f() \n- 2 golang  select  f(), stopCh chan\n\nk8s  wait  time.Timer \n\n### wait \n\n##### 1 Forever \n\nfunc Forever(f func(), period time.Duration)\n\n##### 2 chan \n\nfunc Until(f func(), period time.Duration, stopCh <-chan struct{})\n\n stopCh  close  chan \n\n##### 3 Poll \n\nfunc Poll(interval, timeout time.Duration, condition ConditionFunc)\n\n interval  condition  timeout \n\n##### 4PollUntil  timeout  stopCh \n\nPollUntil(interval time.Duration, condition ConditionFunc, stopCh <-chan struct{}) error\n\n PollImmediate  PollInfinite  PollImmediateInfinite \n\n### \n\n k8s wait k8s  k8s \n\n","source":"_posts/k8s-crontab.md","raw":"---\ntitle: k8s \ndate: 2019-02-16 21:59:30\ntags: [\"crontab\",\"wait\",\"k8s\"]\ntype: \"wait\"\n\n---\nk8s  k8s k8s  wait wait  k8s  wait  kubelet \n\n\n```\t\t\nfunc run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh <-chan struct{}) (err error) {\n\t\t...\n\t\t// kubelet 5 apiserver \n\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t\n\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t...\n}\n\n...\n\nfunc startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration,   kubeDeps *kubelet.Dependencies, enableServer bool) {\n    //  pod \n    go wait.Until(func() {\n        k.Run(podCfg.Updates())\n    }, 0, wait.NeverStop)\n    ...\n}\n```\n\ngolang  time.Ticker  k8s  time.Timer time.Ticker  time.Timer \n\n- ticker \n- timer \n-  timer  ticker  `func (t *Timer) Reset(d Duration) bool`\n \n\n\n\n```\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\n\ttimer1 := time.NewTimer(2 * time.Second)\n\tticker1 := time.NewTicker(2 * time.Second)\n\n\twg.Add(1)\n\tgo func(t *time.Ticker) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\t<-t.C\n\t\t\tfmt.Println(\"exec ticker\", time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\t}\n\t}(ticker1)\n\n\twg.Add(1)\n\tgo func(t *time.Timer) {\n\t\tdefer wg.Done()\n\t\tfor {\n\t\t\t<-t.C\n\t\t\tfmt.Println(\"exec timer\", time.Now().Format(\"2006-01-02 15:04:05\"))\n\t\t\tt.Reset(2 * time.Second)\n\t\t}\n\t}(timer1)\n\t\n\twg.Wait()\n}\n\n```\n\n### wait \n\n\nk8s.io/apimachinery/pkg/util/wait/wait.go\n\n\n```\nfunc JitterUntil(f func(), period time.Duration, jitterFactor float64, sliding bool, stopCh <-chan struct{}) {\n\tvar t *time.Timer\n\tvar sawTimeout bool\n\n\tfor {\n\t\tselect {\n\t\tcase <-stopCh:\n\t\t\treturn\n\t\tdefault:\n\t\t}\n\n\t\tjitteredPeriod := period\n\t\tif jitterFactor > 0.0 {\n\t\t\tjitteredPeriod = Jitter(period, jitterFactor)\n\t\t}\n\n\t\tif !sliding {\n\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)\n\t\t}\n\n\t\tfunc() {\n\t\t\tdefer runtime.HandleCrash()\n\t\t\tf()\n\t\t}()\n\n\t\tif sliding {\n\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)\n\t\t}\n\n\t\tselect {\n\t\tcase <-stopCh:\n\t\t\treturn\n\t\tcase <-t.C:\n\t\t\tsawTimeout = true\n\t\t}\n\t}\n}\n\n...\n\nfunc resetOrReuseTimer(t *time.Timer, d time.Duration, sawTimeout bool) *time.Timer {\n    if t == nil {\n        return time.NewTimer(d)\n    }\n    if !t.Stop() && !sawTimeout {\n        <-t.C\n    }\n    t.Reset(d)\n    return t\n}\n```\n\n\n\n- 1 sliding  true f()  false period  f() \n- 2 golang  select  f(), stopCh chan\n\nk8s  wait  time.Timer \n\n### wait \n\n##### 1 Forever \n\nfunc Forever(f func(), period time.Duration)\n\n##### 2 chan \n\nfunc Until(f func(), period time.Duration, stopCh <-chan struct{})\n\n stopCh  close  chan \n\n##### 3 Poll \n\nfunc Poll(interval, timeout time.Duration, condition ConditionFunc)\n\n interval  condition  timeout \n\n##### 4PollUntil  timeout  stopCh \n\nPollUntil(interval time.Duration, condition ConditionFunc, stopCh <-chan struct{}) error\n\n PollImmediate  PollInfinite  PollImmediateInfinite \n\n### \n\n k8s wait k8s  k8s \n\n","slug":"k8s-crontab","published":1,"updated":"2019-02-16T14:16:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyss60004tadv88lq8wq6","content":"<p>k8s  k8s k8s  wait wait  k8s  wait  kubelet </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh &lt;-chan struct&#123;&#125;) (err error) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t// kubelet 5 apiserver </span><br><span class=\"line\">\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">func startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration,   kubeDeps *kubelet.Dependencies, enableServer bool) &#123;</span><br><span class=\"line\">    //  pod </span><br><span class=\"line\">    go wait.Until(func() &#123;</span><br><span class=\"line\">        k.Run(podCfg.Updates())</span><br><span class=\"line\">    &#125;, 0, wait.NeverStop)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>golang  time.Ticker  k8s  time.Timer time.Ticker  time.Timer </p>\n<ul>\n<li>ticker </li>\n<li>timer </li>\n<li> timer  ticker  <code>func (t *Timer) Reset(d Duration) bool</code></li>\n</ul>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;sync&quot;</span><br><span class=\"line\">\t&quot;time&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tvar wg sync.WaitGroup</span><br><span class=\"line\"></span><br><span class=\"line\">\ttimer1 := time.NewTimer(2 * time.Second)</span><br><span class=\"line\">\tticker1 := time.NewTicker(2 * time.Second)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(1)</span><br><span class=\"line\">\tgo func(t *time.Ticker) &#123;</span><br><span class=\"line\">\t\tdefer wg.Done()</span><br><span class=\"line\">\t\tfor &#123;</span><br><span class=\"line\">\t\t\t&lt;-t.C</span><br><span class=\"line\">\t\t\tfmt.Println(&quot;exec ticker&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;))</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;(ticker1)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(1)</span><br><span class=\"line\">\tgo func(t *time.Timer) &#123;</span><br><span class=\"line\">\t\tdefer wg.Done()</span><br><span class=\"line\">\t\tfor &#123;</span><br><span class=\"line\">\t\t\t&lt;-t.C</span><br><span class=\"line\">\t\t\tfmt.Println(&quot;exec timer&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;))</span><br><span class=\"line\">\t\t\tt.Reset(2 * time.Second)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;(timer1)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"wait-\"><a href=\"#wait-\" class=\"headerlink\" title=\"wait \"></a>wait </h3><p>k8s.io/apimachinery/pkg/util/wait/wait.go</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func JitterUntil(f func(), period time.Duration, jitterFactor float64, sliding bool, stopCh &lt;-chan struct&#123;&#125;) &#123;</span><br><span class=\"line\">\tvar t *time.Timer</span><br><span class=\"line\">\tvar sawTimeout bool</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase &lt;-stopCh:</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\tdefault:</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tjitteredPeriod := period</span><br><span class=\"line\">\t\tif jitterFactor &gt; 0.0 &#123;</span><br><span class=\"line\">\t\t\tjitteredPeriod = Jitter(period, jitterFactor)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif !sliding &#123;</span><br><span class=\"line\">\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tfunc() &#123;</span><br><span class=\"line\">\t\t\tdefer runtime.HandleCrash()</span><br><span class=\"line\">\t\t\tf()</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif sliding &#123;</span><br><span class=\"line\">\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase &lt;-stopCh:</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\tcase &lt;-t.C:</span><br><span class=\"line\">\t\t\tsawTimeout = true</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">func resetOrReuseTimer(t *time.Timer, d time.Duration, sawTimeout bool) *time.Timer &#123;</span><br><span class=\"line\">    if t == nil &#123;</span><br><span class=\"line\">        return time.NewTimer(d)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if !t.Stop() &amp;&amp; !sawTimeout &#123;</span><br><span class=\"line\">        &lt;-t.C</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    t.Reset(d)</span><br><span class=\"line\">    return t</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>1 sliding  true f()  false period  f() </li>\n<li>2 golang  select  f(), stopCh chan</li>\n</ul>\n<p>k8s  wait  time.Timer </p>\n<h3 id=\"wait-\"><a href=\"#wait-\" class=\"headerlink\" title=\"wait \"></a>wait </h3><h5 id=\"1-Forever-\"><a href=\"#1-Forever-\" class=\"headerlink\" title=\"1 Forever \"></a>1 Forever </h5><p>func Forever(f func(), period time.Duration)</p>\n<h5 id=\"2-chan-\"><a href=\"#2-chan-\" class=\"headerlink\" title=\"2 chan \"></a>2 chan </h5><p>func Until(f func(), period time.Duration, stopCh &lt;-chan struct{})</p>\n<p> stopCh  close  chan </p>\n<h5 id=\"3-Poll-\"><a href=\"#3-Poll-\" class=\"headerlink\" title=\"3 Poll \"></a>3 Poll </h5><p>func Poll(interval, timeout time.Duration, condition ConditionFunc)</p>\n<p> interval  condition  timeout </p>\n<h5 id=\"4PollUntil--timeout--stopCh-\"><a href=\"#4PollUntil--timeout--stopCh-\" class=\"headerlink\" title=\"4PollUntil  timeout  stopCh \"></a>4PollUntil  timeout  stopCh </h5><p>PollUntil(interval time.Duration, condition ConditionFunc, stopCh &lt;-chan struct{}) error</p>\n<p> PollImmediate  PollInfinite  PollImmediateInfinite </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> k8s wait k8s  k8s </p>\n","site":{"data":{}},"excerpt":"","more":"<p>k8s  k8s k8s  wait wait  k8s  wait  kubelet </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh &lt;-chan struct&#123;&#125;) (err error) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t// kubelet 5 apiserver </span><br><span class=\"line\">\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tcloseAllConns, err := kubeletcertificate.UpdateTransport(wait.NeverStop, clientConfig, clientCertificateManager, 5*time.Minute)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">func startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration,   kubeDeps *kubelet.Dependencies, enableServer bool) &#123;</span><br><span class=\"line\">    //  pod </span><br><span class=\"line\">    go wait.Until(func() &#123;</span><br><span class=\"line\">        k.Run(podCfg.Updates())</span><br><span class=\"line\">    &#125;, 0, wait.NeverStop)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>golang  time.Ticker  k8s  time.Timer time.Ticker  time.Timer </p>\n<ul>\n<li>ticker </li>\n<li>timer </li>\n<li> timer  ticker  <code>func (t *Timer) Reset(d Duration) bool</code></li>\n</ul>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;sync&quot;</span><br><span class=\"line\">\t&quot;time&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tvar wg sync.WaitGroup</span><br><span class=\"line\"></span><br><span class=\"line\">\ttimer1 := time.NewTimer(2 * time.Second)</span><br><span class=\"line\">\tticker1 := time.NewTicker(2 * time.Second)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(1)</span><br><span class=\"line\">\tgo func(t *time.Ticker) &#123;</span><br><span class=\"line\">\t\tdefer wg.Done()</span><br><span class=\"line\">\t\tfor &#123;</span><br><span class=\"line\">\t\t\t&lt;-t.C</span><br><span class=\"line\">\t\t\tfmt.Println(&quot;exec ticker&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;))</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;(ticker1)</span><br><span class=\"line\"></span><br><span class=\"line\">\twg.Add(1)</span><br><span class=\"line\">\tgo func(t *time.Timer) &#123;</span><br><span class=\"line\">\t\tdefer wg.Done()</span><br><span class=\"line\">\t\tfor &#123;</span><br><span class=\"line\">\t\t\t&lt;-t.C</span><br><span class=\"line\">\t\t\tfmt.Println(&quot;exec timer&quot;, time.Now().Format(&quot;2006-01-02 15:04:05&quot;))</span><br><span class=\"line\">\t\t\tt.Reset(2 * time.Second)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;(timer1)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\twg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"wait-\"><a href=\"#wait-\" class=\"headerlink\" title=\"wait \"></a>wait </h3><p>k8s.io/apimachinery/pkg/util/wait/wait.go</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func JitterUntil(f func(), period time.Duration, jitterFactor float64, sliding bool, stopCh &lt;-chan struct&#123;&#125;) &#123;</span><br><span class=\"line\">\tvar t *time.Timer</span><br><span class=\"line\">\tvar sawTimeout bool</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase &lt;-stopCh:</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\tdefault:</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tjitteredPeriod := period</span><br><span class=\"line\">\t\tif jitterFactor &gt; 0.0 &#123;</span><br><span class=\"line\">\t\t\tjitteredPeriod = Jitter(period, jitterFactor)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif !sliding &#123;</span><br><span class=\"line\">\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tfunc() &#123;</span><br><span class=\"line\">\t\t\tdefer runtime.HandleCrash()</span><br><span class=\"line\">\t\t\tf()</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif sliding &#123;</span><br><span class=\"line\">\t\t\tt = resetOrReuseTimer(t, jitteredPeriod, sawTimeout)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tselect &#123;</span><br><span class=\"line\">\t\tcase &lt;-stopCh:</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\tcase &lt;-t.C:</span><br><span class=\"line\">\t\t\tsawTimeout = true</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">func resetOrReuseTimer(t *time.Timer, d time.Duration, sawTimeout bool) *time.Timer &#123;</span><br><span class=\"line\">    if t == nil &#123;</span><br><span class=\"line\">        return time.NewTimer(d)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if !t.Stop() &amp;&amp; !sawTimeout &#123;</span><br><span class=\"line\">        &lt;-t.C</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    t.Reset(d)</span><br><span class=\"line\">    return t</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>1 sliding  true f()  false period  f() </li>\n<li>2 golang  select  f(), stopCh chan</li>\n</ul>\n<p>k8s  wait  time.Timer </p>\n<h3 id=\"wait-\"><a href=\"#wait-\" class=\"headerlink\" title=\"wait \"></a>wait </h3><h5 id=\"1-Forever-\"><a href=\"#1-Forever-\" class=\"headerlink\" title=\"1 Forever \"></a>1 Forever </h5><p>func Forever(f func(), period time.Duration)</p>\n<h5 id=\"2-chan-\"><a href=\"#2-chan-\" class=\"headerlink\" title=\"2 chan \"></a>2 chan </h5><p>func Until(f func(), period time.Duration, stopCh &lt;-chan struct{})</p>\n<p> stopCh  close  chan </p>\n<h5 id=\"3-Poll-\"><a href=\"#3-Poll-\" class=\"headerlink\" title=\"3 Poll \"></a>3 Poll </h5><p>func Poll(interval, timeout time.Duration, condition ConditionFunc)</p>\n<p> interval  condition  timeout </p>\n<h5 id=\"4PollUntil--timeout--stopCh-\"><a href=\"#4PollUntil--timeout--stopCh-\" class=\"headerlink\" title=\"4PollUntil  timeout  stopCh \"></a>4PollUntil  timeout  stopCh </h5><p>PollUntil(interval time.Duration, condition ConditionFunc, stopCh &lt;-chan struct{}) error</p>\n<p> PollImmediate  PollInfinite  PollImmediateInfinite </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> k8s wait k8s  k8s </p>\n"},{"title":"kubernetes  metrics-server ","date":"2019-04-14T13:27:30.000Z","type":"metrics-server","_content":"\n[metrics-server](https://github.com/kubernetes-incubator/metrics-server)  cadvisor v1.8  heapster metric-server  core metrics() API metrics.k8s.io nodepod  CPU/Memory/Storage  Metrics API  DashboardHPAscheduler \n\n####  API Aggregation\n\n metrics-server  API k8s  API  apiserver  metrics-server  [kube-aggregator](https://github.com/kubernetes/kube-aggregator)  metrics-server  kube-apiserver  API Aggregation\n\n```\n--proxy-client-cert-file=/etc/kubernetes/certs/proxy.crt\n--proxy-client-key-file=/etc/kubernetes/certs/proxy.key\n--requestheader-client-ca-file=/etc/kubernetes/certs/proxy-ca.crt\n--requestheader-allowed-names=aggregator\n--requestheader-extra-headers-prefix=X-Remote-Extra-\n--requestheader-group-headers=X-Remote-Group\n--requestheader-username-headers=X-Remote-User\n```\n\nkube-proxyMaster\n\n```\n--enable-aggregator-routing=true\n```\n\n[kube-aggregator](https://github.com/kubernetes/kube-aggregator)  [configure-aggregation-layer](https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/)\n\n####  metrics-server\n\n##### 1\n\n```\n$ git clone  https://github.com/kubernetes/kubernetes\n$ cd  kubernetes/cluster/addons/metrics-server/\n```\n\n##### 2 metrics-server \n\n `resource-reader.yaml` \n\n```\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - nodes\n  - nodes/stats    #\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n```\n\n `metrics-server-deployment.yaml`:\n\n```\n\n      ......\n      # metrics-server containers \n      containers:\n      - name: metrics-server\n        image: k8s.gcr.io/metrics-server-amd64:v0.3.1\n        command:\n        - /metrics-server\n        - --metric-resolution=30s\n        - --kubelet-insecure-tls\n        - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP\n        # These are needed for GKE, which doesn't support secure communication yet.\n        # Remove these lines for non-GKE clusters, and when GKE supports token-based auth.\n        #- --kubelet-port=10255\n        #- --deprecated-kubelet-completely-insecure=true\n\t\t\t\t\n\t......           \n\t# \n        command:\n          - /pod_nanny\n          - --config-dir=/etc/config\n          - --cpu=80m\n          - --extra-cpu=0.5m\n          - --memory=80Mi\n          - --extra-memory=8Mi\n          - --threshold=5\n          - --deployment=metrics-server-v0.3.1\n          - --container=metrics-server\n          - --poll-period=300000\n          - --estimator=exponential\n          # Specifies the smallest cluster (defined in number of nodes)\n          # resources will be scaled to.\n          #- --minClusterSize={{ metrics_server_min_cluster_size }}\n```\n\n##### 3\n\n```\nkubectl apply -f .  \n```\n\nmetrics-server  Pod  addon-resizer  metrics-serveraddon-resizer  metrics-servermetrics API [addon-resizer](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer)\n\n>   [k8s-system-images](https://github.com/gosoon/k8s-system-images.git)  \n\n\n\n\n\n```\n$ kubectl get apiservices | grep metrics\nv1beta1.metrics.k8s.io     kube-system/metrics-server   True        2m\n\n$ kubectl get pod -n kube-system\nmetrics-server-v0.3.1-65b6db6945-rpqwf   2/2     Running   0          20h\n```\n\n\n\n#### metrics-server \n\n1\n\n```\n$ kubectl top node\nNAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\nnode1            108m         2%     1532Mi          40%\n\n$ kubectl top pod -n kube-system\nNAME                                     CPU(cores)   MEMORY(bytes)\ncoredns-576cbf47c7-8v6n8                 2m           14Mi\ncoredns-576cbf47c7-qk7rk                 2m           10Mi\netcd-node1                               11m          80Mi\nkube-apiserver-node1                     17m          566Mi\nkube-controller-manager-node1            17m          67Mi\nkube-flannel-ds-amd64-8lvs2              2m           13Mi\nkube-proxy-85lhl                         3m           19Mi\nkube-scheduler-node1                     5m           16Mi\nmetrics-server-v0.3.1-65b6db6945-rpqwf   2m           19Mi\n```\n\nMetrics-server  [API](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md) \n\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes`\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes/<node-name>`\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/pods`\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespace/<namespace-name>/pods/<pod-name>`\n\n k8s  v1.10  8080  API\n```\n$ kubectl proxy\n$ curl http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes\n```\n\n kubectl  API\n```\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes/<node-name>\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespace/<namespace-name>/pods/<pod-name>\n```\n\n","source":"_posts/k8s_metrics_server.md","raw":"---\ntitle: kubernetes  metrics-server \ndate: 2019-04-14 21:27:30\ntags: [\"metrics-server\"]\ntype: \"metrics-server\"\n\n---\n\n[metrics-server](https://github.com/kubernetes-incubator/metrics-server)  cadvisor v1.8  heapster metric-server  core metrics() API metrics.k8s.io nodepod  CPU/Memory/Storage  Metrics API  DashboardHPAscheduler \n\n####  API Aggregation\n\n metrics-server  API k8s  API  apiserver  metrics-server  [kube-aggregator](https://github.com/kubernetes/kube-aggregator)  metrics-server  kube-apiserver  API Aggregation\n\n```\n--proxy-client-cert-file=/etc/kubernetes/certs/proxy.crt\n--proxy-client-key-file=/etc/kubernetes/certs/proxy.key\n--requestheader-client-ca-file=/etc/kubernetes/certs/proxy-ca.crt\n--requestheader-allowed-names=aggregator\n--requestheader-extra-headers-prefix=X-Remote-Extra-\n--requestheader-group-headers=X-Remote-Group\n--requestheader-username-headers=X-Remote-User\n```\n\nkube-proxyMaster\n\n```\n--enable-aggregator-routing=true\n```\n\n[kube-aggregator](https://github.com/kubernetes/kube-aggregator)  [configure-aggregation-layer](https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/)\n\n####  metrics-server\n\n##### 1\n\n```\n$ git clone  https://github.com/kubernetes/kubernetes\n$ cd  kubernetes/cluster/addons/metrics-server/\n```\n\n##### 2 metrics-server \n\n `resource-reader.yaml` \n\n```\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - pods\n  - nodes\n  - nodes/stats    #\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n```\n\n `metrics-server-deployment.yaml`:\n\n```\n\n      ......\n      # metrics-server containers \n      containers:\n      - name: metrics-server\n        image: k8s.gcr.io/metrics-server-amd64:v0.3.1\n        command:\n        - /metrics-server\n        - --metric-resolution=30s\n        - --kubelet-insecure-tls\n        - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP\n        # These are needed for GKE, which doesn't support secure communication yet.\n        # Remove these lines for non-GKE clusters, and when GKE supports token-based auth.\n        #- --kubelet-port=10255\n        #- --deprecated-kubelet-completely-insecure=true\n\t\t\t\t\n\t......           \n\t# \n        command:\n          - /pod_nanny\n          - --config-dir=/etc/config\n          - --cpu=80m\n          - --extra-cpu=0.5m\n          - --memory=80Mi\n          - --extra-memory=8Mi\n          - --threshold=5\n          - --deployment=metrics-server-v0.3.1\n          - --container=metrics-server\n          - --poll-period=300000\n          - --estimator=exponential\n          # Specifies the smallest cluster (defined in number of nodes)\n          # resources will be scaled to.\n          #- --minClusterSize={{ metrics_server_min_cluster_size }}\n```\n\n##### 3\n\n```\nkubectl apply -f .  \n```\n\nmetrics-server  Pod  addon-resizer  metrics-serveraddon-resizer  metrics-servermetrics API [addon-resizer](https://github.com/kubernetes/autoscaler/tree/master/addon-resizer)\n\n>   [k8s-system-images](https://github.com/gosoon/k8s-system-images.git)  \n\n\n\n\n\n```\n$ kubectl get apiservices | grep metrics\nv1beta1.metrics.k8s.io     kube-system/metrics-server   True        2m\n\n$ kubectl get pod -n kube-system\nmetrics-server-v0.3.1-65b6db6945-rpqwf   2/2     Running   0          20h\n```\n\n\n\n#### metrics-server \n\n1\n\n```\n$ kubectl top node\nNAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\nnode1            108m         2%     1532Mi          40%\n\n$ kubectl top pod -n kube-system\nNAME                                     CPU(cores)   MEMORY(bytes)\ncoredns-576cbf47c7-8v6n8                 2m           14Mi\ncoredns-576cbf47c7-qk7rk                 2m           10Mi\netcd-node1                               11m          80Mi\nkube-apiserver-node1                     17m          566Mi\nkube-controller-manager-node1            17m          67Mi\nkube-flannel-ds-amd64-8lvs2              2m           13Mi\nkube-proxy-85lhl                         3m           19Mi\nkube-scheduler-node1                     5m           16Mi\nmetrics-server-v0.3.1-65b6db6945-rpqwf   2m           19Mi\n```\n\nMetrics-server  [API](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md) \n\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes`\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes/<node-name>`\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/pods`\n- `http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespace/<namespace-name>/pods/<pod-name>`\n\n k8s  v1.10  8080  API\n```\n$ kubectl proxy\n$ curl http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes\n```\n\n kubectl  API\n```\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes/<node-name>\n$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespace/<namespace-name>/pods/<pod-name>\n```\n\n","slug":"k8s_metrics_server","published":1,"updated":"2019-04-14T13:30:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyss80006tadvflk99uum","content":"<p><a href=\"https://github.com/kubernetes-incubator/metrics-server\" target=\"_blank\" rel=\"noopener\">metrics-server</a>  cadvisor v1.8  heapster metric-server  core metrics() API metrics.k8s.io nodepod  CPU/Memory/Storage  Metrics API  DashboardHPAscheduler </p>\n<h4 id=\"-API-Aggregation\"><a href=\"#-API-Aggregation\" class=\"headerlink\" title=\" API Aggregation\"></a> API Aggregation</h4><p> metrics-server  API k8s  API  apiserver  metrics-server  <a href=\"https://github.com/kubernetes/kube-aggregator\" target=\"_blank\" rel=\"noopener\">kube-aggregator</a>  metrics-server  kube-apiserver  API Aggregation</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--proxy-client-cert-file=/etc/kubernetes/certs/proxy.crt</span><br><span class=\"line\">--proxy-client-key-file=/etc/kubernetes/certs/proxy.key</span><br><span class=\"line\">--requestheader-client-ca-file=/etc/kubernetes/certs/proxy-ca.crt</span><br><span class=\"line\">--requestheader-allowed-names=aggregator</span><br><span class=\"line\">--requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class=\"line\">--requestheader-group-headers=X-Remote-Group</span><br><span class=\"line\">--requestheader-username-headers=X-Remote-User</span><br></pre></td></tr></table></figure>\n<p>kube-proxyMaster</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--enable-aggregator-routing=true</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://github.com/kubernetes/kube-aggregator\" target=\"_blank\" rel=\"noopener\">kube-aggregator</a>  <a href=\"https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/\" target=\"_blank\" rel=\"noopener\">configure-aggregation-layer</a></p>\n<h4 id=\"-metrics-server\"><a href=\"#-metrics-server\" class=\"headerlink\" title=\" metrics-server\"></a> metrics-server</h4><h5 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone  https://github.com/kubernetes/kubernetes</span><br><span class=\"line\">$ cd  kubernetes/cluster/addons/metrics-server/</span><br></pre></td></tr></table></figure>\n<h5 id=\"2-metrics-server-\"><a href=\"#2-metrics-server-\" class=\"headerlink\" title=\"2 metrics-server \"></a>2 metrics-server </h5><p> <code>resource-reader.yaml</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  - nodes</span><br><span class=\"line\">  - nodes/stats    #</span><br><span class=\"line\">  - namespaces</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - get</span><br><span class=\"line\">  - list</span><br><span class=\"line\">  - watch</span><br></pre></td></tr></table></figure>\n<p> <code>metrics-server-deployment.yaml</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">     ......</span><br><span class=\"line\">     # metrics-server containers </span><br><span class=\"line\">     containers:</span><br><span class=\"line\">     - name: metrics-server</span><br><span class=\"line\">       image: k8s.gcr.io/metrics-server-amd64:v0.3.1</span><br><span class=\"line\">       command:</span><br><span class=\"line\">       - /metrics-server</span><br><span class=\"line\">       - --metric-resolution=30s</span><br><span class=\"line\">       - --kubelet-insecure-tls</span><br><span class=\"line\">       - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</span><br><span class=\"line\">       # These are needed for GKE, which doesn&apos;t support secure communication yet.</span><br><span class=\"line\">       # Remove these lines for non-GKE clusters, and when GKE supports token-based auth.</span><br><span class=\"line\">       #- --kubelet-port=10255</span><br><span class=\"line\">       #- --deprecated-kubelet-completely-insecure=true</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">......           </span><br><span class=\"line\"># </span><br><span class=\"line\">       command:</span><br><span class=\"line\">         - /pod_nanny</span><br><span class=\"line\">         - --config-dir=/etc/config</span><br><span class=\"line\">         - --cpu=80m</span><br><span class=\"line\">         - --extra-cpu=0.5m</span><br><span class=\"line\">         - --memory=80Mi</span><br><span class=\"line\">         - --extra-memory=8Mi</span><br><span class=\"line\">         - --threshold=5</span><br><span class=\"line\">         - --deployment=metrics-server-v0.3.1</span><br><span class=\"line\">         - --container=metrics-server</span><br><span class=\"line\">         - --poll-period=300000</span><br><span class=\"line\">         - --estimator=exponential</span><br><span class=\"line\">         # Specifies the smallest cluster (defined in number of nodes)</span><br><span class=\"line\">         # resources will be scaled to.</span><br><span class=\"line\">         #- --minClusterSize=&#123;&#123; metrics_server_min_cluster_size &#125;&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"3\"><a href=\"#3\" class=\"headerlink\" title=\"3\"></a>3</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f .</span><br></pre></td></tr></table></figure>\n<p>metrics-server  Pod  addon-resizer  metrics-serveraddon-resizer  metrics-servermetrics API <a href=\"https://github.com/kubernetes/autoscaler/tree/master/addon-resizer\" target=\"_blank\" rel=\"noopener\">addon-resizer</a></p>\n<blockquote>\n<p>  <a href=\"https://github.com/gosoon/k8s-system-images.git\" target=\"_blank\" rel=\"noopener\">k8s-system-images</a>  </p>\n</blockquote>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get apiservices | grep metrics</span><br><span class=\"line\">v1beta1.metrics.k8s.io     kube-system/metrics-server   True        2m</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n kube-system</span><br><span class=\"line\">metrics-server-v0.3.1-65b6db6945-rpqwf   2/2     Running   0          20h</span><br></pre></td></tr></table></figure>\n<h4 id=\"metrics-server-\"><a href=\"#metrics-server-\" class=\"headerlink\" title=\"metrics-server \"></a>metrics-server </h4><p>1</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl top node</span><br><span class=\"line\">NAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span><br><span class=\"line\">node1            108m         2%     1532Mi          40%</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl top pod -n kube-system</span><br><span class=\"line\">NAME                                     CPU(cores)   MEMORY(bytes)</span><br><span class=\"line\">coredns-576cbf47c7-8v6n8                 2m           14Mi</span><br><span class=\"line\">coredns-576cbf47c7-qk7rk                 2m           10Mi</span><br><span class=\"line\">etcd-node1                               11m          80Mi</span><br><span class=\"line\">kube-apiserver-node1                     17m          566Mi</span><br><span class=\"line\">kube-controller-manager-node1            17m          67Mi</span><br><span class=\"line\">kube-flannel-ds-amd64-8lvs2              2m           13Mi</span><br><span class=\"line\">kube-proxy-85lhl                         3m           19Mi</span><br><span class=\"line\">kube-scheduler-node1                     5m           16Mi</span><br><span class=\"line\">metrics-server-v0.3.1-65b6db6945-rpqwf   2m           19Mi</span><br></pre></td></tr></table></figure>\n<p>Metrics-server  <a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md\" target=\"_blank\" rel=\"noopener\">API</a> </p>\n<ul>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes</code></li>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes/&lt;node-name&gt;</code></li>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/pods</code></li>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespace/&lt;namespace-name&gt;/pods/&lt;pod-name&gt;</code></li>\n</ul>\n<p> k8s  v1.10  8080  API<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl proxy</span><br><span class=\"line\">$ curl http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes</span><br></pre></td></tr></table></figure></p>\n<p> kubectl  API<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes</span><br><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods</span><br><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes/&lt;node-name&gt;</span><br><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespace/&lt;namespace-name&gt;/pods/&lt;pod-name&gt;</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://github.com/kubernetes-incubator/metrics-server\" target=\"_blank\" rel=\"noopener\">metrics-server</a>  cadvisor v1.8  heapster metric-server  core metrics() API metrics.k8s.io nodepod  CPU/Memory/Storage  Metrics API  DashboardHPAscheduler </p>\n<h4 id=\"-API-Aggregation\"><a href=\"#-API-Aggregation\" class=\"headerlink\" title=\" API Aggregation\"></a> API Aggregation</h4><p> metrics-server  API k8s  API  apiserver  metrics-server  <a href=\"https://github.com/kubernetes/kube-aggregator\" target=\"_blank\" rel=\"noopener\">kube-aggregator</a>  metrics-server  kube-apiserver  API Aggregation</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--proxy-client-cert-file=/etc/kubernetes/certs/proxy.crt</span><br><span class=\"line\">--proxy-client-key-file=/etc/kubernetes/certs/proxy.key</span><br><span class=\"line\">--requestheader-client-ca-file=/etc/kubernetes/certs/proxy-ca.crt</span><br><span class=\"line\">--requestheader-allowed-names=aggregator</span><br><span class=\"line\">--requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class=\"line\">--requestheader-group-headers=X-Remote-Group</span><br><span class=\"line\">--requestheader-username-headers=X-Remote-User</span><br></pre></td></tr></table></figure>\n<p>kube-proxyMaster</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--enable-aggregator-routing=true</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://github.com/kubernetes/kube-aggregator\" target=\"_blank\" rel=\"noopener\">kube-aggregator</a>  <a href=\"https://kubernetes.io/docs/tasks/access-kubernetes-api/configure-aggregation-layer/\" target=\"_blank\" rel=\"noopener\">configure-aggregation-layer</a></p>\n<h4 id=\"-metrics-server\"><a href=\"#-metrics-server\" class=\"headerlink\" title=\" metrics-server\"></a> metrics-server</h4><h5 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone  https://github.com/kubernetes/kubernetes</span><br><span class=\"line\">$ cd  kubernetes/cluster/addons/metrics-server/</span><br></pre></td></tr></table></figure>\n<h5 id=\"2-metrics-server-\"><a href=\"#2-metrics-server-\" class=\"headerlink\" title=\"2 metrics-server \"></a>2 metrics-server </h5><p> <code>resource-reader.yaml</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rules:</span><br><span class=\"line\">- apiGroups:</span><br><span class=\"line\">  - &quot;&quot;</span><br><span class=\"line\">  resources:</span><br><span class=\"line\">  - pods</span><br><span class=\"line\">  - nodes</span><br><span class=\"line\">  - nodes/stats    #</span><br><span class=\"line\">  - namespaces</span><br><span class=\"line\">  verbs:</span><br><span class=\"line\">  - get</span><br><span class=\"line\">  - list</span><br><span class=\"line\">  - watch</span><br></pre></td></tr></table></figure>\n<p> <code>metrics-server-deployment.yaml</code>:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">     ......</span><br><span class=\"line\">     # metrics-server containers </span><br><span class=\"line\">     containers:</span><br><span class=\"line\">     - name: metrics-server</span><br><span class=\"line\">       image: k8s.gcr.io/metrics-server-amd64:v0.3.1</span><br><span class=\"line\">       command:</span><br><span class=\"line\">       - /metrics-server</span><br><span class=\"line\">       - --metric-resolution=30s</span><br><span class=\"line\">       - --kubelet-insecure-tls</span><br><span class=\"line\">       - --kubelet-preferred-address-types=InternalIP,Hostname,InternalDNS,ExternalDNS,ExternalIP</span><br><span class=\"line\">       # These are needed for GKE, which doesn&apos;t support secure communication yet.</span><br><span class=\"line\">       # Remove these lines for non-GKE clusters, and when GKE supports token-based auth.</span><br><span class=\"line\">       #- --kubelet-port=10255</span><br><span class=\"line\">       #- --deprecated-kubelet-completely-insecure=true</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">......           </span><br><span class=\"line\"># </span><br><span class=\"line\">       command:</span><br><span class=\"line\">         - /pod_nanny</span><br><span class=\"line\">         - --config-dir=/etc/config</span><br><span class=\"line\">         - --cpu=80m</span><br><span class=\"line\">         - --extra-cpu=0.5m</span><br><span class=\"line\">         - --memory=80Mi</span><br><span class=\"line\">         - --extra-memory=8Mi</span><br><span class=\"line\">         - --threshold=5</span><br><span class=\"line\">         - --deployment=metrics-server-v0.3.1</span><br><span class=\"line\">         - --container=metrics-server</span><br><span class=\"line\">         - --poll-period=300000</span><br><span class=\"line\">         - --estimator=exponential</span><br><span class=\"line\">         # Specifies the smallest cluster (defined in number of nodes)</span><br><span class=\"line\">         # resources will be scaled to.</span><br><span class=\"line\">         #- --minClusterSize=&#123;&#123; metrics_server_min_cluster_size &#125;&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"3\"><a href=\"#3\" class=\"headerlink\" title=\"3\"></a>3</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl apply -f .</span><br></pre></td></tr></table></figure>\n<p>metrics-server  Pod  addon-resizer  metrics-serveraddon-resizer  metrics-servermetrics API <a href=\"https://github.com/kubernetes/autoscaler/tree/master/addon-resizer\" target=\"_blank\" rel=\"noopener\">addon-resizer</a></p>\n<blockquote>\n<p>  <a href=\"https://github.com/gosoon/k8s-system-images.git\" target=\"_blank\" rel=\"noopener\">k8s-system-images</a>  </p>\n</blockquote>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get apiservices | grep metrics</span><br><span class=\"line\">v1beta1.metrics.k8s.io     kube-system/metrics-server   True        2m</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n kube-system</span><br><span class=\"line\">metrics-server-v0.3.1-65b6db6945-rpqwf   2/2     Running   0          20h</span><br></pre></td></tr></table></figure>\n<h4 id=\"metrics-server-\"><a href=\"#metrics-server-\" class=\"headerlink\" title=\"metrics-server \"></a>metrics-server </h4><p>1</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl top node</span><br><span class=\"line\">NAME             CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span><br><span class=\"line\">node1            108m         2%     1532Mi          40%</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl top pod -n kube-system</span><br><span class=\"line\">NAME                                     CPU(cores)   MEMORY(bytes)</span><br><span class=\"line\">coredns-576cbf47c7-8v6n8                 2m           14Mi</span><br><span class=\"line\">coredns-576cbf47c7-qk7rk                 2m           10Mi</span><br><span class=\"line\">etcd-node1                               11m          80Mi</span><br><span class=\"line\">kube-apiserver-node1                     17m          566Mi</span><br><span class=\"line\">kube-controller-manager-node1            17m          67Mi</span><br><span class=\"line\">kube-flannel-ds-amd64-8lvs2              2m           13Mi</span><br><span class=\"line\">kube-proxy-85lhl                         3m           19Mi</span><br><span class=\"line\">kube-scheduler-node1                     5m           16Mi</span><br><span class=\"line\">metrics-server-v0.3.1-65b6db6945-rpqwf   2m           19Mi</span><br></pre></td></tr></table></figure>\n<p>Metrics-server  <a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/instrumentation/resource-metrics-api.md\" target=\"_blank\" rel=\"noopener\">API</a> </p>\n<ul>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes</code></li>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes/&lt;node-name&gt;</code></li>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/pods</code></li>\n<li><code>http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/namespace/&lt;namespace-name&gt;/pods/&lt;pod-name&gt;</code></li>\n</ul>\n<p> k8s  v1.10  8080  API<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl proxy</span><br><span class=\"line\">$ curl http://127.0.0.1:8001/apis/metrics.k8s.io/v1beta1/nodes</span><br></pre></td></tr></table></figure></p>\n<p> kubectl  API<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes</span><br><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/pods</span><br><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes/&lt;node-name&gt;</span><br><span class=\"line\">$ kubectl get --raw /apis/metrics.k8s.io/v1beta1/namespace/&lt;namespace-name&gt;/pods/&lt;pod-name&gt;</span><br></pre></td></tr></table></figure></p>\n"},{"title":"kubernetes  v1.12 ","date":"2019-03-05T10:30:30.000Z","type":"v1.12","_content":"\n v1.12  v1.8k8s  k8s  v1.12 \n\n### 1 k8s  resource version \n\nk8s  resouce  k8s statefulset  v1.8  apiVersion  apps/v1beta1 v1.12  apps/v1k8s  OpenAPI \n\n![image.png](https://upload-images.jianshu.io/upload_images/1262158-272c63b4eabe3cee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n[The Kubernetes API](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)\n\n k8s  resource version  resource version \n\n### 2kubelet \n\nv1.8  kubelet  /etc/kubernetes/kubelet  KUBELET_ARGS  v1.12  config.yaml  yaml  config.yaml \n\nconfig.yaml [Set Kubelet parameters via a config file](https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/)\n\n\n\n```\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\naddress: 0.0.0.0\n- pods\neventBurst: 10\neventRecordQPS: 5\nevictionHard:\n  imagefs.available: 15%\n  memory.available: 100Mi\n  nodefs.available: 10%\n  nodefs.inodesFree: 5%\nevictionPressureTransitionPeriod: 5m0s\nfailSwapOn: true\nfileCheckFrequency: 20s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 20s\nimageGCHighThresholdPercent: 85\nimageGCLowThresholdPercent: 80\nimageMinimumGCAge: 2m0s\nmaxOpenFiles: 1000000\nmaxPods: 110\nnodeLeaseDurationSeconds: 40\nnodeStatusUpdateFrequency: 10s\noomScoreAdj: -999\npodPidsLimit: -1\nport: 10250\nstaticPodPath: /etc/kubernetes/manifests\n```\n\n kubelet  LOG_LEVEL  5  config.yaml \n\n![image.png](https://upload-images.jianshu.io/upload_images/1262158-8af5facac815e980.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n\n```\nI0228 16:14:14.064292  191819 server.go:260] KubeletConfiguration: \nconfig.KubeletConfiguration{TypeMeta:v1.TypeMeta{Kind:\"\", \nAPIVersion:\"\"}, StaticPodPath:\"\", Sync    \nFrequency:v1.Duration{Duration:60000000000}, \nFileCheckFrequency:v1.Duration{Duration:20000000000},\nHTTPCheckFrequency:v1.Duration{Duration:20000000000}, \nStaticPodURL:\"\", StaticPodURLHeader:map[string][]string(nil),\nAddress:\"0.0.0.0\", Port:10250, \n...\n```\n\n> kubelet  ARGS  config.yaml \n\n\n### 3feature-gates \n\nv1.12  feature-gates \n\nk8s  Feature  [Feature Gates](https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/) \n\n\n### 4cadvisor  \n\nk8s  1.12  cadvisor  kubelet  cadvisor DaemonSet  cadvisor  cadvisor \n\n cadvisor [cAdvisor Kubernetes Daemonset](\nhttps://github.com/google/cadvisor/blob/master/deploy/kubernetes/README.md) `k8s.gcr.io/cadvisor:v0.30.2`  `/sys/fs/cgroup/cpuacct,cpu: no such file or directory`,  cadvisor v0.30.2  cgroup v2v2  cpuacct subsystem linux kernel 4.5  cgroup v2 v0.28.0 \n\ncadvisor  4194  hostnetwork \n\n```\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cadvisor\n  namespace: kube-system\n  labels:\n    app: cadvisor\nspec:\n  selector:\n    matchLabels:\n      name: cadvisor\n  template:\n    metadata:\n      labels:\n        name: cadvisor\n    spec:\n      hostNetwork: true\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n        key: enabledDiskSchedule\n        value: \"true\"\n        effect: NoSchedule\n      containers:\n      - name: cadvisor\n        image: k8s.gcr.io/cadvisor:v0.28.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: rootfs\n          mountPath: /rootfs\n          readOnly: true\n        - name: var-run\n          mountPath: /var/run\n          readOnly: false\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        - name: docker\n          mountPath: /var/lib/docker\n          readOnly: true\n        ports:\n          - name: http\n            containerPort: 4194\n            protocol: TCP\n        readinessProbe:\n          tcpSocket:\n            port: 4194\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        args:\n          - --housekeeping_interval=10s\n          - --port=4194\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: rootfs\n        hostPath:\n          path: /\n      - name: var-run\n        hostPath:\n          path: /var/run\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: docker\n        hostPath:\n          path: /var/lib/docker\n```\n\n kustomize kustomize  k8s \n\n>  taint  yaml  tolerations\n\n\n","source":"_posts/k8s_v1.12.md","raw":"---\ntitle: kubernetes  v1.12 \ndate: 2019-03-05 18:30:30\ntags: \"kubernetes v1.12\"\ntype: \"v1.12\"\n\n---\n\n v1.12  v1.8k8s  k8s  v1.12 \n\n### 1 k8s  resource version \n\nk8s  resouce  k8s statefulset  v1.8  apiVersion  apps/v1beta1 v1.12  apps/v1k8s  OpenAPI \n\n![image.png](https://upload-images.jianshu.io/upload_images/1262158-272c63b4eabe3cee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n[The Kubernetes API](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)\n\n k8s  resource version  resource version \n\n### 2kubelet \n\nv1.8  kubelet  /etc/kubernetes/kubelet  KUBELET_ARGS  v1.12  config.yaml  yaml  config.yaml \n\nconfig.yaml [Set Kubelet parameters via a config file](https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/)\n\n\n\n```\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\naddress: 0.0.0.0\n- pods\neventBurst: 10\neventRecordQPS: 5\nevictionHard:\n  imagefs.available: 15%\n  memory.available: 100Mi\n  nodefs.available: 10%\n  nodefs.inodesFree: 5%\nevictionPressureTransitionPeriod: 5m0s\nfailSwapOn: true\nfileCheckFrequency: 20s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 20s\nimageGCHighThresholdPercent: 85\nimageGCLowThresholdPercent: 80\nimageMinimumGCAge: 2m0s\nmaxOpenFiles: 1000000\nmaxPods: 110\nnodeLeaseDurationSeconds: 40\nnodeStatusUpdateFrequency: 10s\noomScoreAdj: -999\npodPidsLimit: -1\nport: 10250\nstaticPodPath: /etc/kubernetes/manifests\n```\n\n kubelet  LOG_LEVEL  5  config.yaml \n\n![image.png](https://upload-images.jianshu.io/upload_images/1262158-8af5facac815e980.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n\n```\nI0228 16:14:14.064292  191819 server.go:260] KubeletConfiguration: \nconfig.KubeletConfiguration{TypeMeta:v1.TypeMeta{Kind:\"\", \nAPIVersion:\"\"}, StaticPodPath:\"\", Sync    \nFrequency:v1.Duration{Duration:60000000000}, \nFileCheckFrequency:v1.Duration{Duration:20000000000},\nHTTPCheckFrequency:v1.Duration{Duration:20000000000}, \nStaticPodURL:\"\", StaticPodURLHeader:map[string][]string(nil),\nAddress:\"0.0.0.0\", Port:10250, \n...\n```\n\n> kubelet  ARGS  config.yaml \n\n\n### 3feature-gates \n\nv1.12  feature-gates \n\nk8s  Feature  [Feature Gates](https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/) \n\n\n### 4cadvisor  \n\nk8s  1.12  cadvisor  kubelet  cadvisor DaemonSet  cadvisor  cadvisor \n\n cadvisor [cAdvisor Kubernetes Daemonset](\nhttps://github.com/google/cadvisor/blob/master/deploy/kubernetes/README.md) `k8s.gcr.io/cadvisor:v0.30.2`  `/sys/fs/cgroup/cpuacct,cpu: no such file or directory`,  cadvisor v0.30.2  cgroup v2v2  cpuacct subsystem linux kernel 4.5  cgroup v2 v0.28.0 \n\ncadvisor  4194  hostnetwork \n\n```\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: cadvisor\n  namespace: kube-system\n  labels:\n    app: cadvisor\nspec:\n  selector:\n    matchLabels:\n      name: cadvisor\n  template:\n    metadata:\n      labels:\n        name: cadvisor\n    spec:\n      hostNetwork: true\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n        key: enabledDiskSchedule\n        value: \"true\"\n        effect: NoSchedule\n      containers:\n      - name: cadvisor\n        image: k8s.gcr.io/cadvisor:v0.28.0\n        imagePullPolicy: IfNotPresent\n        volumeMounts:\n        - name: rootfs\n          mountPath: /rootfs\n          readOnly: true\n        - name: var-run\n          mountPath: /var/run\n          readOnly: false\n        - name: sys\n          mountPath: /sys\n          readOnly: true\n        - name: docker\n          mountPath: /var/lib/docker\n          readOnly: true\n        ports:\n          - name: http\n            containerPort: 4194\n            protocol: TCP\n        readinessProbe:\n          tcpSocket:\n            port: 4194\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        args:\n          - --housekeeping_interval=10s\n          - --port=4194\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: rootfs\n        hostPath:\n          path: /\n      - name: var-run\n        hostPath:\n          path: /var/run\n      - name: sys\n        hostPath:\n          path: /sys\n      - name: docker\n        hostPath:\n          path: /var/lib/docker\n```\n\n kustomize kustomize  k8s \n\n>  taint  yaml  tolerations\n\n\n","slug":"k8s_v1.12","published":1,"updated":"2019-03-05T08:41:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyssb0008tadv100lgpq4","content":"<p> v1.12  v1.8k8s  k8s  v1.12 </p>\n<h3 id=\"1-k8s--resource-version-\"><a href=\"#1-k8s--resource-version-\" class=\"headerlink\" title=\"1 k8s  resource version \"></a>1 k8s  resource version </h3><p>k8s  resouce  k8s statefulset  v1.8  apiVersion  apps/v1beta1 v1.12  apps/v1k8s  OpenAPI </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-272c63b4eabe3cee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/kubernetes-api/\" target=\"_blank\" rel=\"noopener\">The Kubernetes API</a></p>\n<p> k8s  resource version  resource version </p>\n<h3 id=\"2kubelet-\"><a href=\"#2kubelet-\" class=\"headerlink\" title=\"2kubelet \"></a>2kubelet </h3><p>v1.8  kubelet  /etc/kubernetes/kubelet  KUBELET_ARGS  v1.12  config.yaml  yaml  config.yaml </p>\n<p>config.yaml <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/\" target=\"_blank\" rel=\"noopener\">Set Kubelet parameters via a config file</a></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">kind: KubeletConfiguration</span><br><span class=\"line\">address: 0.0.0.0</span><br><span class=\"line\">- pods</span><br><span class=\"line\">eventBurst: 10</span><br><span class=\"line\">eventRecordQPS: 5</span><br><span class=\"line\">evictionHard:</span><br><span class=\"line\">  imagefs.available: 15%</span><br><span class=\"line\">  memory.available: 100Mi</span><br><span class=\"line\">  nodefs.available: 10%</span><br><span class=\"line\">  nodefs.inodesFree: 5%</span><br><span class=\"line\">evictionPressureTransitionPeriod: 5m0s</span><br><span class=\"line\">failSwapOn: true</span><br><span class=\"line\">fileCheckFrequency: 20s</span><br><span class=\"line\">healthzBindAddress: 127.0.0.1</span><br><span class=\"line\">healthzPort: 10248</span><br><span class=\"line\">httpCheckFrequency: 20s</span><br><span class=\"line\">imageGCHighThresholdPercent: 85</span><br><span class=\"line\">imageGCLowThresholdPercent: 80</span><br><span class=\"line\">imageMinimumGCAge: 2m0s</span><br><span class=\"line\">maxOpenFiles: 1000000</span><br><span class=\"line\">maxPods: 110</span><br><span class=\"line\">nodeLeaseDurationSeconds: 40</span><br><span class=\"line\">nodeStatusUpdateFrequency: 10s</span><br><span class=\"line\">oomScoreAdj: -999</span><br><span class=\"line\">podPidsLimit: -1</span><br><span class=\"line\">port: 10250</span><br><span class=\"line\">staticPodPath: /etc/kubernetes/manifests</span><br></pre></td></tr></table></figure>\n<p> kubelet  LOG_LEVEL  5  config.yaml </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-8af5facac815e980.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">I0228 16:14:14.064292  191819 server.go:260] KubeletConfiguration: </span><br><span class=\"line\">config.KubeletConfiguration&#123;TypeMeta:v1.TypeMeta&#123;Kind:&quot;&quot;, </span><br><span class=\"line\">APIVersion:&quot;&quot;&#125;, StaticPodPath:&quot;&quot;, Sync    </span><br><span class=\"line\">Frequency:v1.Duration&#123;Duration:60000000000&#125;, </span><br><span class=\"line\">FileCheckFrequency:v1.Duration&#123;Duration:20000000000&#125;,</span><br><span class=\"line\">HTTPCheckFrequency:v1.Duration&#123;Duration:20000000000&#125;, </span><br><span class=\"line\">StaticPodURL:&quot;&quot;, StaticPodURLHeader:map[string][]string(nil),</span><br><span class=\"line\">Address:&quot;0.0.0.0&quot;, Port:10250, </span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>kubelet  ARGS  config.yaml </p>\n</blockquote>\n<h3 id=\"3feature-gates-\"><a href=\"#3feature-gates-\" class=\"headerlink\" title=\"3feature-gates \"></a>3feature-gates </h3><p>v1.12  feature-gates </p>\n<p>k8s  Feature  <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\" target=\"_blank\" rel=\"noopener\">Feature Gates</a> </p>\n<h3 id=\"4cadvisor-\"><a href=\"#4cadvisor-\" class=\"headerlink\" title=\"4cadvisor \"></a>4cadvisor </h3><p>k8s  1.12  cadvisor  kubelet  cadvisor DaemonSet  cadvisor  cadvisor </p>\n<p> cadvisor <a href=\"https://github.com/google/cadvisor/blob/master/deploy/kubernetes/README.md\" target=\"_blank\" rel=\"noopener\">cAdvisor Kubernetes Daemonset</a> <code>k8s.gcr.io/cadvisor:v0.30.2</code>  <code>/sys/fs/cgroup/cpuacct,cpu: no such file or directory</code>,  cadvisor v0.30.2  cgroup v2v2  cpuacct subsystem linux kernel 4.5  cgroup v2 v0.28.0 </p>\n<p>cadvisor  4194  hostnetwork </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: DaemonSet</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: cadvisor</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: cadvisor</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      name: cadvisor</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        name: cadvisor</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: node-role.kubernetes.io/master</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">        key: enabledDiskSchedule</span><br><span class=\"line\">        value: &quot;true&quot;</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: cadvisor</span><br><span class=\"line\">        image: k8s.gcr.io/cadvisor:v0.28.0</span><br><span class=\"line\">        imagePullPolicy: IfNotPresent</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: rootfs</span><br><span class=\"line\">          mountPath: /rootfs</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">        - name: var-run</span><br><span class=\"line\">          mountPath: /var/run</span><br><span class=\"line\">          readOnly: false</span><br><span class=\"line\">        - name: sys</span><br><span class=\"line\">          mountPath: /sys</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">        - name: docker</span><br><span class=\"line\">          mountPath: /var/lib/docker</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">          - name: http</span><br><span class=\"line\">            containerPort: 4194</span><br><span class=\"line\">            protocol: TCP</span><br><span class=\"line\">        readinessProbe:</span><br><span class=\"line\">          tcpSocket:</span><br><span class=\"line\">            port: 4194</span><br><span class=\"line\">          initialDelaySeconds: 5</span><br><span class=\"line\">          periodSeconds: 10</span><br><span class=\"line\">        args:</span><br><span class=\"line\">          - --housekeeping_interval=10s</span><br><span class=\"line\">          - --port=4194</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: rootfs</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /</span><br><span class=\"line\">      - name: var-run</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /var/run</span><br><span class=\"line\">      - name: sys</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /sys</span><br><span class=\"line\">      - name: docker</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /var/lib/docker</span><br></pre></td></tr></table></figure>\n<p> kustomize kustomize  k8s </p>\n<blockquote>\n<p> taint  yaml  tolerations</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p> v1.12  v1.8k8s  k8s  v1.12 </p>\n<h3 id=\"1-k8s--resource-version-\"><a href=\"#1-k8s--resource-version-\" class=\"headerlink\" title=\"1 k8s  resource version \"></a>1 k8s  resource version </h3><p>k8s  resouce  k8s statefulset  v1.8  apiVersion  apps/v1beta1 v1.12  apps/v1k8s  OpenAPI </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-272c63b4eabe3cee.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/kubernetes-api/\" target=\"_blank\" rel=\"noopener\">The Kubernetes API</a></p>\n<p> k8s  resource version  resource version </p>\n<h3 id=\"2kubelet-\"><a href=\"#2kubelet-\" class=\"headerlink\" title=\"2kubelet \"></a>2kubelet </h3><p>v1.8  kubelet  /etc/kubernetes/kubelet  KUBELET_ARGS  v1.12  config.yaml  yaml  config.yaml </p>\n<p>config.yaml <a href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/\" target=\"_blank\" rel=\"noopener\">Set Kubelet parameters via a config file</a></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class=\"line\">kind: KubeletConfiguration</span><br><span class=\"line\">address: 0.0.0.0</span><br><span class=\"line\">- pods</span><br><span class=\"line\">eventBurst: 10</span><br><span class=\"line\">eventRecordQPS: 5</span><br><span class=\"line\">evictionHard:</span><br><span class=\"line\">  imagefs.available: 15%</span><br><span class=\"line\">  memory.available: 100Mi</span><br><span class=\"line\">  nodefs.available: 10%</span><br><span class=\"line\">  nodefs.inodesFree: 5%</span><br><span class=\"line\">evictionPressureTransitionPeriod: 5m0s</span><br><span class=\"line\">failSwapOn: true</span><br><span class=\"line\">fileCheckFrequency: 20s</span><br><span class=\"line\">healthzBindAddress: 127.0.0.1</span><br><span class=\"line\">healthzPort: 10248</span><br><span class=\"line\">httpCheckFrequency: 20s</span><br><span class=\"line\">imageGCHighThresholdPercent: 85</span><br><span class=\"line\">imageGCLowThresholdPercent: 80</span><br><span class=\"line\">imageMinimumGCAge: 2m0s</span><br><span class=\"line\">maxOpenFiles: 1000000</span><br><span class=\"line\">maxPods: 110</span><br><span class=\"line\">nodeLeaseDurationSeconds: 40</span><br><span class=\"line\">nodeStatusUpdateFrequency: 10s</span><br><span class=\"line\">oomScoreAdj: -999</span><br><span class=\"line\">podPidsLimit: -1</span><br><span class=\"line\">port: 10250</span><br><span class=\"line\">staticPodPath: /etc/kubernetes/manifests</span><br></pre></td></tr></table></figure>\n<p> kubelet  LOG_LEVEL  5  config.yaml </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-8af5facac815e980.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"image.png\"></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">I0228 16:14:14.064292  191819 server.go:260] KubeletConfiguration: </span><br><span class=\"line\">config.KubeletConfiguration&#123;TypeMeta:v1.TypeMeta&#123;Kind:&quot;&quot;, </span><br><span class=\"line\">APIVersion:&quot;&quot;&#125;, StaticPodPath:&quot;&quot;, Sync    </span><br><span class=\"line\">Frequency:v1.Duration&#123;Duration:60000000000&#125;, </span><br><span class=\"line\">FileCheckFrequency:v1.Duration&#123;Duration:20000000000&#125;,</span><br><span class=\"line\">HTTPCheckFrequency:v1.Duration&#123;Duration:20000000000&#125;, </span><br><span class=\"line\">StaticPodURL:&quot;&quot;, StaticPodURLHeader:map[string][]string(nil),</span><br><span class=\"line\">Address:&quot;0.0.0.0&quot;, Port:10250, </span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>kubelet  ARGS  config.yaml </p>\n</blockquote>\n<h3 id=\"3feature-gates-\"><a href=\"#3feature-gates-\" class=\"headerlink\" title=\"3feature-gates \"></a>3feature-gates </h3><p>v1.12  feature-gates </p>\n<p>k8s  Feature  <a href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\" target=\"_blank\" rel=\"noopener\">Feature Gates</a> </p>\n<h3 id=\"4cadvisor-\"><a href=\"#4cadvisor-\" class=\"headerlink\" title=\"4cadvisor \"></a>4cadvisor </h3><p>k8s  1.12  cadvisor  kubelet  cadvisor DaemonSet  cadvisor  cadvisor </p>\n<p> cadvisor <a href=\"https://github.com/google/cadvisor/blob/master/deploy/kubernetes/README.md\" target=\"_blank\" rel=\"noopener\">cAdvisor Kubernetes Daemonset</a> <code>k8s.gcr.io/cadvisor:v0.30.2</code>  <code>/sys/fs/cgroup/cpuacct,cpu: no such file or directory</code>,  cadvisor v0.30.2  cgroup v2v2  cpuacct subsystem linux kernel 4.5  cgroup v2 v0.28.0 </p>\n<p>cadvisor  4194  hostnetwork </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">kind: DaemonSet</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: cadvisor</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    app: cadvisor</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      name: cadvisor</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        name: cadvisor</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">      - key: node-role.kubernetes.io/master</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">        key: enabledDiskSchedule</span><br><span class=\"line\">        value: &quot;true&quot;</span><br><span class=\"line\">        effect: NoSchedule</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">      - name: cadvisor</span><br><span class=\"line\">        image: k8s.gcr.io/cadvisor:v0.28.0</span><br><span class=\"line\">        imagePullPolicy: IfNotPresent</span><br><span class=\"line\">        volumeMounts:</span><br><span class=\"line\">        - name: rootfs</span><br><span class=\"line\">          mountPath: /rootfs</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">        - name: var-run</span><br><span class=\"line\">          mountPath: /var/run</span><br><span class=\"line\">          readOnly: false</span><br><span class=\"line\">        - name: sys</span><br><span class=\"line\">          mountPath: /sys</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">        - name: docker</span><br><span class=\"line\">          mountPath: /var/lib/docker</span><br><span class=\"line\">          readOnly: true</span><br><span class=\"line\">        ports:</span><br><span class=\"line\">          - name: http</span><br><span class=\"line\">            containerPort: 4194</span><br><span class=\"line\">            protocol: TCP</span><br><span class=\"line\">        readinessProbe:</span><br><span class=\"line\">          tcpSocket:</span><br><span class=\"line\">            port: 4194</span><br><span class=\"line\">          initialDelaySeconds: 5</span><br><span class=\"line\">          periodSeconds: 10</span><br><span class=\"line\">        args:</span><br><span class=\"line\">          - --housekeeping_interval=10s</span><br><span class=\"line\">          - --port=4194</span><br><span class=\"line\">      terminationGracePeriodSeconds: 30</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">      - name: rootfs</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /</span><br><span class=\"line\">      - name: var-run</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /var/run</span><br><span class=\"line\">      - name: sys</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /sys</span><br><span class=\"line\">      - name: docker</span><br><span class=\"line\">        hostPath:</span><br><span class=\"line\">          path: /var/lib/docker</span><br></pre></td></tr></table></figure>\n<p> kustomize kustomize  k8s </p>\n<blockquote>\n<p> taint  yaml  tolerations</p>\n</blockquote>\n"},{"title":"kubernetes  kubeconfig ","date":"2019-01-09T11:28:30.000Z","type":"kubeconfig","_content":"\n kubeconfig  TLS  kubeconfig k8s  kubeconfig  apiserver[client-go ](https://github.com/kubernetes/client-go/blob/master/examples/create-update-delete-deployment/main.go)operatorhelm  kubeconfig  apiserver\n\n## kubeconfig \n\nkubeconfig \n```\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: xxx\n    server: https://xxx:6443\n  name: cluster1\n- cluster:\n    certificate-authority-data: xxx\n    server: https://xxx:6443\n  name: cluster2\ncontexts:\n- context:\n    cluster: cluster1\n    user: kubelet\n  name: cluster1-context\n- context:\n    cluster: cluster2\n    user: kubelet\n  name: cluster2-context\ncurrent-context: cluster1-context\nkind: Config\npreferences: {}\nusers:\n- name: kubelet\n  user:\n    client-certificate-data: xxx\n    client-key-data: xxx\n```\n\napiVersion  kind  preferences  kubectl \n\n#### 1clusters\ncluster kubernetes  kubernetes apiserver  url \n\n `kubectl config set-cluster`  cluster \n\n#### 2users \nuser  kubernetes \n\n `client-certificateclient-keytoken  username/password` \n`username/password`  `token`  `client-certificate`  `client-key` \n\n `kubectl config set-credentials`  user \n\n#### 3contexts \n\ncontext `clusterusernamespace`\n\n\n clusterusernamespace `none` \n\n kubeconfig \n kubeconfig [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/)\n\n`kubectl config set-context`\n\n#### 4current-context \n\ncurrent-context `clusterusernamespace` key\n kubectl \n\n kubectl `--context=CONTEXT--cluster=CLUSTER--user=USER  --namespace=NAMESPACE`\n context  cluster1-context\n```\nkubectl  get node --kubeconfig=./kubeconfig --context=cluster2-context\n```\n `kubectl config use-context`  current-context\n\n#### 5kubectl  kubeconfig \n\nkubectl  kubeconfig\n```\n$ kubectl config set-credentials myself --username=admin --password=secret\n$ kubectl config set-cluster local-server --server=http://localhost:8080\n$ kubectl config set-context default-context --cluster=local-server --user=myself\n$ kubectl config use-context cluster-context\n$ kubectl config set contexts.default-context.namespace the-right-prefix\n$ kubectl config view\n```\n\n kubeconfig  [kubeval](https://github.com/garethr/kubeval) kubernetes yaml  json \n\n##  kubeconfig  kuebctl \n\nkubectl  k8s  kubectl  apiserver (kubeconfig)kubectl  kubeconfig kubectl \n\nkubectl \n1kubectl  8080 \n2 $HOME/.kube  config \n3 KUBECONFIG  kubeconfig \n```\n#  KUBECONFIG \nexport KUBECONFIG=/etc/kubernetes/kubeconfig/kubelet.kubeconfig\n#  kubeconfig \nkubectl get node --kubeconfig=/etc/kubernetes/kubeconfig/kubelet.kubeconfig\n#  context \nkubectl  get node --kubeconfig=./kubeconfig --context=cluster1-context\n```\n\n\n\nhttps://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\nhttps://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\n","source":"_posts/kubeconfig.md","raw":"---\ntitle: kubernetes  kubeconfig \ndate: 2019-01-09 19:28:30\ntags: \"kubeconfig\"\ntype: \"kubeconfig\"\n\n---\n\n kubeconfig  TLS  kubeconfig k8s  kubeconfig  apiserver[client-go ](https://github.com/kubernetes/client-go/blob/master/examples/create-update-delete-deployment/main.go)operatorhelm  kubeconfig  apiserver\n\n## kubeconfig \n\nkubeconfig \n```\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: xxx\n    server: https://xxx:6443\n  name: cluster1\n- cluster:\n    certificate-authority-data: xxx\n    server: https://xxx:6443\n  name: cluster2\ncontexts:\n- context:\n    cluster: cluster1\n    user: kubelet\n  name: cluster1-context\n- context:\n    cluster: cluster2\n    user: kubelet\n  name: cluster2-context\ncurrent-context: cluster1-context\nkind: Config\npreferences: {}\nusers:\n- name: kubelet\n  user:\n    client-certificate-data: xxx\n    client-key-data: xxx\n```\n\napiVersion  kind  preferences  kubectl \n\n#### 1clusters\ncluster kubernetes  kubernetes apiserver  url \n\n `kubectl config set-cluster`  cluster \n\n#### 2users \nuser  kubernetes \n\n `client-certificateclient-keytoken  username/password` \n`username/password`  `token`  `client-certificate`  `client-key` \n\n `kubectl config set-credentials`  user \n\n#### 3contexts \n\ncontext `clusterusernamespace`\n\n\n clusterusernamespace `none` \n\n kubeconfig \n kubeconfig [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/)\n\n`kubectl config set-context`\n\n#### 4current-context \n\ncurrent-context `clusterusernamespace` key\n kubectl \n\n kubectl `--context=CONTEXT--cluster=CLUSTER--user=USER  --namespace=NAMESPACE`\n context  cluster1-context\n```\nkubectl  get node --kubeconfig=./kubeconfig --context=cluster2-context\n```\n `kubectl config use-context`  current-context\n\n#### 5kubectl  kubeconfig \n\nkubectl  kubeconfig\n```\n$ kubectl config set-credentials myself --username=admin --password=secret\n$ kubectl config set-cluster local-server --server=http://localhost:8080\n$ kubectl config set-context default-context --cluster=local-server --user=myself\n$ kubectl config use-context cluster-context\n$ kubectl config set contexts.default-context.namespace the-right-prefix\n$ kubectl config view\n```\n\n kubeconfig  [kubeval](https://github.com/garethr/kubeval) kubernetes yaml  json \n\n##  kubeconfig  kuebctl \n\nkubectl  k8s  kubectl  apiserver (kubeconfig)kubectl  kubeconfig kubectl \n\nkubectl \n1kubectl  8080 \n2 $HOME/.kube  config \n3 KUBECONFIG  kubeconfig \n```\n#  KUBECONFIG \nexport KUBECONFIG=/etc/kubernetes/kubeconfig/kubelet.kubeconfig\n#  kubeconfig \nkubectl get node --kubeconfig=/etc/kubernetes/kubeconfig/kubelet.kubeconfig\n#  context \nkubectl  get node --kubeconfig=./kubeconfig --context=cluster1-context\n```\n\n\n\nhttps://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\nhttps://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\n","slug":"kubeconfig","published":1,"updated":"2019-01-09T11:31:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyysse0009tadv3ryu0o1f","content":"<p> kubeconfig  TLS  kubeconfig k8s  kubeconfig  apiserver<a href=\"https://github.com/kubernetes/client-go/blob/master/examples/create-update-delete-deployment/main.go\" target=\"_blank\" rel=\"noopener\">client-go </a>operatorhelm  kubeconfig  apiserver</p>\n<h2 id=\"kubeconfig-\"><a href=\"#kubeconfig-\" class=\"headerlink\" title=\"kubeconfig \"></a>kubeconfig </h2><p>kubeconfig <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: xxx</span><br><span class=\"line\">    server: https://xxx:6443</span><br><span class=\"line\">  name: cluster1</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: xxx</span><br><span class=\"line\">    server: https://xxx:6443</span><br><span class=\"line\">  name: cluster2</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: cluster1</span><br><span class=\"line\">    user: kubelet</span><br><span class=\"line\">  name: cluster1-context</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: cluster2</span><br><span class=\"line\">    user: kubelet</span><br><span class=\"line\">  name: cluster2-context</span><br><span class=\"line\">current-context: cluster1-context</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: kubelet</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate-data: xxx</span><br><span class=\"line\">    client-key-data: xxx</span><br></pre></td></tr></table></figure></p>\n<p>apiVersion  kind  preferences  kubectl </p>\n<h4 id=\"1clusters\"><a href=\"#1clusters\" class=\"headerlink\" title=\"1clusters\"></a>1clusters</h4><p>cluster kubernetes  kubernetes apiserver  url </p>\n<p> <code>kubectl config set-cluster</code>  cluster </p>\n<h4 id=\"2users-\"><a href=\"#2users-\" class=\"headerlink\" title=\"2users \"></a>2users </h4><p>user  kubernetes </p>\n<p> <code>client-certificateclient-keytoken  username/password</code><br><code>username/password</code>  <code>token</code>  <code>client-certificate</code>  <code>client-key</code> </p>\n<p> <code>kubectl config set-credentials</code>  user </p>\n<h4 id=\"3contexts-\"><a href=\"#3contexts-\" class=\"headerlink\" title=\"3contexts \"></a>3contexts </h4><p>context <code>clusterusernamespace</code></p>\n<p><br> clusterusernamespace <code>none</code> </p>\n<p> kubeconfig <br> kubeconfig <a href=\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\" target=\"_blank\" rel=\"noopener\">kubeconfig</a></p>\n<p><code>kubectl config set-context</code></p>\n<h4 id=\"4current-context-\"><a href=\"#4current-context-\" class=\"headerlink\" title=\"4current-context \"></a>4current-context </h4><p>current-context <code>clusterusernamespace</code> key<br> kubectl </p>\n<p> kubectl <code>--context=CONTEXT--cluster=CLUSTER--user=USER  --namespace=NAMESPACE</code><br> context  cluster1-context<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl  get node --kubeconfig=./kubeconfig --context=cluster2-context</span><br></pre></td></tr></table></figure></p>\n<p> <code>kubectl config use-context</code>  current-context</p>\n<h4 id=\"5kubectl--kubeconfig-\"><a href=\"#5kubectl--kubeconfig-\" class=\"headerlink\" title=\"5kubectl  kubeconfig \"></a>5kubectl  kubeconfig </h4><p>kubectl  kubeconfig<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl config set-credentials myself --username=admin --password=secret</span><br><span class=\"line\">$ kubectl config set-cluster local-server --server=http://localhost:8080</span><br><span class=\"line\">$ kubectl config set-context default-context --cluster=local-server --user=myself</span><br><span class=\"line\">$ kubectl config use-context cluster-context</span><br><span class=\"line\">$ kubectl config set contexts.default-context.namespace the-right-prefix</span><br><span class=\"line\">$ kubectl config view</span><br></pre></td></tr></table></figure></p>\n<p> kubeconfig  <a href=\"https://github.com/garethr/kubeval\" target=\"_blank\" rel=\"noopener\">kubeval</a> kubernetes yaml  json </p>\n<h2 id=\"-kubeconfig--kuebctl-\"><a href=\"#-kubeconfig--kuebctl-\" class=\"headerlink\" title=\" kubeconfig  kuebctl \"></a> kubeconfig  kuebctl </h2><p>kubectl  k8s  kubectl  apiserver (kubeconfig)kubectl  kubeconfig kubectl </p>\n<p>kubectl <br>1kubectl  8080 <br>2 $HOME/.kube  config <br>3 KUBECONFIG  kubeconfig <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  KUBECONFIG </span><br><span class=\"line\">export KUBECONFIG=/etc/kubernetes/kubeconfig/kubelet.kubeconfig</span><br><span class=\"line\">#  kubeconfig </span><br><span class=\"line\">kubectl get node --kubeconfig=/etc/kubernetes/kubeconfig/kubelet.kubeconfig</span><br><span class=\"line\">#  context </span><br><span class=\"line\">kubectl  get node --kubeconfig=./kubeconfig --context=cluster1-context</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<p><br><a href=\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/</a><br><a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p> kubeconfig  TLS  kubeconfig k8s  kubeconfig  apiserver<a href=\"https://github.com/kubernetes/client-go/blob/master/examples/create-update-delete-deployment/main.go\" target=\"_blank\" rel=\"noopener\">client-go </a>operatorhelm  kubeconfig  apiserver</p>\n<h2 id=\"kubeconfig-\"><a href=\"#kubeconfig-\" class=\"headerlink\" title=\"kubeconfig \"></a>kubeconfig </h2><p>kubeconfig <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: xxx</span><br><span class=\"line\">    server: https://xxx:6443</span><br><span class=\"line\">  name: cluster1</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    certificate-authority-data: xxx</span><br><span class=\"line\">    server: https://xxx:6443</span><br><span class=\"line\">  name: cluster2</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: cluster1</span><br><span class=\"line\">    user: kubelet</span><br><span class=\"line\">  name: cluster1-context</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: cluster2</span><br><span class=\"line\">    user: kubelet</span><br><span class=\"line\">  name: cluster2-context</span><br><span class=\"line\">current-context: cluster1-context</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users:</span><br><span class=\"line\">- name: kubelet</span><br><span class=\"line\">  user:</span><br><span class=\"line\">    client-certificate-data: xxx</span><br><span class=\"line\">    client-key-data: xxx</span><br></pre></td></tr></table></figure></p>\n<p>apiVersion  kind  preferences  kubectl </p>\n<h4 id=\"1clusters\"><a href=\"#1clusters\" class=\"headerlink\" title=\"1clusters\"></a>1clusters</h4><p>cluster kubernetes  kubernetes apiserver  url </p>\n<p> <code>kubectl config set-cluster</code>  cluster </p>\n<h4 id=\"2users-\"><a href=\"#2users-\" class=\"headerlink\" title=\"2users \"></a>2users </h4><p>user  kubernetes </p>\n<p> <code>client-certificateclient-keytoken  username/password</code><br><code>username/password</code>  <code>token</code>  <code>client-certificate</code>  <code>client-key</code> </p>\n<p> <code>kubectl config set-credentials</code>  user </p>\n<h4 id=\"3contexts-\"><a href=\"#3contexts-\" class=\"headerlink\" title=\"3contexts \"></a>3contexts </h4><p>context <code>clusterusernamespace</code></p>\n<p><br> clusterusernamespace <code>none</code> </p>\n<p> kubeconfig <br> kubeconfig <a href=\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\" target=\"_blank\" rel=\"noopener\">kubeconfig</a></p>\n<p><code>kubectl config set-context</code></p>\n<h4 id=\"4current-context-\"><a href=\"#4current-context-\" class=\"headerlink\" title=\"4current-context \"></a>4current-context </h4><p>current-context <code>clusterusernamespace</code> key<br> kubectl </p>\n<p> kubectl <code>--context=CONTEXT--cluster=CLUSTER--user=USER  --namespace=NAMESPACE</code><br> context  cluster1-context<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl  get node --kubeconfig=./kubeconfig --context=cluster2-context</span><br></pre></td></tr></table></figure></p>\n<p> <code>kubectl config use-context</code>  current-context</p>\n<h4 id=\"5kubectl--kubeconfig-\"><a href=\"#5kubectl--kubeconfig-\" class=\"headerlink\" title=\"5kubectl  kubeconfig \"></a>5kubectl  kubeconfig </h4><p>kubectl  kubeconfig<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl config set-credentials myself --username=admin --password=secret</span><br><span class=\"line\">$ kubectl config set-cluster local-server --server=http://localhost:8080</span><br><span class=\"line\">$ kubectl config set-context default-context --cluster=local-server --user=myself</span><br><span class=\"line\">$ kubectl config use-context cluster-context</span><br><span class=\"line\">$ kubectl config set contexts.default-context.namespace the-right-prefix</span><br><span class=\"line\">$ kubectl config view</span><br></pre></td></tr></table></figure></p>\n<p> kubeconfig  <a href=\"https://github.com/garethr/kubeval\" target=\"_blank\" rel=\"noopener\">kubeval</a> kubernetes yaml  json </p>\n<h2 id=\"-kubeconfig--kuebctl-\"><a href=\"#-kubeconfig--kuebctl-\" class=\"headerlink\" title=\" kubeconfig  kuebctl \"></a> kubeconfig  kuebctl </h2><p>kubectl  k8s  kubectl  apiserver (kubeconfig)kubectl  kubeconfig kubectl </p>\n<p>kubectl <br>1kubectl  8080 <br>2 $HOME/.kube  config <br>3 KUBECONFIG  kubeconfig <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#  KUBECONFIG </span><br><span class=\"line\">export KUBECONFIG=/etc/kubernetes/kubeconfig/kubelet.kubeconfig</span><br><span class=\"line\">#  kubeconfig </span><br><span class=\"line\">kubectl get node --kubeconfig=/etc/kubernetes/kubeconfig/kubelet.kubeconfig</span><br><span class=\"line\">#  context </span><br><span class=\"line\">kubectl  get node --kubeconfig=./kubeconfig --context=cluster1-context</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<p><br><a href=\"https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/</a><br><a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/</a></p>\n"},{"title":"kubernetes  API","date":"2018-09-02T05:13:00.000Z","type":"kubernetes","_content":"\nkubectl   kube-apisever  API  API kubectl   -v=9   API\n `$ kubectl get node -v=9` \n\n kubernetes  API\n![deployment  API](https://upload-images.jianshu.io/upload_images/1262158-6fdb3babc9522929.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![statefulset  API](https://upload-images.jianshu.io/upload_images/1262158-2562e12aaa019909.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![pod  API](https://upload-images.jianshu.io/upload_images/1262158-d74728f38ba4361e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n![service  API](https://upload-images.jianshu.io/upload_images/1262158-225076f08495b6d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![endpoints  API](https://upload-images.jianshu.io/upload_images/1262158-71c815ad4fc45a65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![namespace  API](https://upload-images.jianshu.io/upload_images/1262158-f79e0c4bb215bb40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![node  API](https://upload-images.jianshu.io/upload_images/1262158-e67546fabc697d13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![pv  API](https://upload-images.jianshu.io/upload_images/1262158-a0eca87df2960565.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n Markdown \n\n","source":"_posts/kubernetes-api.md","raw":"---\ntitle: kubernetes  API\ndate: 2018-09-02 13:13:00\ntype: \"kubernetes\"\n\n---\n\nkubectl   kube-apisever  API  API kubectl   -v=9   API\n `$ kubectl get node -v=9` \n\n kubernetes  API\n![deployment  API](https://upload-images.jianshu.io/upload_images/1262158-6fdb3babc9522929.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![statefulset  API](https://upload-images.jianshu.io/upload_images/1262158-2562e12aaa019909.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![pod  API](https://upload-images.jianshu.io/upload_images/1262158-d74728f38ba4361e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n![service  API](https://upload-images.jianshu.io/upload_images/1262158-225076f08495b6d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![endpoints  API](https://upload-images.jianshu.io/upload_images/1262158-71c815ad4fc45a65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![namespace  API](https://upload-images.jianshu.io/upload_images/1262158-f79e0c4bb215bb40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![node  API](https://upload-images.jianshu.io/upload_images/1262158-e67546fabc697d13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n![pv  API](https://upload-images.jianshu.io/upload_images/1262158-a0eca87df2960565.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n Markdown \n\n","slug":"kubernetes-api","published":1,"updated":"2018-12-08T10:35:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyssf000atadvchvvyj56","content":"<p>kubectl   kube-apisever  API  API kubectl   -v=9   API<br> <code>$ kubectl get node -v=9</code> </p>\n<p> kubernetes  API<br><img src=\"https://upload-images.jianshu.io/upload_images/1262158-6fdb3babc9522929.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"deployment  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-2562e12aaa019909.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"statefulset  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-d74728f38ba4361e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"pod  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-225076f08495b6d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"service  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-71c815ad4fc45a65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"endpoints  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-f79e0c4bb215bb40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"namespace  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-e67546fabc697d13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"node  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-a0eca87df2960565.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"pv  API\"></p>\n<p> Markdown </p>\n","site":{"data":{}},"excerpt":"","more":"<p>kubectl   kube-apisever  API  API kubectl   -v=9   API<br> <code>$ kubectl get node -v=9</code> </p>\n<p> kubernetes  API<br><img src=\"https://upload-images.jianshu.io/upload_images/1262158-6fdb3babc9522929.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"deployment  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-2562e12aaa019909.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"statefulset  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-d74728f38ba4361e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"pod  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-225076f08495b6d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"service  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-71c815ad4fc45a65.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"endpoints  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-f79e0c4bb215bb40.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"namespace  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-e67546fabc697d13.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"node  API\"></p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-a0eca87df2960565.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"pv  API\"></p>\n<p> Markdown </p>\n"},{"title":"etcd  https","date":"2017-03-15T13:32:00.000Z","type":"etcd","_content":"* 1  TLS \n* 2\n* 3 etcd \n* 4 etcd \n* 5 kube-apiserver  CA  etcd\n* 6 kube-apiserver\n* 7\n\nSSL/TSL \n\n kubernetes  IP  CA  IP  CA \n\n[Generate self-signed certificates ](https://coreos.com/os/docs/latest/generate-self-signed-certificates.html)\n\n cfssl  CA  OpenSSL  [easy-rsa](https://github.com/OpenVPN/easy-rsa)\n\n## 1  TLS \n\n\n\n* 1 cfssl\n* 2\n* 3 CA \n* 4\n* 5\n* 6\n\n HTTPS \n\n* [HTTPSSSL/TLS](http://www.techug.com/post/https-ssl-tls.html)\n* [CA](http://blog.jobbole.com/104919/)\n* [OpenSSL](https://mritd.me/2016/07/02/%E4%BA%92%E8%81%94%E7%BD%91%E5%8A%A0%E5%AF%86%E5%8F%8AOpenSSL%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8)\n* [SSL](http://www.cnblogs.com/Michael-Kong/archive/2012/08/16/SSL%E8%AF%81%E4%B9%A6%E5%8E%9F%E7%90%86.html)\n\n##### 1 cfssl\n\n    mkdir ~/bin\n    curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64\n    curl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64\n    chmod +x ~/bin/{cfssl,cfssljson}\n    export PATH=$PATH:~/bin\n\n##### 2\n\n```\nmkdir ~/cfssl\ncd ~/cfssl\ncfssl print-defaults config > ca-config.json\ncfssl print-defaults csr > ca-csr.json\n```\n\n\n\n* client certificate  etcdctletcd proxyfleetctldocker\n* server certificate dockerkube-apiserver\n* peer certificate  etcd \n\n##### 3 CA \n\n```\n$ cat << EOF > ca-config.json\n\n{\n    \"signing\": {\n        \"default\": {\n            \"expiry\": \"43800h\"\n        },\n        \"profiles\": {\n            \"server\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\"\n                ]\n            },\n            \"client\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"client auth\"\n                ]\n            },\n            \"peer\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\",\n                    \"client auth\"\n                ]\n            }\n        }\n    }\n}\n\n$ cat << EOF > ca-csr.json\n\n{\n    \"CN\": \"My own CA\",\n    \"key\": {\n        \"algo\": \"rsa\",\n        \"size\": 2048\n    },\n    \"names\": [\n        {\n            \"C\": \"US\",\n            \"L\": \"CA\",\n            \"O\": \"My Company Name\",\n            \"ST\": \"San Francisco\",\n            \"OU\": \"Org Unit 1\",\n            \"OU\": \"Org Unit 2\"\n        }\n    ]\n}\n\n CA \n\n$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca -\n\n\n\nca-key.pem\nca.csr\nca.pem\n\n```\n>  ca-key.pem *.csr \n\n##### 4\n```\n$ echo '{\"CN\":\"coreos1\",\"hosts\":[\"10.93.81.17\",\"127.0.0.1\"],\"key\":{\"algo\":\"rsa\",\"size\":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server -hostname=\"10.93.81.17,127.0.0.1,server\" - | cfssljson -bare server\n\nhosts \n\n\nserver-key.pem\nserver.csr\nserver.pem\n```\n\n##### 5\n```\n$ echo '{\"CN\":\"member1\",\"hosts\":[\"10.93.81.17\",\"127.0.0.1\"],\"key\":{\"algo\":\"rsa\",\"size\":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer -hostname=\"10.93.81.17,127.0.0.1,server,member1\" - | cfssljson -bare member1\n\nhosts \n\n\n\nmember1-key.pem\nmember1.csr\nmember1.pem\n\n etcd \n\n```\n\n##### 6\n\n```\n$ echo '{\"CN\":\"client\",\"hosts\":[\"10.93.81.17\",\"127.0.0.1\"],\"key\":{\"algo\":\"rsa\",\"size\":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client - | cfssljson -bare client\n\nhosts \n\n\n\nclient-key.pem\nclient.csr\nclient.pem\n\n```\n\n\n\n## 2\n* 1\n* 2\n\n##### 1\n\n\n```\n$ mkdir -pv /etc/ssl/etcd/\n$ cp ~/cfssl/* /etc/ssl/etcd/\n$ chown -R etcd:etcd /etc/ssl/etcd\n$ chmod 600 /etc/ssl/etcd/*-key.pem\n$ cp ~/cfssl/ca.pem /etc/ssl/certs/\n```\n\n##### 2\n\n```\n$ yum install ca-certificates -y\n     \n$ update-ca-trust\n        \n```\n\n## 3 etcd \n\n```\n$ etcdctl version\netcdctl version: 3.1.3\nAPI version: 3.1\n\n$ cat  /etc/etcd/etcd.conf\n\nETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"\n#URL\nETCD_LISTEN_PEER_URLS=\"https://10.93.81.17:2380\"\n\n#URL, URL\nETCD_LISTEN_CLIENT_URLS=\"https://10.93.81.17:2379,https://10.93.81.17:4001\"\n\n#\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"https://10.93.81.17:2380\"\n\n#advertise-client-urls URL, URLtcp2379\nETCD_ADVERTISE_CLIENT_URLS=\"https://10.93.81.17:2379\"\n\n#\nETCD_NAME=\"node1\"\nETCD_INITIAL_CLUSTER=\"node1=https://10.93.81.17:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\n\n#[security]\n\nETCD_CERT_FILE=\"/etc/ssl/etcd/server.pem\"\nETCD_KEY_FILE=\"/etc/ssl/etcd/server-key.pem\"\nETCD_TRUSTED_CA_FILE=\"/etc/ssl/etcd/ca.pem\"\nETCD_CLIENT_CERT_AUTH=\"true\"\nETCD_PEER_CERT_FILE=\"/etc/ssl/etcd/member1.pem\"\nETCD_PEER_KEY_FILE=\"/etc/ssl/etcd/member1-key.pem\"\nETCD_PEER_TRUSTED_CA_FILE=\"/etc/ssl/etcd/ca.pem\"\nETCD_PEER_CLIENT_CERT_AUTH=\"true\"\n#[logging]\nETCD_DEBUG=\"true\"\nETCD_LOG_PACKAGE_LEVELS=\"etcdserver=WARNING,security=DEBUG\"\n```\n\n\n## 4 etcd \n\n```\n$ systemctl restart  etcd\n\n journalctl -f -t etcd  journalctl -u etcd \n\n$ curl --cacert /etc/ssl/etcd/ca.pem --cert /etc/ssl/etcd/client.pem --key /etc/ssl/etcd/client-key.pem https://10.93.81.17:2379/health\n{\"health\": \"true\"}\n\n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list\n     \n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem put /foo/bar  \"hello world\"\n     \n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem get /foo/bar\n```\n\n## 5 kube-apiserver  CA  etcd\n\n```\n$ cp /etc/ssl/etcd/*  /var/run/kubernetes/\n    \n$ chown  -R kube.kube /var/run/kubernetes/\n\n /etc/kubernetes/apiserver  KUBE_API_ARGS \n\n--cert-dir='/var/run/kubernetes/' --etcd-cafile='/var/run/kubernetes/ca.pem' --etcd-certfile='/var/run/kubernetes/client.pem' --etcd-keyfile='/var/run/kubernetes/client-key.pem'\n\n\n```\n\n## 6 kube-apiserver \n\n```\n$ systemctl restart kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy\n\n$ systemctl status -l kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy\n\n$ kubectl get node\n\n$ kubectl get cs\nNAME                 STATUS      MESSAGE                                                                   ERROR\nscheduler            Healthy     ok\ncontroller-manager   Healthy     ok\netcd-0               Unhealthy   Get https://10.93.81.17:2379/health: remote error: tls: bad certificate\n\n$ ./version.sh\netcdctl version: 3.1.3\nAPI version: 3.1\nKubernetes v1.6.0-beta.1\n\n```\n\n## 7\n\n##### 1  `kubectl get cs `  \n```\netcd-0 Unhealthy Get https://10.93.81.17:2379/health: remote error: tls: bad certificate\n```\n pr  merge[etcd component status check should include credentials](https://github.com/kubernetes/kubernetes/pull/39716)\n\n##### 2 2380 \n```\n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list  \n\n2017-03-15 15:02:05.611564 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated\n145b401ad8709f51, started, node1, http://10.93.81.17:2380, https://10.93.81.17:2379\n```\n\n\n\n* [kubernetes + etcd ssl ](https://www.addops.cn/post/tls-for-kubernetes-etcd.html)\n* [Security model](https://coreos.com/etcd/docs/latest/op-guide/security.html)\n* [Enabling HTTPS in an existing etcd cluster](https://coreos.com/etcd/docs/latest/etcd-live-http-to-https-migration.html)\n","source":"_posts/etcd-enable-https.md","raw":"---\ntitle: etcd  https\ndate: 2017-03-15 21:32:00\ntype: \"etcd\"\n\n---\n* 1  TLS \n* 2\n* 3 etcd \n* 4 etcd \n* 5 kube-apiserver  CA  etcd\n* 6 kube-apiserver\n* 7\n\nSSL/TSL \n\n kubernetes  IP  CA  IP  CA \n\n[Generate self-signed certificates ](https://coreos.com/os/docs/latest/generate-self-signed-certificates.html)\n\n cfssl  CA  OpenSSL  [easy-rsa](https://github.com/OpenVPN/easy-rsa)\n\n## 1  TLS \n\n\n\n* 1 cfssl\n* 2\n* 3 CA \n* 4\n* 5\n* 6\n\n HTTPS \n\n* [HTTPSSSL/TLS](http://www.techug.com/post/https-ssl-tls.html)\n* [CA](http://blog.jobbole.com/104919/)\n* [OpenSSL](https://mritd.me/2016/07/02/%E4%BA%92%E8%81%94%E7%BD%91%E5%8A%A0%E5%AF%86%E5%8F%8AOpenSSL%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8)\n* [SSL](http://www.cnblogs.com/Michael-Kong/archive/2012/08/16/SSL%E8%AF%81%E4%B9%A6%E5%8E%9F%E7%90%86.html)\n\n##### 1 cfssl\n\n    mkdir ~/bin\n    curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64\n    curl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64\n    chmod +x ~/bin/{cfssl,cfssljson}\n    export PATH=$PATH:~/bin\n\n##### 2\n\n```\nmkdir ~/cfssl\ncd ~/cfssl\ncfssl print-defaults config > ca-config.json\ncfssl print-defaults csr > ca-csr.json\n```\n\n\n\n* client certificate  etcdctletcd proxyfleetctldocker\n* server certificate dockerkube-apiserver\n* peer certificate  etcd \n\n##### 3 CA \n\n```\n$ cat << EOF > ca-config.json\n\n{\n    \"signing\": {\n        \"default\": {\n            \"expiry\": \"43800h\"\n        },\n        \"profiles\": {\n            \"server\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\"\n                ]\n            },\n            \"client\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"client auth\"\n                ]\n            },\n            \"peer\": {\n                \"expiry\": \"43800h\",\n                \"usages\": [\n                    \"signing\",\n                    \"key encipherment\",\n                    \"server auth\",\n                    \"client auth\"\n                ]\n            }\n        }\n    }\n}\n\n$ cat << EOF > ca-csr.json\n\n{\n    \"CN\": \"My own CA\",\n    \"key\": {\n        \"algo\": \"rsa\",\n        \"size\": 2048\n    },\n    \"names\": [\n        {\n            \"C\": \"US\",\n            \"L\": \"CA\",\n            \"O\": \"My Company Name\",\n            \"ST\": \"San Francisco\",\n            \"OU\": \"Org Unit 1\",\n            \"OU\": \"Org Unit 2\"\n        }\n    ]\n}\n\n CA \n\n$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca -\n\n\n\nca-key.pem\nca.csr\nca.pem\n\n```\n>  ca-key.pem *.csr \n\n##### 4\n```\n$ echo '{\"CN\":\"coreos1\",\"hosts\":[\"10.93.81.17\",\"127.0.0.1\"],\"key\":{\"algo\":\"rsa\",\"size\":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server -hostname=\"10.93.81.17,127.0.0.1,server\" - | cfssljson -bare server\n\nhosts \n\n\nserver-key.pem\nserver.csr\nserver.pem\n```\n\n##### 5\n```\n$ echo '{\"CN\":\"member1\",\"hosts\":[\"10.93.81.17\",\"127.0.0.1\"],\"key\":{\"algo\":\"rsa\",\"size\":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer -hostname=\"10.93.81.17,127.0.0.1,server,member1\" - | cfssljson -bare member1\n\nhosts \n\n\n\nmember1-key.pem\nmember1.csr\nmember1.pem\n\n etcd \n\n```\n\n##### 6\n\n```\n$ echo '{\"CN\":\"client\",\"hosts\":[\"10.93.81.17\",\"127.0.0.1\"],\"key\":{\"algo\":\"rsa\",\"size\":2048}}' | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client - | cfssljson -bare client\n\nhosts \n\n\n\nclient-key.pem\nclient.csr\nclient.pem\n\n```\n\n\n\n## 2\n* 1\n* 2\n\n##### 1\n\n\n```\n$ mkdir -pv /etc/ssl/etcd/\n$ cp ~/cfssl/* /etc/ssl/etcd/\n$ chown -R etcd:etcd /etc/ssl/etcd\n$ chmod 600 /etc/ssl/etcd/*-key.pem\n$ cp ~/cfssl/ca.pem /etc/ssl/certs/\n```\n\n##### 2\n\n```\n$ yum install ca-certificates -y\n     \n$ update-ca-trust\n        \n```\n\n## 3 etcd \n\n```\n$ etcdctl version\netcdctl version: 3.1.3\nAPI version: 3.1\n\n$ cat  /etc/etcd/etcd.conf\n\nETCD_DATA_DIR=\"/var/lib/etcd/default.etcd\"\n#URL\nETCD_LISTEN_PEER_URLS=\"https://10.93.81.17:2380\"\n\n#URL, URL\nETCD_LISTEN_CLIENT_URLS=\"https://10.93.81.17:2379,https://10.93.81.17:4001\"\n\n#\nETCD_INITIAL_ADVERTISE_PEER_URLS=\"https://10.93.81.17:2380\"\n\n#advertise-client-urls URL, URLtcp2379\nETCD_ADVERTISE_CLIENT_URLS=\"https://10.93.81.17:2379\"\n\n#\nETCD_NAME=\"node1\"\nETCD_INITIAL_CLUSTER=\"node1=https://10.93.81.17:2380\"\nETCD_INITIAL_CLUSTER_STATE=\"new\"\n\n#[security]\n\nETCD_CERT_FILE=\"/etc/ssl/etcd/server.pem\"\nETCD_KEY_FILE=\"/etc/ssl/etcd/server-key.pem\"\nETCD_TRUSTED_CA_FILE=\"/etc/ssl/etcd/ca.pem\"\nETCD_CLIENT_CERT_AUTH=\"true\"\nETCD_PEER_CERT_FILE=\"/etc/ssl/etcd/member1.pem\"\nETCD_PEER_KEY_FILE=\"/etc/ssl/etcd/member1-key.pem\"\nETCD_PEER_TRUSTED_CA_FILE=\"/etc/ssl/etcd/ca.pem\"\nETCD_PEER_CLIENT_CERT_AUTH=\"true\"\n#[logging]\nETCD_DEBUG=\"true\"\nETCD_LOG_PACKAGE_LEVELS=\"etcdserver=WARNING,security=DEBUG\"\n```\n\n\n## 4 etcd \n\n```\n$ systemctl restart  etcd\n\n journalctl -f -t etcd  journalctl -u etcd \n\n$ curl --cacert /etc/ssl/etcd/ca.pem --cert /etc/ssl/etcd/client.pem --key /etc/ssl/etcd/client-key.pem https://10.93.81.17:2379/health\n{\"health\": \"true\"}\n\n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list\n     \n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem put /foo/bar  \"hello world\"\n     \n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem get /foo/bar\n```\n\n## 5 kube-apiserver  CA  etcd\n\n```\n$ cp /etc/ssl/etcd/*  /var/run/kubernetes/\n    \n$ chown  -R kube.kube /var/run/kubernetes/\n\n /etc/kubernetes/apiserver  KUBE_API_ARGS \n\n--cert-dir='/var/run/kubernetes/' --etcd-cafile='/var/run/kubernetes/ca.pem' --etcd-certfile='/var/run/kubernetes/client.pem' --etcd-keyfile='/var/run/kubernetes/client-key.pem'\n\n\n```\n\n## 6 kube-apiserver \n\n```\n$ systemctl restart kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy\n\n$ systemctl status -l kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy\n\n$ kubectl get node\n\n$ kubectl get cs\nNAME                 STATUS      MESSAGE                                                                   ERROR\nscheduler            Healthy     ok\ncontroller-manager   Healthy     ok\netcd-0               Unhealthy   Get https://10.93.81.17:2379/health: remote error: tls: bad certificate\n\n$ ./version.sh\netcdctl version: 3.1.3\nAPI version: 3.1\nKubernetes v1.6.0-beta.1\n\n```\n\n## 7\n\n##### 1  `kubectl get cs `  \n```\netcd-0 Unhealthy Get https://10.93.81.17:2379/health: remote error: tls: bad certificate\n```\n pr  merge[etcd component status check should include credentials](https://github.com/kubernetes/kubernetes/pull/39716)\n\n##### 2 2380 \n```\n$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list  \n\n2017-03-15 15:02:05.611564 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated\n145b401ad8709f51, started, node1, http://10.93.81.17:2380, https://10.93.81.17:2379\n```\n\n\n\n* [kubernetes + etcd ssl ](https://www.addops.cn/post/tls-for-kubernetes-etcd.html)\n* [Security model](https://coreos.com/etcd/docs/latest/op-guide/security.html)\n* [Enabling HTTPS in an existing etcd cluster](https://coreos.com/etcd/docs/latest/etcd-live-http-to-https-migration.html)\n","slug":"etcd-enable-https","published":1,"updated":"2018-12-08T10:33:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyysyg000mtadv7hbfx2p5","content":"<ul>\n<li>1  TLS </li>\n<li>2</li>\n<li>3 etcd </li>\n<li>4 etcd </li>\n<li>5 kube-apiserver  CA  etcd</li>\n<li>6 kube-apiserver</li>\n<li>7</li>\n</ul>\n<p>SSL/TSL </p>\n<p> kubernetes  IP  CA  IP  CA </p>\n<p><a href=\"https://coreos.com/os/docs/latest/generate-self-signed-certificates.html\" target=\"_blank\" rel=\"noopener\">Generate self-signed certificates </a></p>\n<p> cfssl  CA  OpenSSL  <a href=\"https://github.com/OpenVPN/easy-rsa\" target=\"_blank\" rel=\"noopener\">easy-rsa</a></p>\n<h2 id=\"1--TLS-\"><a href=\"#1--TLS-\" class=\"headerlink\" title=\"1  TLS \"></a>1  TLS </h2><p></p>\n<ul>\n<li>1 cfssl</li>\n<li>2</li>\n<li>3 CA </li>\n<li>4</li>\n<li>5</li>\n<li>6</li>\n</ul>\n<p> HTTPS </p>\n<ul>\n<li><a href=\"http://www.techug.com/post/https-ssl-tls.html\" target=\"_blank\" rel=\"noopener\">HTTPSSSL/TLS</a></li>\n<li><a href=\"http://blog.jobbole.com/104919/\" target=\"_blank\" rel=\"noopener\">CA</a></li>\n<li><a href=\"https://mritd.me/2016/07/02/%E4%BA%92%E8%81%94%E7%BD%91%E5%8A%A0%E5%AF%86%E5%8F%8AOpenSSL%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8\" target=\"_blank\" rel=\"noopener\">OpenSSL</a></li>\n<li><a href=\"http://www.cnblogs.com/Michael-Kong/archive/2012/08/16/SSL%E8%AF%81%E4%B9%A6%E5%8E%9F%E7%90%86.html\" target=\"_blank\" rel=\"noopener\">SSL</a></li>\n</ul>\n<h5 id=\"1-cfssl\"><a href=\"#1-cfssl\" class=\"headerlink\" title=\"1 cfssl\"></a>1 cfssl</h5><pre><code>mkdir ~/bin\ncurl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64\ncurl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64\nchmod +x ~/bin/{cfssl,cfssljson}\nexport PATH=$PATH:~/bin\n</code></pre><h5 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir ~/cfssl</span><br><span class=\"line\">cd ~/cfssl</span><br><span class=\"line\">cfssl print-defaults config &gt; ca-config.json</span><br><span class=\"line\">cfssl print-defaults csr &gt; ca-csr.json</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>client certificate  etcdctletcd proxyfleetctldocker</li>\n<li>server certificate dockerkube-apiserver</li>\n<li>peer certificate  etcd </li>\n</ul>\n<h5 id=\"3-CA-\"><a href=\"#3-CA-\" class=\"headerlink\" title=\"3 CA \"></a>3 CA </h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat &lt;&lt; EOF &gt; ca-config.json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;signing&quot;: &#123;</span><br><span class=\"line\">        &quot;default&quot;: &#123;</span><br><span class=\"line\">            &quot;expiry&quot;: &quot;43800h&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;profiles&quot;: &#123;</span><br><span class=\"line\">            &quot;server&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;client&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;peer&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat &lt;&lt; EOF &gt; ca-csr.json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;My own CA&quot;,</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 2048</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;US&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;CA&quot;,</span><br><span class=\"line\">            &quot;O&quot;: &quot;My Company Name&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;San Francisco&quot;,</span><br><span class=\"line\">            &quot;OU&quot;: &quot;Org Unit 1&quot;,</span><br><span class=\"line\">            &quot;OU&quot;: &quot;Org Unit 2&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> CA </span><br><span class=\"line\"></span><br><span class=\"line\">$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">ca-key.pem</span><br><span class=\"line\">ca.csr</span><br><span class=\"line\">ca.pem</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p> ca-key.pem *.csr </p>\n</blockquote>\n<h5 id=\"4\"><a href=\"#4\" class=\"headerlink\" title=\"4\"></a>4</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &apos;&#123;&quot;CN&quot;:&quot;coreos1&quot;,&quot;hosts&quot;:[&quot;10.93.81.17&quot;,&quot;127.0.0.1&quot;],&quot;key&quot;:&#123;&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048&#125;&#125;&apos; | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server -hostname=&quot;10.93.81.17,127.0.0.1,server&quot; - | cfssljson -bare server</span><br><span class=\"line\"></span><br><span class=\"line\">hosts </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">server-key.pem</span><br><span class=\"line\">server.csr</span><br><span class=\"line\">server.pem</span><br></pre></td></tr></table></figure>\n<h5 id=\"5\"><a href=\"#5\" class=\"headerlink\" title=\"5\"></a>5</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &apos;&#123;&quot;CN&quot;:&quot;member1&quot;,&quot;hosts&quot;:[&quot;10.93.81.17&quot;,&quot;127.0.0.1&quot;],&quot;key&quot;:&#123;&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048&#125;&#125;&apos; | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer -hostname=&quot;10.93.81.17,127.0.0.1,server,member1&quot; - | cfssljson -bare member1</span><br><span class=\"line\"></span><br><span class=\"line\">hosts </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">member1-key.pem</span><br><span class=\"line\">member1.csr</span><br><span class=\"line\">member1.pem</span><br><span class=\"line\"></span><br><span class=\"line\"> etcd </span><br></pre></td></tr></table></figure>\n<h5 id=\"6\"><a href=\"#6\" class=\"headerlink\" title=\"6\"></a>6</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &apos;&#123;&quot;CN&quot;:&quot;client&quot;,&quot;hosts&quot;:[&quot;10.93.81.17&quot;,&quot;127.0.0.1&quot;],&quot;key&quot;:&#123;&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048&#125;&#125;&apos; | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client - | cfssljson -bare client</span><br><span class=\"line\"></span><br><span class=\"line\">hosts </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">client-key.pem</span><br><span class=\"line\">client.csr</span><br><span class=\"line\">client.pem</span><br></pre></td></tr></table></figure>\n<p></p>\n<h2 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h2><ul>\n<li>1</li>\n<li>2</li>\n</ul>\n<h5 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -pv /etc/ssl/etcd/</span><br><span class=\"line\">$ cp ~/cfssl/* /etc/ssl/etcd/</span><br><span class=\"line\">$ chown -R etcd:etcd /etc/ssl/etcd</span><br><span class=\"line\">$ chmod 600 /etc/ssl/etcd/*-key.pem</span><br><span class=\"line\">$ cp ~/cfssl/ca.pem /etc/ssl/certs/</span><br></pre></td></tr></table></figure>\n<h5 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install ca-certificates -y</span><br><span class=\"line\">     </span><br><span class=\"line\">$ update-ca-trust</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-etcd-\"><a href=\"#3-etcd-\" class=\"headerlink\" title=\"3 etcd \"></a>3 etcd </h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ etcdctl version</span><br><span class=\"line\">etcdctl version: 3.1.3</span><br><span class=\"line\">API version: 3.1</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat  /etc/etcd/etcd.conf</span><br><span class=\"line\"></span><br><span class=\"line\">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</span><br><span class=\"line\">#URL</span><br><span class=\"line\">ETCD_LISTEN_PEER_URLS=&quot;https://10.93.81.17:2380&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#URL, URL</span><br><span class=\"line\">ETCD_LISTEN_CLIENT_URLS=&quot;https://10.93.81.17:2379,https://10.93.81.17:4001&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://10.93.81.17:2380&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#advertise-client-urls URL, URLtcp2379</span><br><span class=\"line\">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://10.93.81.17:2379&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">ETCD_NAME=&quot;node1&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER=&quot;node1=https://10.93.81.17:2380&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#[security]</span><br><span class=\"line\"></span><br><span class=\"line\">ETCD_CERT_FILE=&quot;/etc/ssl/etcd/server.pem&quot;</span><br><span class=\"line\">ETCD_KEY_FILE=&quot;/etc/ssl/etcd/server-key.pem&quot;</span><br><span class=\"line\">ETCD_TRUSTED_CA_FILE=&quot;/etc/ssl/etcd/ca.pem&quot;</span><br><span class=\"line\">ETCD_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class=\"line\">ETCD_PEER_CERT_FILE=&quot;/etc/ssl/etcd/member1.pem&quot;</span><br><span class=\"line\">ETCD_PEER_KEY_FILE=&quot;/etc/ssl/etcd/member1-key.pem&quot;</span><br><span class=\"line\">ETCD_PEER_TRUSTED_CA_FILE=&quot;/etc/ssl/etcd/ca.pem&quot;</span><br><span class=\"line\">ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class=\"line\">#[logging]</span><br><span class=\"line\">ETCD_DEBUG=&quot;true&quot;</span><br><span class=\"line\">ETCD_LOG_PACKAGE_LEVELS=&quot;etcdserver=WARNING,security=DEBUG&quot;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-etcd-\"><a href=\"#4-etcd-\" class=\"headerlink\" title=\"4 etcd \"></a>4 etcd </h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl restart  etcd</span><br><span class=\"line\"></span><br><span class=\"line\"> journalctl -f -t etcd  journalctl -u etcd </span><br><span class=\"line\"></span><br><span class=\"line\">$ curl --cacert /etc/ssl/etcd/ca.pem --cert /etc/ssl/etcd/client.pem --key /etc/ssl/etcd/client-key.pem https://10.93.81.17:2379/health</span><br><span class=\"line\">&#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list</span><br><span class=\"line\">     </span><br><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem put /foo/bar  &quot;hello world&quot;</span><br><span class=\"line\">     </span><br><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem get /foo/bar</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-kube-apiserver--CA--etcd\"><a href=\"#5-kube-apiserver--CA--etcd\" class=\"headerlink\" title=\"5 kube-apiserver  CA  etcd\"></a>5 kube-apiserver  CA  etcd</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cp /etc/ssl/etcd/*  /var/run/kubernetes/</span><br><span class=\"line\">    </span><br><span class=\"line\">$ chown  -R kube.kube /var/run/kubernetes/</span><br><span class=\"line\"></span><br><span class=\"line\"> /etc/kubernetes/apiserver  KUBE_API_ARGS </span><br><span class=\"line\"></span><br><span class=\"line\">--cert-dir=&apos;/var/run/kubernetes/&apos; --etcd-cafile=&apos;/var/run/kubernetes/ca.pem&apos; --etcd-certfile=&apos;/var/run/kubernetes/client.pem&apos; --etcd-keyfile=&apos;/var/run/kubernetes/client-key.pem&apos;</span><br></pre></td></tr></table></figure>\n<h2 id=\"6-kube-apiserver\"><a href=\"#6-kube-apiserver\" class=\"headerlink\" title=\"6 kube-apiserver\"></a>6 kube-apiserver</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl restart kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">$ systemctl status -l kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get node</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get cs</span><br><span class=\"line\">NAME                 STATUS      MESSAGE                                                                   ERROR</span><br><span class=\"line\">scheduler            Healthy     ok</span><br><span class=\"line\">controller-manager   Healthy     ok</span><br><span class=\"line\">etcd-0               Unhealthy   Get https://10.93.81.17:2379/health: remote error: tls: bad certificate</span><br><span class=\"line\"></span><br><span class=\"line\">$ ./version.sh</span><br><span class=\"line\">etcdctl version: 3.1.3</span><br><span class=\"line\">API version: 3.1</span><br><span class=\"line\">Kubernetes v1.6.0-beta.1</span><br></pre></td></tr></table></figure>\n<h2 id=\"7\"><a href=\"#7\" class=\"headerlink\" title=\"7\"></a>7</h2><h5 id=\"1-kubectl-get-cs-\"><a href=\"#1-kubectl-get-cs-\" class=\"headerlink\" title=\"1  kubectl get cs \"></a>1  <code>kubectl get cs</code> </h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcd-0 Unhealthy Get https://10.93.81.17:2379/health: remote error: tls: bad certificate</span><br></pre></td></tr></table></figure>\n<p> pr  merge<a href=\"https://github.com/kubernetes/kubernetes/pull/39716\" target=\"_blank\" rel=\"noopener\">etcd component status check should include credentials</a></p>\n<h5 id=\"2-2380-\"><a href=\"#2-2380-\" class=\"headerlink\" title=\"2 2380 \"></a>2 2380 </h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list  </span><br><span class=\"line\"></span><br><span class=\"line\">2017-03-15 15:02:05.611564 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</span><br><span class=\"line\">145b401ad8709f51, started, node1, http://10.93.81.17:2380, https://10.93.81.17:2379</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><a href=\"https://www.addops.cn/post/tls-for-kubernetes-etcd.html\" target=\"_blank\" rel=\"noopener\">kubernetes + etcd ssl </a></li>\n<li><a href=\"https://coreos.com/etcd/docs/latest/op-guide/security.html\" target=\"_blank\" rel=\"noopener\">Security model</a></li>\n<li><a href=\"https://coreos.com/etcd/docs/latest/etcd-live-http-to-https-migration.html\" target=\"_blank\" rel=\"noopener\">Enabling HTTPS in an existing etcd cluster</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>1  TLS </li>\n<li>2</li>\n<li>3 etcd </li>\n<li>4 etcd </li>\n<li>5 kube-apiserver  CA  etcd</li>\n<li>6 kube-apiserver</li>\n<li>7</li>\n</ul>\n<p>SSL/TSL </p>\n<p> kubernetes  IP  CA  IP  CA </p>\n<p><a href=\"https://coreos.com/os/docs/latest/generate-self-signed-certificates.html\" target=\"_blank\" rel=\"noopener\">Generate self-signed certificates </a></p>\n<p> cfssl  CA  OpenSSL  <a href=\"https://github.com/OpenVPN/easy-rsa\" target=\"_blank\" rel=\"noopener\">easy-rsa</a></p>\n<h2 id=\"1--TLS-\"><a href=\"#1--TLS-\" class=\"headerlink\" title=\"1  TLS \"></a>1  TLS </h2><p></p>\n<ul>\n<li>1 cfssl</li>\n<li>2</li>\n<li>3 CA </li>\n<li>4</li>\n<li>5</li>\n<li>6</li>\n</ul>\n<p> HTTPS </p>\n<ul>\n<li><a href=\"http://www.techug.com/post/https-ssl-tls.html\" target=\"_blank\" rel=\"noopener\">HTTPSSSL/TLS</a></li>\n<li><a href=\"http://blog.jobbole.com/104919/\" target=\"_blank\" rel=\"noopener\">CA</a></li>\n<li><a href=\"https://mritd.me/2016/07/02/%E4%BA%92%E8%81%94%E7%BD%91%E5%8A%A0%E5%AF%86%E5%8F%8AOpenSSL%E4%BB%8B%E7%BB%8D%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8\" target=\"_blank\" rel=\"noopener\">OpenSSL</a></li>\n<li><a href=\"http://www.cnblogs.com/Michael-Kong/archive/2012/08/16/SSL%E8%AF%81%E4%B9%A6%E5%8E%9F%E7%90%86.html\" target=\"_blank\" rel=\"noopener\">SSL</a></li>\n</ul>\n<h5 id=\"1-cfssl\"><a href=\"#1-cfssl\" class=\"headerlink\" title=\"1 cfssl\"></a>1 cfssl</h5><pre><code>mkdir ~/bin\ncurl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64\ncurl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64\nchmod +x ~/bin/{cfssl,cfssljson}\nexport PATH=$PATH:~/bin\n</code></pre><h5 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir ~/cfssl</span><br><span class=\"line\">cd ~/cfssl</span><br><span class=\"line\">cfssl print-defaults config &gt; ca-config.json</span><br><span class=\"line\">cfssl print-defaults csr &gt; ca-csr.json</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>client certificate  etcdctletcd proxyfleetctldocker</li>\n<li>server certificate dockerkube-apiserver</li>\n<li>peer certificate  etcd </li>\n</ul>\n<h5 id=\"3-CA-\"><a href=\"#3-CA-\" class=\"headerlink\" title=\"3 CA \"></a>3 CA </h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat &lt;&lt; EOF &gt; ca-config.json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;signing&quot;: &#123;</span><br><span class=\"line\">        &quot;default&quot;: &#123;</span><br><span class=\"line\">            &quot;expiry&quot;: &quot;43800h&quot;</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        &quot;profiles&quot;: &#123;</span><br><span class=\"line\">            &quot;server&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;client&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            &quot;peer&quot;: &#123;</span><br><span class=\"line\">                &quot;expiry&quot;: &quot;43800h&quot;,</span><br><span class=\"line\">                &quot;usages&quot;: [</span><br><span class=\"line\">                    &quot;signing&quot;,</span><br><span class=\"line\">                    &quot;key encipherment&quot;,</span><br><span class=\"line\">                    &quot;server auth&quot;,</span><br><span class=\"line\">                    &quot;client auth&quot;</span><br><span class=\"line\">                ]</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat &lt;&lt; EOF &gt; ca-csr.json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;CN&quot;: &quot;My own CA&quot;,</span><br><span class=\"line\">    &quot;key&quot;: &#123;</span><br><span class=\"line\">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class=\"line\">        &quot;size&quot;: 2048</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    &quot;names&quot;: [</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            &quot;C&quot;: &quot;US&quot;,</span><br><span class=\"line\">            &quot;L&quot;: &quot;CA&quot;,</span><br><span class=\"line\">            &quot;O&quot;: &quot;My Company Name&quot;,</span><br><span class=\"line\">            &quot;ST&quot;: &quot;San Francisco&quot;,</span><br><span class=\"line\">            &quot;OU&quot;: &quot;Org Unit 1&quot;,</span><br><span class=\"line\">            &quot;OU&quot;: &quot;Org Unit 2&quot;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"> CA </span><br><span class=\"line\"></span><br><span class=\"line\">$ cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">ca-key.pem</span><br><span class=\"line\">ca.csr</span><br><span class=\"line\">ca.pem</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p> ca-key.pem *.csr </p>\n</blockquote>\n<h5 id=\"4\"><a href=\"#4\" class=\"headerlink\" title=\"4\"></a>4</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &apos;&#123;&quot;CN&quot;:&quot;coreos1&quot;,&quot;hosts&quot;:[&quot;10.93.81.17&quot;,&quot;127.0.0.1&quot;],&quot;key&quot;:&#123;&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048&#125;&#125;&apos; | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server -hostname=&quot;10.93.81.17,127.0.0.1,server&quot; - | cfssljson -bare server</span><br><span class=\"line\"></span><br><span class=\"line\">hosts </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">server-key.pem</span><br><span class=\"line\">server.csr</span><br><span class=\"line\">server.pem</span><br></pre></td></tr></table></figure>\n<h5 id=\"5\"><a href=\"#5\" class=\"headerlink\" title=\"5\"></a>5</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &apos;&#123;&quot;CN&quot;:&quot;member1&quot;,&quot;hosts&quot;:[&quot;10.93.81.17&quot;,&quot;127.0.0.1&quot;],&quot;key&quot;:&#123;&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048&#125;&#125;&apos; | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer -hostname=&quot;10.93.81.17,127.0.0.1,server,member1&quot; - | cfssljson -bare member1</span><br><span class=\"line\"></span><br><span class=\"line\">hosts </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">member1-key.pem</span><br><span class=\"line\">member1.csr</span><br><span class=\"line\">member1.pem</span><br><span class=\"line\"></span><br><span class=\"line\"> etcd </span><br></pre></td></tr></table></figure>\n<h5 id=\"6\"><a href=\"#6\" class=\"headerlink\" title=\"6\"></a>6</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ echo &apos;&#123;&quot;CN&quot;:&quot;client&quot;,&quot;hosts&quot;:[&quot;10.93.81.17&quot;,&quot;127.0.0.1&quot;],&quot;key&quot;:&#123;&quot;algo&quot;:&quot;rsa&quot;,&quot;size&quot;:2048&#125;&#125;&apos; | cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client - | cfssljson -bare client</span><br><span class=\"line\"></span><br><span class=\"line\">hosts </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">client-key.pem</span><br><span class=\"line\">client.csr</span><br><span class=\"line\">client.pem</span><br></pre></td></tr></table></figure>\n<p></p>\n<h2 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h2><ul>\n<li>1</li>\n<li>2</li>\n</ul>\n<h5 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -pv /etc/ssl/etcd/</span><br><span class=\"line\">$ cp ~/cfssl/* /etc/ssl/etcd/</span><br><span class=\"line\">$ chown -R etcd:etcd /etc/ssl/etcd</span><br><span class=\"line\">$ chmod 600 /etc/ssl/etcd/*-key.pem</span><br><span class=\"line\">$ cp ~/cfssl/ca.pem /etc/ssl/certs/</span><br></pre></td></tr></table></figure>\n<h5 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ yum install ca-certificates -y</span><br><span class=\"line\">     </span><br><span class=\"line\">$ update-ca-trust</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-etcd-\"><a href=\"#3-etcd-\" class=\"headerlink\" title=\"3 etcd \"></a>3 etcd </h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ etcdctl version</span><br><span class=\"line\">etcdctl version: 3.1.3</span><br><span class=\"line\">API version: 3.1</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat  /etc/etcd/etcd.conf</span><br><span class=\"line\"></span><br><span class=\"line\">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</span><br><span class=\"line\">#URL</span><br><span class=\"line\">ETCD_LISTEN_PEER_URLS=&quot;https://10.93.81.17:2380&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#URL, URL</span><br><span class=\"line\">ETCD_LISTEN_CLIENT_URLS=&quot;https://10.93.81.17:2379,https://10.93.81.17:4001&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://10.93.81.17:2380&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#advertise-client-urls URL, URLtcp2379</span><br><span class=\"line\">ETCD_ADVERTISE_CLIENT_URLS=&quot;https://10.93.81.17:2379&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#</span><br><span class=\"line\">ETCD_NAME=&quot;node1&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER=&quot;node1=https://10.93.81.17:2380&quot;</span><br><span class=\"line\">ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">#[security]</span><br><span class=\"line\"></span><br><span class=\"line\">ETCD_CERT_FILE=&quot;/etc/ssl/etcd/server.pem&quot;</span><br><span class=\"line\">ETCD_KEY_FILE=&quot;/etc/ssl/etcd/server-key.pem&quot;</span><br><span class=\"line\">ETCD_TRUSTED_CA_FILE=&quot;/etc/ssl/etcd/ca.pem&quot;</span><br><span class=\"line\">ETCD_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class=\"line\">ETCD_PEER_CERT_FILE=&quot;/etc/ssl/etcd/member1.pem&quot;</span><br><span class=\"line\">ETCD_PEER_KEY_FILE=&quot;/etc/ssl/etcd/member1-key.pem&quot;</span><br><span class=\"line\">ETCD_PEER_TRUSTED_CA_FILE=&quot;/etc/ssl/etcd/ca.pem&quot;</span><br><span class=\"line\">ETCD_PEER_CLIENT_CERT_AUTH=&quot;true&quot;</span><br><span class=\"line\">#[logging]</span><br><span class=\"line\">ETCD_DEBUG=&quot;true&quot;</span><br><span class=\"line\">ETCD_LOG_PACKAGE_LEVELS=&quot;etcdserver=WARNING,security=DEBUG&quot;</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-etcd-\"><a href=\"#4-etcd-\" class=\"headerlink\" title=\"4 etcd \"></a>4 etcd </h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl restart  etcd</span><br><span class=\"line\"></span><br><span class=\"line\"> journalctl -f -t etcd  journalctl -u etcd </span><br><span class=\"line\"></span><br><span class=\"line\">$ curl --cacert /etc/ssl/etcd/ca.pem --cert /etc/ssl/etcd/client.pem --key /etc/ssl/etcd/client-key.pem https://10.93.81.17:2379/health</span><br><span class=\"line\">&#123;&quot;health&quot;: &quot;true&quot;&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list</span><br><span class=\"line\">     </span><br><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem put /foo/bar  &quot;hello world&quot;</span><br><span class=\"line\">     </span><br><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem get /foo/bar</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-kube-apiserver--CA--etcd\"><a href=\"#5-kube-apiserver--CA--etcd\" class=\"headerlink\" title=\"5 kube-apiserver  CA  etcd\"></a>5 kube-apiserver  CA  etcd</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cp /etc/ssl/etcd/*  /var/run/kubernetes/</span><br><span class=\"line\">    </span><br><span class=\"line\">$ chown  -R kube.kube /var/run/kubernetes/</span><br><span class=\"line\"></span><br><span class=\"line\"> /etc/kubernetes/apiserver  KUBE_API_ARGS </span><br><span class=\"line\"></span><br><span class=\"line\">--cert-dir=&apos;/var/run/kubernetes/&apos; --etcd-cafile=&apos;/var/run/kubernetes/ca.pem&apos; --etcd-certfile=&apos;/var/run/kubernetes/client.pem&apos; --etcd-keyfile=&apos;/var/run/kubernetes/client-key.pem&apos;</span><br></pre></td></tr></table></figure>\n<h2 id=\"6-kube-apiserver\"><a href=\"#6-kube-apiserver\" class=\"headerlink\" title=\"6 kube-apiserver\"></a>6 kube-apiserver</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ systemctl restart kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">$ systemctl status -l kube-apiserver kube-controller-manager kube-scheduler kubelet kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get node</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get cs</span><br><span class=\"line\">NAME                 STATUS      MESSAGE                                                                   ERROR</span><br><span class=\"line\">scheduler            Healthy     ok</span><br><span class=\"line\">controller-manager   Healthy     ok</span><br><span class=\"line\">etcd-0               Unhealthy   Get https://10.93.81.17:2379/health: remote error: tls: bad certificate</span><br><span class=\"line\"></span><br><span class=\"line\">$ ./version.sh</span><br><span class=\"line\">etcdctl version: 3.1.3</span><br><span class=\"line\">API version: 3.1</span><br><span class=\"line\">Kubernetes v1.6.0-beta.1</span><br></pre></td></tr></table></figure>\n<h2 id=\"7\"><a href=\"#7\" class=\"headerlink\" title=\"7\"></a>7</h2><h5 id=\"1-kubectl-get-cs-\"><a href=\"#1-kubectl-get-cs-\" class=\"headerlink\" title=\"1  kubectl get cs \"></a>1  <code>kubectl get cs</code> </h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">etcd-0 Unhealthy Get https://10.93.81.17:2379/health: remote error: tls: bad certificate</span><br></pre></td></tr></table></figure>\n<p> pr  merge<a href=\"https://github.com/kubernetes/kubernetes/pull/39716\" target=\"_blank\" rel=\"noopener\">etcd component status check should include credentials</a></p>\n<h5 id=\"2-2380-\"><a href=\"#2-2380-\" class=\"headerlink\" title=\"2 2380 \"></a>2 2380 </h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ etcdctl --endpoints=[10.93.81.17:2379] --cacert=/etc/ssl/etcd/ca.pem --cert=/etc/ssl/etcd/client.pem --key=/etc/ssl/etcd/client-key.pem member list  </span><br><span class=\"line\"></span><br><span class=\"line\">2017-03-15 15:02:05.611564 I | warning: ignoring ServerName for user-provided CA for backwards compatibility is deprecated</span><br><span class=\"line\">145b401ad8709f51, started, node1, http://10.93.81.17:2380, https://10.93.81.17:2379</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><a href=\"https://www.addops.cn/post/tls-for-kubernetes-etcd.html\" target=\"_blank\" rel=\"noopener\">kubernetes + etcd ssl </a></li>\n<li><a href=\"https://coreos.com/etcd/docs/latest/op-guide/security.html\" target=\"_blank\" rel=\"noopener\">Security model</a></li>\n<li><a href=\"https://coreos.com/etcd/docs/latest/etcd-live-http-to-https-migration.html\" target=\"_blank\" rel=\"noopener\">Enabling HTTPS in an existing etcd cluster</a></li>\n</ul>\n"},{"title":"kubernetes ","date":"2019-01-30T08:26:30.000Z","type":"audit","_content":" apiserver kubernetes  v1.7 Alpha v1.8  Beta v1.12  GA \n\n> kubernetes feature-gates  Alpha  false Beta  true v1.8 \n\n\n### \n\n#### 1\n\nkube-apiserver \n\n- RequestReceived - apiserver \n- ResponseStarted -  header  body  watch\n- ResponseComplete -  body \n- Panic -  panic \n\n apiserver \n\n#### 2\n\n\n\n- None - \n- Metadata -  Request  metadata ( user, timestamp, resource, verb ) Request  Response body\n- Request -  Request  metadata  body\n- RequestResponse -  metadataRequest  Response  body\n\n#### 3\n\n\n\n- \n- \n- kubeletkube-proxykube-schedulerkube-controller-manager  kube-apiserver \n- secertsconfigmapstoken  body  \n\nk8s \n\n```\n{\n  \"kind\": \"EventList\",\n  \"apiVersion\": \"audit.k8s.io/v1beta1\",\n  \"Items\": [\n    {\n      \"Level\": \"Request\",\n      \"AuditID\": \"793e7ae2-5ca7-4ad3-a632-19708d2f8265\",\n      \"Stage\": \"RequestReceived\",\n      \"RequestURI\": \"/api/v1/namespaces/default/pods/test-pre-sf-de7cc-0\",\n      \"Verb\": \"get\",\n      \"User\": {\n        \"Username\": \"system:unsecured\",\n        \"UID\": \"\",\n        \"Groups\": [\n          \"system:masters\",\n          \"system:authenticated\"\n        ],\n        \"Extra\": null\n      },\n      \"ImpersonatedUser\": null,\n      \"SourceIPs\": [\n        \"192.168.1.11\"\n      ],\n      \"UserAgent\": \"kube-scheduler/v1.12.2 (linux/amd64) kubernetes/73f3294/scheduler\",\n      \"ObjectRef\": {\n        \"Resource\": \"pods\",\n        \"Namespace\": \"default\",\n        \"Name\": \"test-pre-sf-de7cc-0\",\n        \"UID\": \"\",\n        \"APIGroup\": \"\",\n        \"APIVersion\": \"v1\",\n        \"ResourceVersion\": \"\",\n        \"Subresource\": \"\"\n      },\n      \"ResponseStatus\": null,\n      \"RequestObject\": null,\n      \"ResponseObject\": null,\n      \"RequestReceivedTimestamp\": \"2019-01-11T06:51:43.528703Z\",\n      \"StageTimestamp\": \"2019-01-11T06:51:43.528703Z\",\n      \"Annotations\": null\n    }\n    ]\n}\n```\n\n### \n\n webhook v1.13  webhook\n\n#### 1 json \n\napiserver  KUBE_API_ARGS \n```\n--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-log-path=/var/log/kube-audit --audit-log-format=json\n```\n\n fluentd \n\n\n#### 2 webhook\n\n```\n--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-webhook-config-file=/etc/kubernetes/audit-webhook-kubeconfig\n```\n\nwebhook kubeconfigapiserver   webhook webhook  kafka \n\n`audit-webhook-kubeconfig` \n```\napiVersion: v1\nclusters:\n- cluster:\n    server: http://127.0.0.1:8081/audit/webhook\n  name: metric\ncontexts:\n- context:\n    cluster: metric\n    user: \"\"\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers: []\n```\n\napiserver  apiserver \n\n> Note: The audit logging feature increases the memory consumption of the API server because some context required for auditing is stored for each request. Additionally, memory consumption depends on the audit logging configuration.\n\n\n`audit-policy.yaml` \n\n```\napiVersion: audit.k8s.io/v1\nkind: Policy\n# ResponseStarted \nomitStages:\n  - \"ResponseStarted\"\nrules:\n  #  pod  statefulset \n  - level: RequestResponse\n    resources:\n    - group: \"\"\n      resources: [\"pods\",\"pods/status\"]\n    - group: \"apps\"\n      resources: [\"statefulsets\",\"statefulsets/scale\"]\n  # kube-controller-managerkube-scheduler \n  - level: None\n    userGroups: [\"system:authenticated\"]\n    nonResourceURLs:\n    - \"/api*\"\n    - \"/version\"\n  #  configsecrettoken \n  - level: Metadata\n    resources:\n    - group: \"\" # core API group\n      resources: [\"secrets\", \"configmaps\"]\n```\n\n\n\n- [Use fluentd to collect and distribute audit events from log file](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/audit/#%E6%97%A5%E5%BF%97%E9%80%89%E6%8B%A9%E5%99%A8%E7%A4%BA%E4%BE%8B)\n- [Use logstash to collect and distribute audit events from webhook backend](https://kubernetes.io/docs/tasks/debug-application-cluster/audit/#use-logstash-to-collect-and-distribute-audit-events-from-webhook-backend)\n\n#### 3subresource \n\n\nkubernetes  subresource, master  api  kubernetes  resource  subresource, pod  logsexec  subresource\n\n\n![](https://upload-images.jianshu.io/upload_images/1262158-4450a01f65b3f76d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n```\n resource 1.10 \n$ curl  127.0.0.1:8080/openapi/v2\n```\n\n[https://kubernetes.io/docs/concepts/overview/kubernetes-api/](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)\n\n### webhook \n\n```\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/emicklei/go-restful\"\n\t\"github.com/gosoon/glog\"\n\t\"k8s.io/apiserver/pkg/apis/audit\"\n)\n\nfunc main() {\n\t// NewContainer creates a new Container using a new ServeMux and default router (CurlyRouter)\n\tcontainer := restful.NewContainer()\n\tws := new(restful.WebService)\n\tws.Path(\"/audit\").\n\t\tConsumes(restful.MIME_JSON).\n\t\tProduces(restful.MIME_JSON)\n\tws.Route(ws.POST(\"/webhook\").To(AuditWebhook))\n\n\t//WebService ws2container2\n\tcontainer.Add(ws)\n\tserver := &http.Server{\n\t\tAddr:    \":8081\",\n\t\tHandler: container,\n\t}\n\t//go consumer()\n\tlog.Fatal(server.ListenAndServe())\n}\n\nfunc AuditWebhook(req *restful.Request, resp *restful.Response) {\n\tbody, err := ioutil.ReadAll(req.Request.Body)\n\tif err != nil {\n\t\tglog.Errorf(\"read body err is: %v\", err)\n\t}\n\tvar eventList audit.EventList\n\terr = json.Unmarshal(body, &eventList)\n\tif err != nil {\n\t\tglog.Errorf(\"unmarshal failed with:%v,body is :\\n\", err, string(body))\n\t\treturn\n\t}\n\tfor _, event := range eventList.Items {\n\t\tjsonBytes, err := json.Marshal(event)\n\t\tif err != nil {\n\t\t\tglog.Infof(\"marshal failed with:%v,event is \\n %+v\", err, event)\n\t\t}\n\t\t// \n\t\tasyncProducer(string(jsonBytes))\n\t}\n\tresp.AddHeader(\"Content-Type\", \"application/json\")\n\tresp.WriteEntity(\"success\")\n}\n```\n\n> [https://github.com/gosoon/k8s-audit-webhook](https://github.com/gosoon/k8s-audit-webhook)\n\n\n### \n\n kubernetes kubernetes kubernetes \n\n\n----\n\n\n[https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\n[ttps://kubernetes.io/docs/tasks/debug-application-cluster/audit/](https://kubernetes.io/docs/tasks/debug-application-cluster/audit/)\n[ Kubernetes ](https://yq.aliyun.com/articles/686982?utm_content=g_1000040449)\n\n","source":"_posts/k8s-audit-webhook.md","raw":"---\ntitle: kubernetes \ndate: 2019-01-30 16:26:30\ntags: [\"audit\",\"log\"]\ntype: \"audit\"\n\n---\n apiserver kubernetes  v1.7 Alpha v1.8  Beta v1.12  GA \n\n> kubernetes feature-gates  Alpha  false Beta  true v1.8 \n\n\n### \n\n#### 1\n\nkube-apiserver \n\n- RequestReceived - apiserver \n- ResponseStarted -  header  body  watch\n- ResponseComplete -  body \n- Panic -  panic \n\n apiserver \n\n#### 2\n\n\n\n- None - \n- Metadata -  Request  metadata ( user, timestamp, resource, verb ) Request  Response body\n- Request -  Request  metadata  body\n- RequestResponse -  metadataRequest  Response  body\n\n#### 3\n\n\n\n- \n- \n- kubeletkube-proxykube-schedulerkube-controller-manager  kube-apiserver \n- secertsconfigmapstoken  body  \n\nk8s \n\n```\n{\n  \"kind\": \"EventList\",\n  \"apiVersion\": \"audit.k8s.io/v1beta1\",\n  \"Items\": [\n    {\n      \"Level\": \"Request\",\n      \"AuditID\": \"793e7ae2-5ca7-4ad3-a632-19708d2f8265\",\n      \"Stage\": \"RequestReceived\",\n      \"RequestURI\": \"/api/v1/namespaces/default/pods/test-pre-sf-de7cc-0\",\n      \"Verb\": \"get\",\n      \"User\": {\n        \"Username\": \"system:unsecured\",\n        \"UID\": \"\",\n        \"Groups\": [\n          \"system:masters\",\n          \"system:authenticated\"\n        ],\n        \"Extra\": null\n      },\n      \"ImpersonatedUser\": null,\n      \"SourceIPs\": [\n        \"192.168.1.11\"\n      ],\n      \"UserAgent\": \"kube-scheduler/v1.12.2 (linux/amd64) kubernetes/73f3294/scheduler\",\n      \"ObjectRef\": {\n        \"Resource\": \"pods\",\n        \"Namespace\": \"default\",\n        \"Name\": \"test-pre-sf-de7cc-0\",\n        \"UID\": \"\",\n        \"APIGroup\": \"\",\n        \"APIVersion\": \"v1\",\n        \"ResourceVersion\": \"\",\n        \"Subresource\": \"\"\n      },\n      \"ResponseStatus\": null,\n      \"RequestObject\": null,\n      \"ResponseObject\": null,\n      \"RequestReceivedTimestamp\": \"2019-01-11T06:51:43.528703Z\",\n      \"StageTimestamp\": \"2019-01-11T06:51:43.528703Z\",\n      \"Annotations\": null\n    }\n    ]\n}\n```\n\n### \n\n webhook v1.13  webhook\n\n#### 1 json \n\napiserver  KUBE_API_ARGS \n```\n--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-log-path=/var/log/kube-audit --audit-log-format=json\n```\n\n fluentd \n\n\n#### 2 webhook\n\n```\n--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-webhook-config-file=/etc/kubernetes/audit-webhook-kubeconfig\n```\n\nwebhook kubeconfigapiserver   webhook webhook  kafka \n\n`audit-webhook-kubeconfig` \n```\napiVersion: v1\nclusters:\n- cluster:\n    server: http://127.0.0.1:8081/audit/webhook\n  name: metric\ncontexts:\n- context:\n    cluster: metric\n    user: \"\"\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers: []\n```\n\napiserver  apiserver \n\n> Note: The audit logging feature increases the memory consumption of the API server because some context required for auditing is stored for each request. Additionally, memory consumption depends on the audit logging configuration.\n\n\n`audit-policy.yaml` \n\n```\napiVersion: audit.k8s.io/v1\nkind: Policy\n# ResponseStarted \nomitStages:\n  - \"ResponseStarted\"\nrules:\n  #  pod  statefulset \n  - level: RequestResponse\n    resources:\n    - group: \"\"\n      resources: [\"pods\",\"pods/status\"]\n    - group: \"apps\"\n      resources: [\"statefulsets\",\"statefulsets/scale\"]\n  # kube-controller-managerkube-scheduler \n  - level: None\n    userGroups: [\"system:authenticated\"]\n    nonResourceURLs:\n    - \"/api*\"\n    - \"/version\"\n  #  configsecrettoken \n  - level: Metadata\n    resources:\n    - group: \"\" # core API group\n      resources: [\"secrets\", \"configmaps\"]\n```\n\n\n\n- [Use fluentd to collect and distribute audit events from log file](https://kubernetes.io/zh/docs/tasks/debug-application-cluster/audit/#%E6%97%A5%E5%BF%97%E9%80%89%E6%8B%A9%E5%99%A8%E7%A4%BA%E4%BE%8B)\n- [Use logstash to collect and distribute audit events from webhook backend](https://kubernetes.io/docs/tasks/debug-application-cluster/audit/#use-logstash-to-collect-and-distribute-audit-events-from-webhook-backend)\n\n#### 3subresource \n\n\nkubernetes  subresource, master  api  kubernetes  resource  subresource, pod  logsexec  subresource\n\n\n![](https://upload-images.jianshu.io/upload_images/1262158-4450a01f65b3f76d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n```\n resource 1.10 \n$ curl  127.0.0.1:8080/openapi/v2\n```\n\n[https://kubernetes.io/docs/concepts/overview/kubernetes-api/](https://kubernetes.io/docs/concepts/overview/kubernetes-api/)\n\n### webhook \n\n```\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"io/ioutil\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/emicklei/go-restful\"\n\t\"github.com/gosoon/glog\"\n\t\"k8s.io/apiserver/pkg/apis/audit\"\n)\n\nfunc main() {\n\t// NewContainer creates a new Container using a new ServeMux and default router (CurlyRouter)\n\tcontainer := restful.NewContainer()\n\tws := new(restful.WebService)\n\tws.Path(\"/audit\").\n\t\tConsumes(restful.MIME_JSON).\n\t\tProduces(restful.MIME_JSON)\n\tws.Route(ws.POST(\"/webhook\").To(AuditWebhook))\n\n\t//WebService ws2container2\n\tcontainer.Add(ws)\n\tserver := &http.Server{\n\t\tAddr:    \":8081\",\n\t\tHandler: container,\n\t}\n\t//go consumer()\n\tlog.Fatal(server.ListenAndServe())\n}\n\nfunc AuditWebhook(req *restful.Request, resp *restful.Response) {\n\tbody, err := ioutil.ReadAll(req.Request.Body)\n\tif err != nil {\n\t\tglog.Errorf(\"read body err is: %v\", err)\n\t}\n\tvar eventList audit.EventList\n\terr = json.Unmarshal(body, &eventList)\n\tif err != nil {\n\t\tglog.Errorf(\"unmarshal failed with:%v,body is :\\n\", err, string(body))\n\t\treturn\n\t}\n\tfor _, event := range eventList.Items {\n\t\tjsonBytes, err := json.Marshal(event)\n\t\tif err != nil {\n\t\t\tglog.Infof(\"marshal failed with:%v,event is \\n %+v\", err, event)\n\t\t}\n\t\t// \n\t\tasyncProducer(string(jsonBytes))\n\t}\n\tresp.AddHeader(\"Content-Type\", \"application/json\")\n\tresp.WriteEntity(\"success\")\n}\n```\n\n> [https://github.com/gosoon/k8s-audit-webhook](https://github.com/gosoon/k8s-audit-webhook)\n\n\n### \n\n kubernetes kubernetes kubernetes \n\n\n----\n\n\n[https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\n[ttps://kubernetes.io/docs/tasks/debug-application-cluster/audit/](https://kubernetes.io/docs/tasks/debug-application-cluster/audit/)\n[ Kubernetes ](https://yq.aliyun.com/articles/686982?utm_content=g_1000040449)\n\n","slug":"k8s-audit-webhook","published":1,"updated":"2019-01-30T08:30:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyysyi000ntadv90s65k6j","content":"<p> apiserver kubernetes  v1.7 Alpha v1.8  Beta v1.12  GA </p>\n<blockquote>\n<p>kubernetes feature-gates  Alpha  false Beta  true v1.8 </p>\n</blockquote>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h4><p>kube-apiserver </p>\n<ul>\n<li>RequestReceived - apiserver </li>\n<li>ResponseStarted -  header  body  watch</li>\n<li>ResponseComplete -  body </li>\n<li>Panic -  panic </li>\n</ul>\n<p> apiserver </p>\n<h4 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h4><p></p>\n<ul>\n<li>None - </li>\n<li>Metadata -  Request  metadata ( user, timestamp, resource, verb ) Request  Response body</li>\n<li>Request -  Request  metadata  body</li>\n<li>RequestResponse -  metadataRequest  Response  body</li>\n</ul>\n<h4 id=\"3\"><a href=\"#3\" class=\"headerlink\" title=\"3\"></a>3</h4><p></p>\n<ul>\n<li></li>\n<li></li>\n<li>kubeletkube-proxykube-schedulerkube-controller-manager  kube-apiserver </li>\n<li>secertsconfigmapstoken  body  </li>\n</ul>\n<p>k8s </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;kind&quot;: &quot;EventList&quot;,</span><br><span class=\"line\">  &quot;apiVersion&quot;: &quot;audit.k8s.io/v1beta1&quot;,</span><br><span class=\"line\">  &quot;Items&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;Level&quot;: &quot;Request&quot;,</span><br><span class=\"line\">      &quot;AuditID&quot;: &quot;793e7ae2-5ca7-4ad3-a632-19708d2f8265&quot;,</span><br><span class=\"line\">      &quot;Stage&quot;: &quot;RequestReceived&quot;,</span><br><span class=\"line\">      &quot;RequestURI&quot;: &quot;/api/v1/namespaces/default/pods/test-pre-sf-de7cc-0&quot;,</span><br><span class=\"line\">      &quot;Verb&quot;: &quot;get&quot;,</span><br><span class=\"line\">      &quot;User&quot;: &#123;</span><br><span class=\"line\">        &quot;Username&quot;: &quot;system:unsecured&quot;,</span><br><span class=\"line\">        &quot;UID&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Groups&quot;: [</span><br><span class=\"line\">          &quot;system:masters&quot;,</span><br><span class=\"line\">          &quot;system:authenticated&quot;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;Extra&quot;: null</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;ImpersonatedUser&quot;: null,</span><br><span class=\"line\">      &quot;SourceIPs&quot;: [</span><br><span class=\"line\">        &quot;192.168.1.11&quot;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      &quot;UserAgent&quot;: &quot;kube-scheduler/v1.12.2 (linux/amd64) kubernetes/73f3294/scheduler&quot;,</span><br><span class=\"line\">      &quot;ObjectRef&quot;: &#123;</span><br><span class=\"line\">        &quot;Resource&quot;: &quot;pods&quot;,</span><br><span class=\"line\">        &quot;Namespace&quot;: &quot;default&quot;,</span><br><span class=\"line\">        &quot;Name&quot;: &quot;test-pre-sf-de7cc-0&quot;,</span><br><span class=\"line\">        &quot;UID&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;APIGroup&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;APIVersion&quot;: &quot;v1&quot;,</span><br><span class=\"line\">        &quot;ResourceVersion&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Subresource&quot;: &quot;&quot;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;ResponseStatus&quot;: null,</span><br><span class=\"line\">      &quot;RequestObject&quot;: null,</span><br><span class=\"line\">      &quot;ResponseObject&quot;: null,</span><br><span class=\"line\">      &quot;RequestReceivedTimestamp&quot;: &quot;2019-01-11T06:51:43.528703Z&quot;,</span><br><span class=\"line\">      &quot;StageTimestamp&quot;: &quot;2019-01-11T06:51:43.528703Z&quot;,</span><br><span class=\"line\">      &quot;Annotations&quot;: null</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> webhook v1.13  webhook</p>\n<h4 id=\"1-json-\"><a href=\"#1-json-\" class=\"headerlink\" title=\"1 json \"></a>1 json </h4><p>apiserver  KUBE_API_ARGS <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-log-path=/var/log/kube-audit --audit-log-format=json</span><br></pre></td></tr></table></figure></p>\n<p> fluentd <br></p>\n<h4 id=\"2-webhook\"><a href=\"#2-webhook\" class=\"headerlink\" title=\"2 webhook\"></a>2 webhook</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-webhook-config-file=/etc/kubernetes/audit-webhook-kubeconfig</span><br></pre></td></tr></table></figure>\n<p>webhook  kubeconfigapiserver   webhook webhook  kafka </p>\n<p><code>audit-webhook-kubeconfig</code> <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    server: http://127.0.0.1:8081/audit/webhook</span><br><span class=\"line\">  name: metric</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: metric</span><br><span class=\"line\">    user: &quot;&quot;</span><br><span class=\"line\">  name: default-context</span><br><span class=\"line\">current-context: default-context</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users: []</span><br></pre></td></tr></table></figure></p>\n<p>apiserver  apiserver </p>\n<blockquote>\n<p>Note: The audit logging feature increases the memory consumption of the API server because some context required for auditing is stored for each request. Additionally, memory consumption depends on the audit logging configuration.</p>\n</blockquote>\n<p><code>audit-policy.yaml</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: audit.k8s.io/v1</span><br><span class=\"line\">kind: Policy</span><br><span class=\"line\"># ResponseStarted </span><br><span class=\"line\">omitStages:</span><br><span class=\"line\">  - &quot;ResponseStarted&quot;</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  #  pod  statefulset </span><br><span class=\"line\">  - level: RequestResponse</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">    - group: &quot;&quot;</span><br><span class=\"line\">      resources: [&quot;pods&quot;,&quot;pods/status&quot;]</span><br><span class=\"line\">    - group: &quot;apps&quot;</span><br><span class=\"line\">      resources: [&quot;statefulsets&quot;,&quot;statefulsets/scale&quot;]</span><br><span class=\"line\">  # kube-controller-managerkube-scheduler </span><br><span class=\"line\">  - level: None</span><br><span class=\"line\">    userGroups: [&quot;system:authenticated&quot;]</span><br><span class=\"line\">    nonResourceURLs:</span><br><span class=\"line\">    - &quot;/api*&quot;</span><br><span class=\"line\">    - &quot;/version&quot;</span><br><span class=\"line\">  #  configsecrettoken </span><br><span class=\"line\">  - level: Metadata</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">    - group: &quot;&quot; # core API group</span><br><span class=\"line\">      resources: [&quot;secrets&quot;, &quot;configmaps&quot;]</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><a href=\"https://kubernetes.io/zh/docs/tasks/debug-application-cluster/audit/#%E6%97%A5%E5%BF%97%E9%80%89%E6%8B%A9%E5%99%A8%E7%A4%BA%E4%BE%8B\" target=\"_blank\" rel=\"noopener\">Use fluentd to collect and distribute audit events from log file</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/debug-application-cluster/audit/#use-logstash-to-collect-and-distribute-audit-events-from-webhook-backend\" target=\"_blank\" rel=\"noopener\">Use logstash to collect and distribute audit events from webhook backend</a></li>\n</ul>\n<h4 id=\"3subresource-\"><a href=\"#3subresource-\" class=\"headerlink\" title=\"3subresource \"></a>3subresource </h4><p>kubernetes  subresource, master  api  kubernetes  resource  subresource, pod  logsexec  subresource</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-4450a01f65b3f76d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> resource 1.10 </span><br><span class=\"line\">$ curl  127.0.0.1:8080/openapi/v2</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/kubernetes-api/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/concepts/overview/kubernetes-api/</a></p>\n<h3 id=\"webhook-\"><a href=\"#webhook-\" class=\"headerlink\" title=\"webhook \"></a>webhook </h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;encoding/json&quot;</span><br><span class=\"line\">\t&quot;io/ioutil&quot;</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;net/http&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&quot;github.com/emicklei/go-restful&quot;</span><br><span class=\"line\">\t&quot;github.com/gosoon/glog&quot;</span><br><span class=\"line\">\t&quot;k8s.io/apiserver/pkg/apis/audit&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\t// NewContainer creates a new Container using a new ServeMux and default router (CurlyRouter)</span><br><span class=\"line\">\tcontainer := restful.NewContainer()</span><br><span class=\"line\">\tws := new(restful.WebService)</span><br><span class=\"line\">\tws.Path(&quot;/audit&quot;).</span><br><span class=\"line\">\t\tConsumes(restful.MIME_JSON).</span><br><span class=\"line\">\t\tProduces(restful.MIME_JSON)</span><br><span class=\"line\">\tws.Route(ws.POST(&quot;/webhook&quot;).To(AuditWebhook))</span><br><span class=\"line\"></span><br><span class=\"line\">\t//WebService ws2container2</span><br><span class=\"line\">\tcontainer.Add(ws)</span><br><span class=\"line\">\tserver := &amp;http.Server&#123;</span><br><span class=\"line\">\t\tAddr:    &quot;:8081&quot;,</span><br><span class=\"line\">\t\tHandler: container,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//go consumer()</span><br><span class=\"line\">\tlog.Fatal(server.ListenAndServe())</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func AuditWebhook(req *restful.Request, resp *restful.Response) &#123;</span><br><span class=\"line\">\tbody, err := ioutil.ReadAll(req.Request.Body)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Errorf(&quot;read body err is: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvar eventList audit.EventList</span><br><span class=\"line\">\terr = json.Unmarshal(body, &amp;eventList)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Errorf(&quot;unmarshal failed with:%v,body is :\\n&quot;, err, string(body))</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor _, event := range eventList.Items &#123;</span><br><span class=\"line\">\t\tjsonBytes, err := json.Marshal(event)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Infof(&quot;marshal failed with:%v,event is \\n %+v&quot;, err, event)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tasyncProducer(string(jsonBytes))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tresp.AddHeader(&quot;Content-Type&quot;, &quot;application/json&quot;)</span><br><span class=\"line\">\tresp.WriteEntity(&quot;success&quot;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><a href=\"https://github.com/gosoon/k8s-audit-webhook\" target=\"_blank\" rel=\"noopener\">https://github.com/gosoon/k8s-audit-webhook</a></p>\n</blockquote>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> kubernetes kubernetes kubernetes </p>\n<hr>\n<p><br><a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/</a><br><a href=\"https://kubernetes.io/docs/tasks/debug-application-cluster/audit/\" target=\"_blank\" rel=\"noopener\">ttps://kubernetes.io/docs/tasks/debug-application-cluster/audit/</a><br><a href=\"https://yq.aliyun.com/articles/686982?utm_content=g_1000040449\" target=\"_blank\" rel=\"noopener\"> Kubernetes </a></p>\n","site":{"data":{}},"excerpt":"","more":"<p> apiserver kubernetes  v1.7 Alpha v1.8  Beta v1.12  GA </p>\n<blockquote>\n<p>kubernetes feature-gates  Alpha  false Beta  true v1.8 </p>\n</blockquote>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"1\"><a href=\"#1\" class=\"headerlink\" title=\"1\"></a>1</h4><p>kube-apiserver </p>\n<ul>\n<li>RequestReceived - apiserver </li>\n<li>ResponseStarted -  header  body  watch</li>\n<li>ResponseComplete -  body </li>\n<li>Panic -  panic </li>\n</ul>\n<p> apiserver </p>\n<h4 id=\"2\"><a href=\"#2\" class=\"headerlink\" title=\"2\"></a>2</h4><p></p>\n<ul>\n<li>None - </li>\n<li>Metadata -  Request  metadata ( user, timestamp, resource, verb ) Request  Response body</li>\n<li>Request -  Request  metadata  body</li>\n<li>RequestResponse -  metadataRequest  Response  body</li>\n</ul>\n<h4 id=\"3\"><a href=\"#3\" class=\"headerlink\" title=\"3\"></a>3</h4><p></p>\n<ul>\n<li></li>\n<li></li>\n<li>kubeletkube-proxykube-schedulerkube-controller-manager  kube-apiserver </li>\n<li>secertsconfigmapstoken  body  </li>\n</ul>\n<p>k8s </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;kind&quot;: &quot;EventList&quot;,</span><br><span class=\"line\">  &quot;apiVersion&quot;: &quot;audit.k8s.io/v1beta1&quot;,</span><br><span class=\"line\">  &quot;Items&quot;: [</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">      &quot;Level&quot;: &quot;Request&quot;,</span><br><span class=\"line\">      &quot;AuditID&quot;: &quot;793e7ae2-5ca7-4ad3-a632-19708d2f8265&quot;,</span><br><span class=\"line\">      &quot;Stage&quot;: &quot;RequestReceived&quot;,</span><br><span class=\"line\">      &quot;RequestURI&quot;: &quot;/api/v1/namespaces/default/pods/test-pre-sf-de7cc-0&quot;,</span><br><span class=\"line\">      &quot;Verb&quot;: &quot;get&quot;,</span><br><span class=\"line\">      &quot;User&quot;: &#123;</span><br><span class=\"line\">        &quot;Username&quot;: &quot;system:unsecured&quot;,</span><br><span class=\"line\">        &quot;UID&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Groups&quot;: [</span><br><span class=\"line\">          &quot;system:masters&quot;,</span><br><span class=\"line\">          &quot;system:authenticated&quot;</span><br><span class=\"line\">        ],</span><br><span class=\"line\">        &quot;Extra&quot;: null</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;ImpersonatedUser&quot;: null,</span><br><span class=\"line\">      &quot;SourceIPs&quot;: [</span><br><span class=\"line\">        &quot;192.168.1.11&quot;</span><br><span class=\"line\">      ],</span><br><span class=\"line\">      &quot;UserAgent&quot;: &quot;kube-scheduler/v1.12.2 (linux/amd64) kubernetes/73f3294/scheduler&quot;,</span><br><span class=\"line\">      &quot;ObjectRef&quot;: &#123;</span><br><span class=\"line\">        &quot;Resource&quot;: &quot;pods&quot;,</span><br><span class=\"line\">        &quot;Namespace&quot;: &quot;default&quot;,</span><br><span class=\"line\">        &quot;Name&quot;: &quot;test-pre-sf-de7cc-0&quot;,</span><br><span class=\"line\">        &quot;UID&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;APIGroup&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;APIVersion&quot;: &quot;v1&quot;,</span><br><span class=\"line\">        &quot;ResourceVersion&quot;: &quot;&quot;,</span><br><span class=\"line\">        &quot;Subresource&quot;: &quot;&quot;</span><br><span class=\"line\">      &#125;,</span><br><span class=\"line\">      &quot;ResponseStatus&quot;: null,</span><br><span class=\"line\">      &quot;RequestObject&quot;: null,</span><br><span class=\"line\">      &quot;ResponseObject&quot;: null,</span><br><span class=\"line\">      &quot;RequestReceivedTimestamp&quot;: &quot;2019-01-11T06:51:43.528703Z&quot;,</span><br><span class=\"line\">      &quot;StageTimestamp&quot;: &quot;2019-01-11T06:51:43.528703Z&quot;,</span><br><span class=\"line\">      &quot;Annotations&quot;: null</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    ]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> webhook v1.13  webhook</p>\n<h4 id=\"1-json-\"><a href=\"#1-json-\" class=\"headerlink\" title=\"1 json \"></a>1 json </h4><p>apiserver  KUBE_API_ARGS <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-log-path=/var/log/kube-audit --audit-log-format=json</span><br></pre></td></tr></table></figure></p>\n<p> fluentd <br></p>\n<h4 id=\"2-webhook\"><a href=\"#2-webhook\" class=\"headerlink\" title=\"2 webhook\"></a>2 webhook</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">--audit-policy-file=/etc/kubernetes/audit-policy.yaml --audit-webhook-config-file=/etc/kubernetes/audit-webhook-kubeconfig</span><br></pre></td></tr></table></figure>\n<p>webhook  kubeconfigapiserver   webhook webhook  kafka </p>\n<p><code>audit-webhook-kubeconfig</code> <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">clusters:</span><br><span class=\"line\">- cluster:</span><br><span class=\"line\">    server: http://127.0.0.1:8081/audit/webhook</span><br><span class=\"line\">  name: metric</span><br><span class=\"line\">contexts:</span><br><span class=\"line\">- context:</span><br><span class=\"line\">    cluster: metric</span><br><span class=\"line\">    user: &quot;&quot;</span><br><span class=\"line\">  name: default-context</span><br><span class=\"line\">current-context: default-context</span><br><span class=\"line\">kind: Config</span><br><span class=\"line\">preferences: &#123;&#125;</span><br><span class=\"line\">users: []</span><br></pre></td></tr></table></figure></p>\n<p>apiserver  apiserver </p>\n<blockquote>\n<p>Note: The audit logging feature increases the memory consumption of the API server because some context required for auditing is stored for each request. Additionally, memory consumption depends on the audit logging configuration.</p>\n</blockquote>\n<p><code>audit-policy.yaml</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: audit.k8s.io/v1</span><br><span class=\"line\">kind: Policy</span><br><span class=\"line\"># ResponseStarted </span><br><span class=\"line\">omitStages:</span><br><span class=\"line\">  - &quot;ResponseStarted&quot;</span><br><span class=\"line\">rules:</span><br><span class=\"line\">  #  pod  statefulset </span><br><span class=\"line\">  - level: RequestResponse</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">    - group: &quot;&quot;</span><br><span class=\"line\">      resources: [&quot;pods&quot;,&quot;pods/status&quot;]</span><br><span class=\"line\">    - group: &quot;apps&quot;</span><br><span class=\"line\">      resources: [&quot;statefulsets&quot;,&quot;statefulsets/scale&quot;]</span><br><span class=\"line\">  # kube-controller-managerkube-scheduler </span><br><span class=\"line\">  - level: None</span><br><span class=\"line\">    userGroups: [&quot;system:authenticated&quot;]</span><br><span class=\"line\">    nonResourceURLs:</span><br><span class=\"line\">    - &quot;/api*&quot;</span><br><span class=\"line\">    - &quot;/version&quot;</span><br><span class=\"line\">  #  configsecrettoken </span><br><span class=\"line\">  - level: Metadata</span><br><span class=\"line\">    resources:</span><br><span class=\"line\">    - group: &quot;&quot; # core API group</span><br><span class=\"line\">      resources: [&quot;secrets&quot;, &quot;configmaps&quot;]</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li><a href=\"https://kubernetes.io/zh/docs/tasks/debug-application-cluster/audit/#%E6%97%A5%E5%BF%97%E9%80%89%E6%8B%A9%E5%99%A8%E7%A4%BA%E4%BE%8B\" target=\"_blank\" rel=\"noopener\">Use fluentd to collect and distribute audit events from log file</a></li>\n<li><a href=\"https://kubernetes.io/docs/tasks/debug-application-cluster/audit/#use-logstash-to-collect-and-distribute-audit-events-from-webhook-backend\" target=\"_blank\" rel=\"noopener\">Use logstash to collect and distribute audit events from webhook backend</a></li>\n</ul>\n<h4 id=\"3subresource-\"><a href=\"#3subresource-\" class=\"headerlink\" title=\"3subresource \"></a>3subresource </h4><p>kubernetes  subresource, master  api  kubernetes  resource  subresource, pod  logsexec  subresource</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-4450a01f65b3f76d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> resource 1.10 </span><br><span class=\"line\">$ curl  127.0.0.1:8080/openapi/v2</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://kubernetes.io/docs/concepts/overview/kubernetes-api/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/concepts/overview/kubernetes-api/</a></p>\n<h3 id=\"webhook-\"><a href=\"#webhook-\" class=\"headerlink\" title=\"webhook \"></a>webhook </h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;encoding/json&quot;</span><br><span class=\"line\">\t&quot;io/ioutil&quot;</span><br><span class=\"line\">\t&quot;log&quot;</span><br><span class=\"line\">\t&quot;net/http&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&quot;github.com/emicklei/go-restful&quot;</span><br><span class=\"line\">\t&quot;github.com/gosoon/glog&quot;</span><br><span class=\"line\">\t&quot;k8s.io/apiserver/pkg/apis/audit&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\t// NewContainer creates a new Container using a new ServeMux and default router (CurlyRouter)</span><br><span class=\"line\">\tcontainer := restful.NewContainer()</span><br><span class=\"line\">\tws := new(restful.WebService)</span><br><span class=\"line\">\tws.Path(&quot;/audit&quot;).</span><br><span class=\"line\">\t\tConsumes(restful.MIME_JSON).</span><br><span class=\"line\">\t\tProduces(restful.MIME_JSON)</span><br><span class=\"line\">\tws.Route(ws.POST(&quot;/webhook&quot;).To(AuditWebhook))</span><br><span class=\"line\"></span><br><span class=\"line\">\t//WebService ws2container2</span><br><span class=\"line\">\tcontainer.Add(ws)</span><br><span class=\"line\">\tserver := &amp;http.Server&#123;</span><br><span class=\"line\">\t\tAddr:    &quot;:8081&quot;,</span><br><span class=\"line\">\t\tHandler: container,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//go consumer()</span><br><span class=\"line\">\tlog.Fatal(server.ListenAndServe())</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func AuditWebhook(req *restful.Request, resp *restful.Response) &#123;</span><br><span class=\"line\">\tbody, err := ioutil.ReadAll(req.Request.Body)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Errorf(&quot;read body err is: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvar eventList audit.EventList</span><br><span class=\"line\">\terr = json.Unmarshal(body, &amp;eventList)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Errorf(&quot;unmarshal failed with:%v,body is :\\n&quot;, err, string(body))</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfor _, event := range eventList.Items &#123;</span><br><span class=\"line\">\t\tjsonBytes, err := json.Marshal(event)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Infof(&quot;marshal failed with:%v,event is \\n %+v&quot;, err, event)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tasyncProducer(string(jsonBytes))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tresp.AddHeader(&quot;Content-Type&quot;, &quot;application/json&quot;)</span><br><span class=\"line\">\tresp.WriteEntity(&quot;success&quot;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><a href=\"https://github.com/gosoon/k8s-audit-webhook\" target=\"_blank\" rel=\"noopener\">https://github.com/gosoon/k8s-audit-webhook</a></p>\n</blockquote>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> kubernetes kubernetes kubernetes </p>\n<hr>\n<p><br><a href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/</a><br><a href=\"https://kubernetes.io/docs/tasks/debug-application-cluster/audit/\" target=\"_blank\" rel=\"noopener\">ttps://kubernetes.io/docs/tasks/debug-application-cluster/audit/</a><br><a href=\"https://yq.aliyun.com/articles/686982?utm_content=g_1000040449\" target=\"_blank\" rel=\"noopener\"> Kubernetes </a></p>\n"},{"title":"kubeadm  kubernetes","date":"2019-01-17T02:11:30.000Z","type":"kubeadm","_content":"\nkubeadm  Kubernetes  GA\n\n## kubeadm \n\nkubeadm  kubelet kubelet  pod /etc/kubernetes/manifestskubeadm  kubelet  /etc/kubernetes/manifests  etcdkube-apiserverkube-controller-managerkube-scheduler  static pod  yaml  kubelet  yaml  pod kube-apiserverkube-controller-managerkube-scheduler  etcd  static pod \n\n\n>  kubernetes v1.12.0\n\n\n```\n$ uname -r\n3.10.0-514.16.1.el7.x86_64\n\n$ cat /etc/redhat-release\nCentOS Linux release 7.2.1511 (Core)\n```\n## \n```\n# swap\n$ sudo swapoff -a\n\n# selinux\n$ sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux \n$ setenforce 0\n\n# \n$ systemctl disable firewalld.service && systemctl stop firewalld.service\n\n# \n$ cat << EOF >> /etc/sysctl.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nvm.swappiness=0\nEOF \n$ sysctl -p\n```\n\n##  Docker CE \n \n>  docker docker-ce-18.06.1.ce\n\n```\n# Install Docker CE\n## Set up the repository\n### Install required packages.\nyum install yum-utils device-mapper-persistent-data lvm2\n\n### Add docker repository.\nyum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo\n\n## Install docker ce.\nyum update && yum install docker-ce-18.06.1.ce\n\n## Create /etc/docker directory.\nmkdir /etc/docker\n\n# Setup daemon.\ncat > /etc/docker/daemon.json <<EOF\n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"100m\"\n  },\n  \"storage-driver\": \"overlay2\",\n  \"storage-opts\": [\n    \"overlay2.override_kernel_check=true\"\n  ]\n}\nEOF\n\nmkdir -p /etc/systemd/system/docker.service.d\n\n# Restart docker.\nsystemctl daemon-reload\nsystemctl restart docker\n```\nhttps://kubernetes.io/docs/setup/cri/\n\n##  kubernetes master \n\n kubeadm \n```\n$ kubeadm init --kubernetes-version=v1.12.0 --pod-network-cidr=10.244.0.0/16\n[init] using Kubernetes version: v1.12.0\n[preflight] running pre-flight checks\n[preflight/images] Pulling images required for setting up a Kubernetes cluster\n[preflight/images] This might take a minute or two, depending on the speed of your internet connection\n[preflight/images] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[preflight] Activating the kubelet service\n[certificates] Using the existing front-proxy-client certificate and key.\n[certificates] Using the existing etcd/server certificate and key.\n[certificates] Using the existing etcd/peer certificate and key.\n[certificates] Using the existing etcd/healthcheck-client certificate and key.\n[certificates] Using the existing apiserver-etcd-client certificate and key.\n[certificates] Using the existing apiserver certificate and key.\n[certificates] Using the existing apiserver-kubelet-client certificate and key.\n[certificates] valid certificates and keys now exist in \"/etc/kubernetes/pki\"\n[certificates] Using the existing sa key.\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/admin.conf\"\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/kubelet.conf\"\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/controller-manager.conf\"\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/scheduler.conf\"\n[controlplane] wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\n[controlplane] wrote Static Pod manifest for component kube-controller-manager to \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\n[controlplane] wrote Static Pod manifest for component kube-scheduler to \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\n[etcd] Wrote Static Pod manifest for a local etcd instance to \"/etc/kubernetes/manifests/etcd.yaml\"\n[init] waiting for the kubelet to boot up the control plane as Static Pods from directory \"/etc/kubernetes/manifests\"\n[init] this might take a minute or longer if the control plane images have to be pulled\n[apiclient] All control plane components are healthy after 14.002350 seconds\n[uploadconfig] storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.12\" in namespace kube-system with the configuration for the kubelets in the cluster\n[markmaster] Marking the node 192.168.1.110 as master by adding the label \"node-role.kubernetes.io/master=''\"\n[markmaster] Marking the node 192.168.1.110 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"192.168.1.110\" as an annotation\n[bootstraptoken] using token: wu5hfy.lkuz9fih6hlqe1jt\n[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash sha256:e8d2649fceae9d7f6de94af0b7e294680b87f7d1e207c75c3cb496841b12ec23\n\n```\n\n\n\n- \n-  token\n-  CA  client \n-  kubeconfig  kubelet  API server\n-  Master  Static Pod manifests /etc/kubernetes/manifests \n-  RBAC  Master node \n-  kube-proxy  CoreDNS\n\n\n kubetl  \n```\n $ mkdir -p $HOME/.kube\n $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n $ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n node  master \n```\n$ kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash\n```\nkubeadm  master  node  master  taint  taint \n```\n$ kubectl taint nodes --all node-role.kubernetes.io/master-\n```\n\n\n\n```\n$ kubectl get pod -n kube-system\nNAME                                     READY   STATUS             RESTARTS   AGE\ncoredns-99b9bb8bd-pgh5t                  1/1     Running            0          48m\netcd                                     1/1     Running            2          48m\nkube-apiserver                           1/1     Running            1          48m\nkube-controller-manager                  1/1     Running            0          49m\nkube-flannel-ds-amd64-b5rjg              1/1     Running            0          31m\nkube-proxy-c8ktg                         1/1     Running            0          48m\nkube-scheduler                           1/1     Running            2          48m\n```\n\n##  kubernetes \n\nkubernetes  Kubernetes \n- overlay  flannel(udp/vxlanweavecalico(ipip)openvswitch \n- ( iptables )flannel(host-gw)calico(bgp)macvlan \n\nflannel  calico  flannel \n\n\n flannel  RBAC flannel  daemonset \n```\n$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n\n pod \n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n```\n\n## kubeadm \n\n1:\n```\n$ kubeadm reset\n```\n2\n```\n# \n$ kubeadm upgrade plan\n\n# \n$ kubeadm upgrade apply [version]\n```\n>  1.  kubeadm \n>  2. kubeadm  kubelet  master  kubelet \n\n\n##  case \n\n##### 1flannel pod cidr not assgned\n\n  /etc/kubernetes/manifests/kube-controller-manager.yaml \n\n--allocate-node-cidrs=true\n--cluster-cidr=10.244.0.0/16\n\nhttps://github.com/coreos/flannel/issues/728\n\n##### 2coredns /proc/sys/net/ipv6/conf/eth0/accept_dad: no such file or directory\n\n```\n$ vim /etc/default/grub and change the value of kernel parameter ipv6.disable from 1 to 0 in line\n$ grub2-mkconfig -o /boot/grub2/grub.cfg\n$ shutdown -r now\n```\nhttps://github.com/containernetworking/cni/issues/569\n\n##### 3kubeadm \n\nkubeadm  --cert-dir  CertificatesDir  /etc/kubernetes/pkikubeadm  CA  /etc/kubernetes/pki/ca.crt  /etc/kubernetes/pki/ca.keykubeadm  CA \n\n##### 4kubeadm join  token \n\ntoken 24 token  `kubeadm token create`  token\n\n## \n kubeadm  kubernetes kubeadm kubeadm  master \n\n\n\n[Creating a single master cluster with kubeadm](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/)\n[kubeadm ](https://github.com/feiskyer/kubernetes-handbook/blob/master/components/kubeadm.md)\n[DockOneKuberneteskubeadm](http://dockone.io/article/4645)\n[centos7.2 k8s v1.11.0](https://segmentfault.com/a/1190000015787725)\n\n","source":"_posts/kubeadm.md","raw":"---\ntitle: kubeadm  kubernetes\ndate: 2019-01-17 10:11:30\ntags: \"kubeadm\"\ntype: \"kubeadm\"\n\n---\n\nkubeadm  Kubernetes  GA\n\n## kubeadm \n\nkubeadm  kubelet kubelet  pod /etc/kubernetes/manifestskubeadm  kubelet  /etc/kubernetes/manifests  etcdkube-apiserverkube-controller-managerkube-scheduler  static pod  yaml  kubelet  yaml  pod kube-apiserverkube-controller-managerkube-scheduler  etcd  static pod \n\n\n>  kubernetes v1.12.0\n\n\n```\n$ uname -r\n3.10.0-514.16.1.el7.x86_64\n\n$ cat /etc/redhat-release\nCentOS Linux release 7.2.1511 (Core)\n```\n## \n```\n# swap\n$ sudo swapoff -a\n\n# selinux\n$ sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux \n$ setenforce 0\n\n# \n$ systemctl disable firewalld.service && systemctl stop firewalld.service\n\n# \n$ cat << EOF >> /etc/sysctl.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nvm.swappiness=0\nEOF \n$ sysctl -p\n```\n\n##  Docker CE \n \n>  docker docker-ce-18.06.1.ce\n\n```\n# Install Docker CE\n## Set up the repository\n### Install required packages.\nyum install yum-utils device-mapper-persistent-data lvm2\n\n### Add docker repository.\nyum-config-manager \\\n    --add-repo \\\n    https://download.docker.com/linux/centos/docker-ce.repo\n\n## Install docker ce.\nyum update && yum install docker-ce-18.06.1.ce\n\n## Create /etc/docker directory.\nmkdir /etc/docker\n\n# Setup daemon.\ncat > /etc/docker/daemon.json <<EOF\n{\n  \"exec-opts\": [\"native.cgroupdriver=systemd\"],\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"100m\"\n  },\n  \"storage-driver\": \"overlay2\",\n  \"storage-opts\": [\n    \"overlay2.override_kernel_check=true\"\n  ]\n}\nEOF\n\nmkdir -p /etc/systemd/system/docker.service.d\n\n# Restart docker.\nsystemctl daemon-reload\nsystemctl restart docker\n```\nhttps://kubernetes.io/docs/setup/cri/\n\n##  kubernetes master \n\n kubeadm \n```\n$ kubeadm init --kubernetes-version=v1.12.0 --pod-network-cidr=10.244.0.0/16\n[init] using Kubernetes version: v1.12.0\n[preflight] running pre-flight checks\n[preflight/images] Pulling images required for setting up a Kubernetes cluster\n[preflight/images] This might take a minute or two, depending on the speed of your internet connection\n[preflight/images] You can also perform this action in beforehand using 'kubeadm config images pull'\n[kubelet] Writing kubelet environment file with flags to file \"/var/lib/kubelet/kubeadm-flags.env\"\n[kubelet] Writing kubelet configuration to file \"/var/lib/kubelet/config.yaml\"\n[preflight] Activating the kubelet service\n[certificates] Using the existing front-proxy-client certificate and key.\n[certificates] Using the existing etcd/server certificate and key.\n[certificates] Using the existing etcd/peer certificate and key.\n[certificates] Using the existing etcd/healthcheck-client certificate and key.\n[certificates] Using the existing apiserver-etcd-client certificate and key.\n[certificates] Using the existing apiserver certificate and key.\n[certificates] Using the existing apiserver-kubelet-client certificate and key.\n[certificates] valid certificates and keys now exist in \"/etc/kubernetes/pki\"\n[certificates] Using the existing sa key.\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/admin.conf\"\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/kubelet.conf\"\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/controller-manager.conf\"\n[kubeconfig] Using existing up-to-date KubeConfig file: \"/etc/kubernetes/scheduler.conf\"\n[controlplane] wrote Static Pod manifest for component kube-apiserver to \"/etc/kubernetes/manifests/kube-apiserver.yaml\"\n[controlplane] wrote Static Pod manifest for component kube-controller-manager to \"/etc/kubernetes/manifests/kube-controller-manager.yaml\"\n[controlplane] wrote Static Pod manifest for component kube-scheduler to \"/etc/kubernetes/manifests/kube-scheduler.yaml\"\n[etcd] Wrote Static Pod manifest for a local etcd instance to \"/etc/kubernetes/manifests/etcd.yaml\"\n[init] waiting for the kubelet to boot up the control plane as Static Pods from directory \"/etc/kubernetes/manifests\"\n[init] this might take a minute or longer if the control plane images have to be pulled\n[apiclient] All control plane components are healthy after 14.002350 seconds\n[uploadconfig] storing the configuration used in ConfigMap \"kubeadm-config\" in the \"kube-system\" Namespace\n[kubelet] Creating a ConfigMap \"kubelet-config-1.12\" in namespace kube-system with the configuration for the kubelets in the cluster\n[markmaster] Marking the node 192.168.1.110 as master by adding the label \"node-role.kubernetes.io/master=''\"\n[markmaster] Marking the node 192.168.1.110 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]\n[patchnode] Uploading the CRI Socket information \"/var/run/dockershim.sock\" to the Node API object \"192.168.1.110\" as an annotation\n[bootstraptoken] using token: wu5hfy.lkuz9fih6hlqe1jt\n[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[bootstraptoken] creating the \"cluster-info\" ConfigMap in the \"kube-public\" namespace\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\nYour Kubernetes master has initialized successfully!\n\nTo start using your cluster, you need to run the following as a regular user:\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\nYou should now deploy a pod network to the cluster.\nRun \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at:\n  https://kubernetes.io/docs/concepts/cluster-administration/addons/\n\nYou can now join any number of machines by running the following on each node\nas root:\n\n  kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash sha256:e8d2649fceae9d7f6de94af0b7e294680b87f7d1e207c75c3cb496841b12ec23\n\n```\n\n\n\n- \n-  token\n-  CA  client \n-  kubeconfig  kubelet  API server\n-  Master  Static Pod manifests /etc/kubernetes/manifests \n-  RBAC  Master node \n-  kube-proxy  CoreDNS\n\n\n kubetl  \n```\n $ mkdir -p $HOME/.kube\n $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n $ sudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n node  master \n```\n$ kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash\n```\nkubeadm  master  node  master  taint  taint \n```\n$ kubectl taint nodes --all node-role.kubernetes.io/master-\n```\n\n\n\n```\n$ kubectl get pod -n kube-system\nNAME                                     READY   STATUS             RESTARTS   AGE\ncoredns-99b9bb8bd-pgh5t                  1/1     Running            0          48m\netcd                                     1/1     Running            2          48m\nkube-apiserver                           1/1     Running            1          48m\nkube-controller-manager                  1/1     Running            0          49m\nkube-flannel-ds-amd64-b5rjg              1/1     Running            0          31m\nkube-proxy-c8ktg                         1/1     Running            0          48m\nkube-scheduler                           1/1     Running            2          48m\n```\n\n##  kubernetes \n\nkubernetes  Kubernetes \n- overlay  flannel(udp/vxlanweavecalico(ipip)openvswitch \n- ( iptables )flannel(host-gw)calico(bgp)macvlan \n\nflannel  calico  flannel \n\n\n flannel  RBAC flannel  daemonset \n```\n$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n```\n\n pod \n\n```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx\n  labels:\n    name: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n```\n\n## kubeadm \n\n1:\n```\n$ kubeadm reset\n```\n2\n```\n# \n$ kubeadm upgrade plan\n\n# \n$ kubeadm upgrade apply [version]\n```\n>  1.  kubeadm \n>  2. kubeadm  kubelet  master  kubelet \n\n\n##  case \n\n##### 1flannel pod cidr not assgned\n\n  /etc/kubernetes/manifests/kube-controller-manager.yaml \n\n--allocate-node-cidrs=true\n--cluster-cidr=10.244.0.0/16\n\nhttps://github.com/coreos/flannel/issues/728\n\n##### 2coredns /proc/sys/net/ipv6/conf/eth0/accept_dad: no such file or directory\n\n```\n$ vim /etc/default/grub and change the value of kernel parameter ipv6.disable from 1 to 0 in line\n$ grub2-mkconfig -o /boot/grub2/grub.cfg\n$ shutdown -r now\n```\nhttps://github.com/containernetworking/cni/issues/569\n\n##### 3kubeadm \n\nkubeadm  --cert-dir  CertificatesDir  /etc/kubernetes/pkikubeadm  CA  /etc/kubernetes/pki/ca.crt  /etc/kubernetes/pki/ca.keykubeadm  CA \n\n##### 4kubeadm join  token \n\ntoken 24 token  `kubeadm token create`  token\n\n## \n kubeadm  kubernetes kubeadm kubeadm  master \n\n\n\n[Creating a single master cluster with kubeadm](https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/)\n[kubeadm ](https://github.com/feiskyer/kubernetes-handbook/blob/master/components/kubeadm.md)\n[DockOneKuberneteskubeadm](http://dockone.io/article/4645)\n[centos7.2 k8s v1.11.0](https://segmentfault.com/a/1190000015787725)\n\n","slug":"kubeadm","published":1,"updated":"2019-01-17T02:46:52.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyysyk000otadvor4e2mrs","content":"<p>kubeadm  Kubernetes  GA</p>\n<h2 id=\"kubeadm-\"><a href=\"#kubeadm-\" class=\"headerlink\" title=\"kubeadm \"></a>kubeadm </h2><p>kubeadm  kubelet kubelet  pod /etc/kubernetes/manifestskubeadm  kubelet  /etc/kubernetes/manifests  etcdkube-apiserverkube-controller-managerkube-scheduler  static pod  yaml  kubelet  yaml  pod kube-apiserverkube-controller-managerkube-scheduler  etcd  static pod </p>\n<blockquote>\n<p> kubernetes v1.12.0</p>\n</blockquote>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ uname -r</span><br><span class=\"line\">3.10.0-514.16.1.el7.x86_64</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat /etc/redhat-release</span><br><span class=\"line\">CentOS Linux release 7.2.1511 (Core)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># swap</span><br><span class=\"line\">$ sudo swapoff -a</span><br><span class=\"line\"></span><br><span class=\"line\"># selinux</span><br><span class=\"line\">$ sed -i &apos;s/SELINUX=permissive/SELINUX=disabled/&apos; /etc/sysconfig/selinux </span><br><span class=\"line\">$ setenforce 0</span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">$ systemctl disable firewalld.service &amp;&amp; systemctl stop firewalld.service</span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">$ cat &lt;&lt; EOF &gt;&gt; /etc/sysctl.conf</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">vm.swappiness=0</span><br><span class=\"line\">EOF </span><br><span class=\"line\">$ sysctl -p</span><br></pre></td></tr></table></figure>\n<h2 id=\"-Docker-CE\"><a href=\"#-Docker-CE\" class=\"headerlink\" title=\" Docker CE\"></a> Docker CE</h2><blockquote>\n<p> docker docker-ce-18.06.1.ce</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Install Docker CE</span><br><span class=\"line\">## Set up the repository</span><br><span class=\"line\">### Install required packages.</span><br><span class=\"line\">yum install yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"></span><br><span class=\"line\">### Add docker repository.</span><br><span class=\"line\">yum-config-manager \\</span><br><span class=\"line\">    --add-repo \\</span><br><span class=\"line\">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class=\"line\"></span><br><span class=\"line\">## Install docker ce.</span><br><span class=\"line\">yum update &amp;&amp; yum install docker-ce-18.06.1.ce</span><br><span class=\"line\"></span><br><span class=\"line\">## Create /etc/docker directory.</span><br><span class=\"line\">mkdir /etc/docker</span><br><span class=\"line\"></span><br><span class=\"line\"># Setup daemon.</span><br><span class=\"line\">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class=\"line\">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class=\"line\">  &quot;log-opts&quot;: &#123;</span><br><span class=\"line\">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class=\"line\">  &quot;storage-opts&quot;: [</span><br><span class=\"line\">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">mkdir -p /etc/systemd/system/docker.service.d</span><br><span class=\"line\"></span><br><span class=\"line\"># Restart docker.</span><br><span class=\"line\">systemctl daemon-reload</span><br><span class=\"line\">systemctl restart docker</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://kubernetes.io/docs/setup/cri/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/setup/cri/</a></p>\n<h2 id=\"-kubernetes-master-\"><a href=\"#-kubernetes-master-\" class=\"headerlink\" title=\" kubernetes master \"></a> kubernetes master </h2><p> kubeadm <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm init --kubernetes-version=v1.12.0 --pod-network-cidr=10.244.0.0/16</span><br><span class=\"line\">[init] using Kubernetes version: v1.12.0</span><br><span class=\"line\">[preflight] running pre-flight checks</span><br><span class=\"line\">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class=\"line\">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"line\">[preflight] Activating the kubelet service</span><br><span class=\"line\">[certificates] Using the existing front-proxy-client certificate and key.</span><br><span class=\"line\">[certificates] Using the existing etcd/server certificate and key.</span><br><span class=\"line\">[certificates] Using the existing etcd/peer certificate and key.</span><br><span class=\"line\">[certificates] Using the existing etcd/healthcheck-client certificate and key.</span><br><span class=\"line\">[certificates] Using the existing apiserver-etcd-client certificate and key.</span><br><span class=\"line\">[certificates] Using the existing apiserver certificate and key.</span><br><span class=\"line\">[certificates] Using the existing apiserver-kubelet-client certificate and key.</span><br><span class=\"line\">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class=\"line\">[certificates] Using the existing sa key.</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class=\"line\">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class=\"line\">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class=\"line\">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class=\"line\">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class=\"line\">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 14.002350 seconds</span><br><span class=\"line\">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.12&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[markmaster] Marking the node 192.168.1.110 as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class=\"line\">[markmaster] Marking the node 192.168.1.110 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"line\">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;192.168.1.110&quot; as an annotation</span><br><span class=\"line\">[bootstraptoken] using token: wu5hfy.lkuz9fih6hlqe1jt</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes master has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of machines by running the following on each node</span><br><span class=\"line\">as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash sha256:e8d2649fceae9d7f6de94af0b7e294680b87f7d1e207c75c3cb496841b12ec23</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<ul>\n<li></li>\n<li> token</li>\n<li> CA  client </li>\n<li> kubeconfig  kubelet  API server</li>\n<li> Master  Static Pod manifests /etc/kubernetes/manifests </li>\n<li> RBAC  Master node </li>\n<li> kube-proxy  CoreDNS</li>\n</ul>\n<p> kubetl <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -p $HOME/.kube</span><br><span class=\"line\">$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></p>\n<p> node  master <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash</span><br></pre></td></tr></table></figure></p>\n<p>kubeadm  master  node  master  taint  taint <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl taint nodes --all node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -n kube-system</span><br><span class=\"line\">NAME                                     READY   STATUS             RESTARTS   AGE</span><br><span class=\"line\">coredns-99b9bb8bd-pgh5t                  1/1     Running            0          48m</span><br><span class=\"line\">etcd                                     1/1     Running            2          48m</span><br><span class=\"line\">kube-apiserver                           1/1     Running            1          48m</span><br><span class=\"line\">kube-controller-manager                  1/1     Running            0          49m</span><br><span class=\"line\">kube-flannel-ds-amd64-b5rjg              1/1     Running            0          31m</span><br><span class=\"line\">kube-proxy-c8ktg                         1/1     Running            0          48m</span><br><span class=\"line\">kube-scheduler                           1/1     Running            2          48m</span><br></pre></td></tr></table></figure>\n<h2 id=\"-kubernetes-\"><a href=\"#-kubernetes-\" class=\"headerlink\" title=\" kubernetes \"></a> kubernetes </h2><p>kubernetes  Kubernetes </p>\n<ul>\n<li>overlay  flannel(udp/vxlanweavecalico(ipip)openvswitch </li>\n<li>( iptables )flannel(host-gw)calico(bgp)macvlan </li>\n</ul>\n<p>flannel  calico  flannel </p>\n<p> flannel  RBAC flannel  daemonset <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></p>\n<p> pod </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    name: nginx</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - name: nginx</span><br><span class=\"line\">    image: nginx</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - containerPort: 80</span><br></pre></td></tr></table></figure>\n<h2 id=\"kubeadm-\"><a href=\"#kubeadm-\" class=\"headerlink\" title=\"kubeadm \"></a>kubeadm </h2><p>1:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm reset</span><br></pre></td></tr></table></figure></p>\n<p>2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># </span><br><span class=\"line\">$ kubeadm upgrade plan</span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">$ kubeadm upgrade apply [version]</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<ol>\n<li> kubeadm </li>\n<li>kubeadm  kubelet  master  kubelet </li>\n</ol>\n</blockquote>\n<h2 id=\"-case-\"><a href=\"#-case-\" class=\"headerlink\" title=\" case \"></a> case </h2><h5 id=\"1flannel-pod-cidr-not-assgned\"><a href=\"#1flannel-pod-cidr-not-assgned\" class=\"headerlink\" title=\"1flannel pod cidr not assgned\"></a>1flannel pod cidr not assgned</h5><p>  /etc/kubernetes/manifests/kube-controller-manager.yaml </p>\n<p>allocate-node-cidrs=true<br>cluster-cidr=10.244.0.0/16</p>\n<p><a href=\"https://github.com/coreos/flannel/issues/728\" target=\"_blank\" rel=\"noopener\">https://github.com/coreos/flannel/issues/728</a></p>\n<h5 id=\"2coredns--proc-sys-net-ipv6-conf-eth0-accept-dad-no-such-file-or-directory\"><a href=\"#2coredns--proc-sys-net-ipv6-conf-eth0-accept-dad-no-such-file-or-directory\" class=\"headerlink\" title=\"2coredns /proc/sys/net/ipv6/conf/eth0/accept_dad: no such file or directory\"></a>2coredns /proc/sys/net/ipv6/conf/eth0/accept_dad: no such file or directory</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim /etc/default/grub and change the value of kernel parameter ipv6.disable from 1 to 0 in line</span><br><span class=\"line\">$ grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class=\"line\">$ shutdown -r now</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://github.com/containernetworking/cni/issues/569\" target=\"_blank\" rel=\"noopener\">https://github.com/containernetworking/cni/issues/569</a></p>\n<h5 id=\"3kubeadm-\"><a href=\"#3kubeadm-\" class=\"headerlink\" title=\"3kubeadm \"></a>3kubeadm </h5><p>kubeadm  cert-dir  CertificatesDir  /etc/kubernetes/pkikubeadm  CA  /etc/kubernetes/pki/ca.crt  /etc/kubernetes/pki/ca.keykubeadm  CA </p>\n<h5 id=\"4kubeadm-join--token-\"><a href=\"#4kubeadm-join--token-\" class=\"headerlink\" title=\"4kubeadm join  token \"></a>4kubeadm join  token </h5><p>token 24 token  <code>kubeadm token create</code>  token</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> kubeadm  kubernetes kubeadm kubeadm  master </p>\n<p><br><a href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\" target=\"_blank\" rel=\"noopener\">Creating a single master cluster with kubeadm</a><br><a href=\"https://github.com/feiskyer/kubernetes-handbook/blob/master/components/kubeadm.md\" target=\"_blank\" rel=\"noopener\">kubeadm </a><br><a href=\"http://dockone.io/article/4645\" target=\"_blank\" rel=\"noopener\">DockOneKuberneteskubeadm</a><br><a href=\"https://segmentfault.com/a/1190000015787725\" target=\"_blank\" rel=\"noopener\">centos7.2 k8s v1.11.0</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>kubeadm  Kubernetes  GA</p>\n<h2 id=\"kubeadm-\"><a href=\"#kubeadm-\" class=\"headerlink\" title=\"kubeadm \"></a>kubeadm </h2><p>kubeadm  kubelet kubelet  pod /etc/kubernetes/manifestskubeadm  kubelet  /etc/kubernetes/manifests  etcdkube-apiserverkube-controller-managerkube-scheduler  static pod  yaml  kubelet  yaml  pod kube-apiserverkube-controller-managerkube-scheduler  etcd  static pod </p>\n<blockquote>\n<p> kubernetes v1.12.0</p>\n</blockquote>\n<p><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ uname -r</span><br><span class=\"line\">3.10.0-514.16.1.el7.x86_64</span><br><span class=\"line\"></span><br><span class=\"line\">$ cat /etc/redhat-release</span><br><span class=\"line\">CentOS Linux release 7.2.1511 (Core)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># swap</span><br><span class=\"line\">$ sudo swapoff -a</span><br><span class=\"line\"></span><br><span class=\"line\"># selinux</span><br><span class=\"line\">$ sed -i &apos;s/SELINUX=permissive/SELINUX=disabled/&apos; /etc/sysconfig/selinux </span><br><span class=\"line\">$ setenforce 0</span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">$ systemctl disable firewalld.service &amp;&amp; systemctl stop firewalld.service</span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">$ cat &lt;&lt; EOF &gt;&gt; /etc/sysctl.conf</span><br><span class=\"line\">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class=\"line\">net.bridge.bridge-nf-call-iptables = 1</span><br><span class=\"line\">vm.swappiness=0</span><br><span class=\"line\">EOF </span><br><span class=\"line\">$ sysctl -p</span><br></pre></td></tr></table></figure>\n<h2 id=\"-Docker-CE\"><a href=\"#-Docker-CE\" class=\"headerlink\" title=\" Docker CE\"></a> Docker CE</h2><blockquote>\n<p> docker docker-ce-18.06.1.ce</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Install Docker CE</span><br><span class=\"line\">## Set up the repository</span><br><span class=\"line\">### Install required packages.</span><br><span class=\"line\">yum install yum-utils device-mapper-persistent-data lvm2</span><br><span class=\"line\"></span><br><span class=\"line\">### Add docker repository.</span><br><span class=\"line\">yum-config-manager \\</span><br><span class=\"line\">    --add-repo \\</span><br><span class=\"line\">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class=\"line\"></span><br><span class=\"line\">## Install docker ce.</span><br><span class=\"line\">yum update &amp;&amp; yum install docker-ce-18.06.1.ce</span><br><span class=\"line\"></span><br><span class=\"line\">## Create /etc/docker directory.</span><br><span class=\"line\">mkdir /etc/docker</span><br><span class=\"line\"></span><br><span class=\"line\"># Setup daemon.</span><br><span class=\"line\">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;],</span><br><span class=\"line\">  &quot;log-driver&quot;: &quot;json-file&quot;,</span><br><span class=\"line\">  &quot;log-opts&quot;: &#123;</span><br><span class=\"line\">    &quot;max-size&quot;: &quot;100m&quot;</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class=\"line\">  &quot;storage-opts&quot;: [</span><br><span class=\"line\">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class=\"line\">  ]</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">EOF</span><br><span class=\"line\"></span><br><span class=\"line\">mkdir -p /etc/systemd/system/docker.service.d</span><br><span class=\"line\"></span><br><span class=\"line\"># Restart docker.</span><br><span class=\"line\">systemctl daemon-reload</span><br><span class=\"line\">systemctl restart docker</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://kubernetes.io/docs/setup/cri/\" target=\"_blank\" rel=\"noopener\">https://kubernetes.io/docs/setup/cri/</a></p>\n<h2 id=\"-kubernetes-master-\"><a href=\"#-kubernetes-master-\" class=\"headerlink\" title=\" kubernetes master \"></a> kubernetes master </h2><p> kubeadm <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm init --kubernetes-version=v1.12.0 --pod-network-cidr=10.244.0.0/16</span><br><span class=\"line\">[init] using Kubernetes version: v1.12.0</span><br><span class=\"line\">[preflight] running pre-flight checks</span><br><span class=\"line\">[preflight/images] Pulling images required for setting up a Kubernetes cluster</span><br><span class=\"line\">[preflight/images] This might take a minute or two, depending on the speed of your internet connection</span><br><span class=\"line\">[preflight/images] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class=\"line\">[kubelet] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class=\"line\">[kubelet] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class=\"line\">[preflight] Activating the kubelet service</span><br><span class=\"line\">[certificates] Using the existing front-proxy-client certificate and key.</span><br><span class=\"line\">[certificates] Using the existing etcd/server certificate and key.</span><br><span class=\"line\">[certificates] Using the existing etcd/peer certificate and key.</span><br><span class=\"line\">[certificates] Using the existing etcd/healthcheck-client certificate and key.</span><br><span class=\"line\">[certificates] Using the existing apiserver-etcd-client certificate and key.</span><br><span class=\"line\">[certificates] Using the existing apiserver certificate and key.</span><br><span class=\"line\">[certificates] Using the existing apiserver-kubelet-client certificate and key.</span><br><span class=\"line\">[certificates] valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;</span><br><span class=\"line\">[certificates] Using the existing sa key.</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/admin.conf&quot;</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/kubelet.conf&quot;</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/controller-manager.conf&quot;</span><br><span class=\"line\">[kubeconfig] Using existing up-to-date KubeConfig file: &quot;/etc/kubernetes/scheduler.conf&quot;</span><br><span class=\"line\">[controlplane] wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;</span><br><span class=\"line\">[controlplane] wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;</span><br><span class=\"line\">[controlplane] wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;</span><br><span class=\"line\">[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;</span><br><span class=\"line\">[init] waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;</span><br><span class=\"line\">[init] this might take a minute or longer if the control plane images have to be pulled</span><br><span class=\"line\">[apiclient] All control plane components are healthy after 14.002350 seconds</span><br><span class=\"line\">[uploadconfig] storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class=\"line\">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.12&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class=\"line\">[markmaster] Marking the node 192.168.1.110 as master by adding the label &quot;node-role.kubernetes.io/master=&apos;&apos;&quot;</span><br><span class=\"line\">[markmaster] Marking the node 192.168.1.110 as master by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class=\"line\">[patchnode] Uploading the CRI Socket information &quot;/var/run/dockershim.sock&quot; to the Node API object &quot;192.168.1.110&quot; as an annotation</span><br><span class=\"line\">[bootstraptoken] using token: wu5hfy.lkuz9fih6hlqe1jt</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class=\"line\">[bootstraptoken] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class=\"line\">[bootstraptoken] creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class=\"line\">[addons] Applied essential addon: CoreDNS</span><br><span class=\"line\">[addons] Applied essential addon: kube-proxy</span><br><span class=\"line\"></span><br><span class=\"line\">Your Kubernetes master has initialized successfully!</span><br><span class=\"line\"></span><br><span class=\"line\">To start using your cluster, you need to run the following as a regular user:</span><br><span class=\"line\"></span><br><span class=\"line\">  mkdir -p $HOME/.kube</span><br><span class=\"line\">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class=\"line\"></span><br><span class=\"line\">You should now deploy a pod network to the cluster.</span><br><span class=\"line\">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class=\"line\">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class=\"line\"></span><br><span class=\"line\">You can now join any number of machines by running the following on each node</span><br><span class=\"line\">as root:</span><br><span class=\"line\"></span><br><span class=\"line\">  kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash sha256:e8d2649fceae9d7f6de94af0b7e294680b87f7d1e207c75c3cb496841b12ec23</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<ul>\n<li></li>\n<li> token</li>\n<li> CA  client </li>\n<li> kubeconfig  kubelet  API server</li>\n<li> Master  Static Pod manifests /etc/kubernetes/manifests </li>\n<li> RBAC  Master node </li>\n<li> kube-proxy  CoreDNS</li>\n</ul>\n<p> kubetl <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir -p $HOME/.kube</span><br><span class=\"line\">$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class=\"line\">$ sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure></p>\n<p> node  master <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm join 192.168.1.110:6443 --token wu5hfy.lkuz9fih6hlqe1jt --discovery-token-ca-cert-hash</span><br></pre></td></tr></table></figure></p>\n<p>kubeadm  master  node  master  taint  taint <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl taint nodes --all node-role.kubernetes.io/master-</span><br></pre></td></tr></table></figure></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get pod -n kube-system</span><br><span class=\"line\">NAME                                     READY   STATUS             RESTARTS   AGE</span><br><span class=\"line\">coredns-99b9bb8bd-pgh5t                  1/1     Running            0          48m</span><br><span class=\"line\">etcd                                     1/1     Running            2          48m</span><br><span class=\"line\">kube-apiserver                           1/1     Running            1          48m</span><br><span class=\"line\">kube-controller-manager                  1/1     Running            0          49m</span><br><span class=\"line\">kube-flannel-ds-amd64-b5rjg              1/1     Running            0          31m</span><br><span class=\"line\">kube-proxy-c8ktg                         1/1     Running            0          48m</span><br><span class=\"line\">kube-scheduler                           1/1     Running            2          48m</span><br></pre></td></tr></table></figure>\n<h2 id=\"-kubernetes-\"><a href=\"#-kubernetes-\" class=\"headerlink\" title=\" kubernetes \"></a> kubernetes </h2><p>kubernetes  Kubernetes </p>\n<ul>\n<li>overlay  flannel(udp/vxlanweavecalico(ipip)openvswitch </li>\n<li>( iptables )flannel(host-gw)calico(bgp)macvlan </li>\n</ul>\n<p>flannel  calico  flannel </p>\n<p> flannel  RBAC flannel  daemonset <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure></p>\n<p> pod </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: Pod</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: nginx</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    name: nginx</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  containers:</span><br><span class=\"line\">  - name: nginx</span><br><span class=\"line\">    image: nginx</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - containerPort: 80</span><br></pre></td></tr></table></figure>\n<h2 id=\"kubeadm-\"><a href=\"#kubeadm-\" class=\"headerlink\" title=\"kubeadm \"></a>kubeadm </h2><p>1:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubeadm reset</span><br></pre></td></tr></table></figure></p>\n<p>2<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># </span><br><span class=\"line\">$ kubeadm upgrade plan</span><br><span class=\"line\"></span><br><span class=\"line\"># </span><br><span class=\"line\">$ kubeadm upgrade apply [version]</span><br></pre></td></tr></table></figure></p>\n<blockquote>\n<ol>\n<li> kubeadm </li>\n<li>kubeadm  kubelet  master  kubelet </li>\n</ol>\n</blockquote>\n<h2 id=\"-case-\"><a href=\"#-case-\" class=\"headerlink\" title=\" case \"></a> case </h2><h5 id=\"1flannel-pod-cidr-not-assgned\"><a href=\"#1flannel-pod-cidr-not-assgned\" class=\"headerlink\" title=\"1flannel pod cidr not assgned\"></a>1flannel pod cidr not assgned</h5><p>  /etc/kubernetes/manifests/kube-controller-manager.yaml </p>\n<p>allocate-node-cidrs=true<br>cluster-cidr=10.244.0.0/16</p>\n<p><a href=\"https://github.com/coreos/flannel/issues/728\" target=\"_blank\" rel=\"noopener\">https://github.com/coreos/flannel/issues/728</a></p>\n<h5 id=\"2coredns--proc-sys-net-ipv6-conf-eth0-accept-dad-no-such-file-or-directory\"><a href=\"#2coredns--proc-sys-net-ipv6-conf-eth0-accept-dad-no-such-file-or-directory\" class=\"headerlink\" title=\"2coredns /proc/sys/net/ipv6/conf/eth0/accept_dad: no such file or directory\"></a>2coredns /proc/sys/net/ipv6/conf/eth0/accept_dad: no such file or directory</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim /etc/default/grub and change the value of kernel parameter ipv6.disable from 1 to 0 in line</span><br><span class=\"line\">$ grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class=\"line\">$ shutdown -r now</span><br></pre></td></tr></table></figure>\n<p><a href=\"https://github.com/containernetworking/cni/issues/569\" target=\"_blank\" rel=\"noopener\">https://github.com/containernetworking/cni/issues/569</a></p>\n<h5 id=\"3kubeadm-\"><a href=\"#3kubeadm-\" class=\"headerlink\" title=\"3kubeadm \"></a>3kubeadm </h5><p>kubeadm  cert-dir  CertificatesDir  /etc/kubernetes/pkikubeadm  CA  /etc/kubernetes/pki/ca.crt  /etc/kubernetes/pki/ca.keykubeadm  CA </p>\n<h5 id=\"4kubeadm-join--token-\"><a href=\"#4kubeadm-join--token-\" class=\"headerlink\" title=\"4kubeadm join  token \"></a>4kubeadm join  token </h5><p>token 24 token  <code>kubeadm token create</code>  token</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> kubeadm  kubernetes kubeadm kubeadm  master </p>\n<p><br><a href=\"https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/\" target=\"_blank\" rel=\"noopener\">Creating a single master cluster with kubeadm</a><br><a href=\"https://github.com/feiskyer/kubernetes-handbook/blob/master/components/kubeadm.md\" target=\"_blank\" rel=\"noopener\">kubeadm </a><br><a href=\"http://dockone.io/article/4645\" target=\"_blank\" rel=\"noopener\">DockOneKuberneteskubeadm</a><br><a href=\"https://segmentfault.com/a/1190000015787725\" target=\"_blank\" rel=\"noopener\">centos7.2 k8s v1.11.0</a></p>\n"},{"title":"kubelet ","date":"2018-12-16T09:35:30.000Z","type":"kubelet","_content":"\n## \nkubelet  kubelet Master  PodSpec Pod PodSpec  pod  YAML  JSON \n\nkubelet  apiserver  PodSpec  PodSpec \n\n## kubelet \n\n1kubelet   10250 10255102484194\n\n```\nLISTEN     0      128          *:10250                    *:*                   users:((\"kubelet\",pid=48500,fd=28))\nLISTEN     0      128          *:10255                    *:*                   users:((\"kubelet\",pid=48500,fd=26))\nLISTEN     0      128          *:4194                     *:*                   users:((\"kubelet\",pid=48500,fd=13))\nLISTEN     0      128    127.0.0.1:10248                    *:*                   users:((\"kubelet\",pid=48500,fd=23))\n```\n\n- 10250kubelet APIkubelet server  apiserver  apiserver  node \n\n- 10248 kubelet ,  kubelet  `--healthz-port`  `--healthz-bind-address` \n```\n  $ curl http://127.0.0.1:10248/healthz\n  ok\n```\n- 4194cAdvisor kublet  node  http://localhost:4194  cAdvisor , kubelet  `--cadvisor-port` \n\n```\n  $ curl  http://127.0.0.1:4194/metrics\n```\n\n- 10255 readonly API pod  node \n``` \n  //   pod  apiserver  \n  // http://127.0.0.1:8080/api/v1/pods?fieldSelector=spec.nodeName=  \n  $ curl  http://127.0.0.1:10255/pods\n\n  // ,CPU\n  $ curl http://127.0.0.1:10255/spec/\n```\n\n2kubelet \n\n- pod kubelet  pod/container \n\n- kubelet  pod \n\n- kubelet  master  cAdvisor  pod \n\n\n## kubelet \n\n ![kubelet ](https://upload-images.jianshu.io/upload_images/1262158-91b13623d3cf45ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n kubelet \n\n- 1PLEG(Pod Lifecycle Event Generator\nPLEG  kubelet ,PLEG  container runtime  containers/sandboxes  pods cache  PodLifecycleEvent eventChannel  eventChannel  kubelet syncLoop  kubelet syncPod  pod \n\n- 2cAdvisor \ncAdvisorhttps://github.com/google/cadvisor google  kubelet  cAdvisor  cAvisor  interface  imageManagerOOMWatchercontainerManager \n\n- 3OOMWatcher \n OOM  cadvisor  SystemOOM, Watch cadvisor  OOM \n\n- 4probeManager \nprobeManager  statusManager,livenessManager,containerRefManager pod livenessProbe readinessProbe\nlivenessProbekubelet  kill \nreadinessProbe pod  service  endpoints readinessProbe  livenessProbe httptcp  cmd \n\n- 5statusManager \nstatusManager  pod  apiserver pod  probeManager\n\n- 6containerRefManager\nManager map  containerID  v1.ObjectReferece \n\n- 7evictionManager \n inode  evict  node  pressure  kubelet  qosClass  pod kubelet  `--eviction-hard=`  evict \n\n- 8imageGC \nimageGC  node  pod  kubelet  `--image-gc-high-threshold`  `--image-gc-low-threshold` \n\n- 9containerGC \ncontainerGC  node  container GC runtime \n\n- 10imageManager \n kubecontainer PullImage/GetImageRef/ListImages/RemoveImage/ImageStates pod \n\n- 11volumeManager \n node  pod  volume volume  pod  pod  volume  mount/umount/attach/detach kubernetes  volume Plugins \n\n- 12containerManager \n node  cgroup kubelet  `--cgroups-per-qos` kubelet  goroutine  pod  cgroup  `true` pod Guaranteed/BestEffort/Burstable  Qos\n\n- 13runtimeManager \ncontainerRuntime  kubelet  runtime  container  runtime  kubelet  `--container-runtime` docker  rkt `docker`\n\n- 14podManager \npodManager  pod  static pod  mirror pods podManager statusManager/volumeManager/runtimeManager podManager  secretManager  configMapManager \n\n\n v1.12 kubelet 18 manager\n\n```\ncertificateManager\ncgroupManager\ncontainerManager\ncpuManager\nnodeContainerManager\nconfigmapManager\ncontainerReferenceManager\nevictionManager\nnvidiaGpuManager\nimageGCManager\nkuberuntimeManager\nhostportManager\npodManager\nproberManager\nsecretManager\nstatusManager\nvolumeManager\t\ntokenManager\n```\n\n\n\n\n\n[ K8S ](https://juejin.im/entry/5bc71b3d6fb9a05cf23029b8)\n[kubernetes  kubelet  pod](https://cizixs.com/2016/10/25/kubernetes-intro-kubelet/)\n[Kubelet ](https://blog.csdn.net/jettery/article/details/78891733)\n\n\n\n","source":"_posts/kubelet-modules.md","raw":"---\ntitle: kubelet \ndate: 2018-12-16 17:35:30\ntags: \"kubelet\"\ntype: \"kubelet\"\n\n---\n\n## \nkubelet  kubelet Master  PodSpec Pod PodSpec  pod  YAML  JSON \n\nkubelet  apiserver  PodSpec  PodSpec \n\n## kubelet \n\n1kubelet   10250 10255102484194\n\n```\nLISTEN     0      128          *:10250                    *:*                   users:((\"kubelet\",pid=48500,fd=28))\nLISTEN     0      128          *:10255                    *:*                   users:((\"kubelet\",pid=48500,fd=26))\nLISTEN     0      128          *:4194                     *:*                   users:((\"kubelet\",pid=48500,fd=13))\nLISTEN     0      128    127.0.0.1:10248                    *:*                   users:((\"kubelet\",pid=48500,fd=23))\n```\n\n- 10250kubelet APIkubelet server  apiserver  apiserver  node \n\n- 10248 kubelet ,  kubelet  `--healthz-port`  `--healthz-bind-address` \n```\n  $ curl http://127.0.0.1:10248/healthz\n  ok\n```\n- 4194cAdvisor kublet  node  http://localhost:4194  cAdvisor , kubelet  `--cadvisor-port` \n\n```\n  $ curl  http://127.0.0.1:4194/metrics\n```\n\n- 10255 readonly API pod  node \n``` \n  //   pod  apiserver  \n  // http://127.0.0.1:8080/api/v1/pods?fieldSelector=spec.nodeName=  \n  $ curl  http://127.0.0.1:10255/pods\n\n  // ,CPU\n  $ curl http://127.0.0.1:10255/spec/\n```\n\n2kubelet \n\n- pod kubelet  pod/container \n\n- kubelet  pod \n\n- kubelet  master  cAdvisor  pod \n\n\n## kubelet \n\n ![kubelet ](https://upload-images.jianshu.io/upload_images/1262158-91b13623d3cf45ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n kubelet \n\n- 1PLEG(Pod Lifecycle Event Generator\nPLEG  kubelet ,PLEG  container runtime  containers/sandboxes  pods cache  PodLifecycleEvent eventChannel  eventChannel  kubelet syncLoop  kubelet syncPod  pod \n\n- 2cAdvisor \ncAdvisorhttps://github.com/google/cadvisor google  kubelet  cAdvisor  cAvisor  interface  imageManagerOOMWatchercontainerManager \n\n- 3OOMWatcher \n OOM  cadvisor  SystemOOM, Watch cadvisor  OOM \n\n- 4probeManager \nprobeManager  statusManager,livenessManager,containerRefManager pod livenessProbe readinessProbe\nlivenessProbekubelet  kill \nreadinessProbe pod  service  endpoints readinessProbe  livenessProbe httptcp  cmd \n\n- 5statusManager \nstatusManager  pod  apiserver pod  probeManager\n\n- 6containerRefManager\nManager map  containerID  v1.ObjectReferece \n\n- 7evictionManager \n inode  evict  node  pressure  kubelet  qosClass  pod kubelet  `--eviction-hard=`  evict \n\n- 8imageGC \nimageGC  node  pod  kubelet  `--image-gc-high-threshold`  `--image-gc-low-threshold` \n\n- 9containerGC \ncontainerGC  node  container GC runtime \n\n- 10imageManager \n kubecontainer PullImage/GetImageRef/ListImages/RemoveImage/ImageStates pod \n\n- 11volumeManager \n node  pod  volume volume  pod  pod  volume  mount/umount/attach/detach kubernetes  volume Plugins \n\n- 12containerManager \n node  cgroup kubelet  `--cgroups-per-qos` kubelet  goroutine  pod  cgroup  `true` pod Guaranteed/BestEffort/Burstable  Qos\n\n- 13runtimeManager \ncontainerRuntime  kubelet  runtime  container  runtime  kubelet  `--container-runtime` docker  rkt `docker`\n\n- 14podManager \npodManager  pod  static pod  mirror pods podManager statusManager/volumeManager/runtimeManager podManager  secretManager  configMapManager \n\n\n v1.12 kubelet 18 manager\n\n```\ncertificateManager\ncgroupManager\ncontainerManager\ncpuManager\nnodeContainerManager\nconfigmapManager\ncontainerReferenceManager\nevictionManager\nnvidiaGpuManager\nimageGCManager\nkuberuntimeManager\nhostportManager\npodManager\nproberManager\nsecretManager\nstatusManager\nvolumeManager\t\ntokenManager\n```\n\n\n\n\n\n[ K8S ](https://juejin.im/entry/5bc71b3d6fb9a05cf23029b8)\n[kubernetes  kubelet  pod](https://cizixs.com/2016/10/25/kubernetes-intro-kubelet/)\n[Kubelet ](https://blog.csdn.net/jettery/article/details/78891733)\n\n\n\n","slug":"kubelet-modules","published":1,"updated":"2018-12-16T09:47:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyysyl000qtadv1qhhfbc9","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>kubelet  kubelet Master  PodSpec Pod PodSpec  pod  YAML  JSON </p>\n<p>kubelet  apiserver  PodSpec  PodSpec </p>\n<h2 id=\"kubelet-\"><a href=\"#kubelet-\" class=\"headerlink\" title=\"kubelet \"></a>kubelet </h2><p>1kubelet   10250 10255102484194</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LISTEN     0      128          *:10250                    *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=28))</span><br><span class=\"line\">LISTEN     0      128          *:10255                    *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=26))</span><br><span class=\"line\">LISTEN     0      128          *:4194                     *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=13))</span><br><span class=\"line\">LISTEN     0      128    127.0.0.1:10248                    *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=23))</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>10250kubelet APIkubelet server  apiserver  apiserver  node </p>\n</li>\n<li><p>10248 kubelet ,  kubelet  <code>--healthz-port</code>  <code>--healthz-bind-address</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl http://127.0.0.1:10248/healthz</span><br><span class=\"line\">ok</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>4194cAdvisor kublet  node  <a href=\"http://localhost:4194\" target=\"_blank\" rel=\"noopener\">http://localhost:4194</a>  cAdvisor , kubelet  <code>--cadvisor-port</code> </p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl  http://127.0.0.1:4194/metrics</span><br></pre></td></tr></table></figure>\n<ul>\n<li>10255 readonly API pod  node <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//   pod  apiserver  </span><br><span class=\"line\">// http://127.0.0.1:8080/api/v1/pods?fieldSelector=spec.nodeName=  </span><br><span class=\"line\">$ curl  http://127.0.0.1:10255/pods</span><br><span class=\"line\"></span><br><span class=\"line\">// ,CPU</span><br><span class=\"line\">$ curl http://127.0.0.1:10255/spec/</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>2kubelet </p>\n<ul>\n<li><p>pod kubelet  pod/container </p>\n</li>\n<li><p>kubelet  pod </p>\n</li>\n<li><p>kubelet  master  cAdvisor  pod </p>\n</li>\n</ul>\n<h2 id=\"kubelet-\"><a href=\"#kubelet-\" class=\"headerlink\" title=\"kubelet \"></a>kubelet </h2><p> <img src=\"https://upload-images.jianshu.io/upload_images/1262158-91b13623d3cf45ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet \"></p>\n<p> kubelet </p>\n<ul>\n<li><p>1PLEG(Pod Lifecycle Event Generator<br>PLEG  kubelet ,PLEG  container runtime  containers/sandboxes  pods cache  PodLifecycleEvent eventChannel  eventChannel  kubelet syncLoop  kubelet syncPod  pod </p>\n</li>\n<li><p>2cAdvisor<br>cAdvisor<a href=\"https://github.com/google/cadvisor\" target=\"_blank\" rel=\"noopener\">https://github.com/google/cadvisor</a> google  kubelet  cAdvisor  cAvisor  interface  imageManagerOOMWatchercontainerManager </p>\n</li>\n<li><p>3OOMWatcher<br> OOM  cadvisor  SystemOOM, Watch cadvisor  OOM </p>\n</li>\n<li><p>4probeManager<br>probeManager  statusManager,livenessManager,containerRefManager pod livenessProbe readinessProbe<br>livenessProbekubelet  kill <br>readinessProbe pod  service  endpoints readinessProbe  livenessProbe httptcp  cmd </p>\n</li>\n<li><p>5statusManager<br>statusManager  pod  apiserver pod  probeManager</p>\n</li>\n<li><p>6containerRefManager<br>Manager map  containerID  v1.ObjectReferece </p>\n</li>\n<li><p>7evictionManager<br> inode  evict  node  pressure  kubelet  qosClass  pod kubelet  <code>--eviction-hard=</code>  evict </p>\n</li>\n<li><p>8imageGC<br>imageGC  node  pod  kubelet  <code>--image-gc-high-threshold</code>  <code>--image-gc-low-threshold</code> </p>\n</li>\n<li><p>9containerGC<br>containerGC  node  container GC runtime </p>\n</li>\n<li><p>10imageManager<br> kubecontainer PullImage/GetImageRef/ListImages/RemoveImage/ImageStates pod </p>\n</li>\n<li><p>11volumeManager<br> node  pod  volume volume  pod  pod  volume  mount/umount/attach/detach kubernetes  volume Plugins </p>\n</li>\n<li><p>12containerManager<br> node  cgroup kubelet  <code>--cgroups-per-qos</code> kubelet  goroutine  pod  cgroup  <code>true</code> pod Guaranteed/BestEffort/Burstable  Qos</p>\n</li>\n<li><p>13runtimeManager<br>containerRuntime  kubelet  runtime  container  runtime  kubelet  <code>--container-runtime</code> docker  rkt <code>docker</code></p>\n</li>\n<li><p>14podManager<br>podManager  pod  static pod  mirror pods podManager statusManager/volumeManager/runtimeManager podManager  secretManager  configMapManager </p>\n</li>\n</ul>\n<p> v1.12 kubelet 18 manager</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">certificateManager</span><br><span class=\"line\">cgroupManager</span><br><span class=\"line\">containerManager</span><br><span class=\"line\">cpuManager</span><br><span class=\"line\">nodeContainerManager</span><br><span class=\"line\">configmapManager</span><br><span class=\"line\">containerReferenceManager</span><br><span class=\"line\">evictionManager</span><br><span class=\"line\">nvidiaGpuManager</span><br><span class=\"line\">imageGCManager</span><br><span class=\"line\">kuberuntimeManager</span><br><span class=\"line\">hostportManager</span><br><span class=\"line\">podManager</span><br><span class=\"line\">proberManager</span><br><span class=\"line\">secretManager</span><br><span class=\"line\">statusManager</span><br><span class=\"line\">volumeManager\t</span><br><span class=\"line\">tokenManager</span><br></pre></td></tr></table></figure>\n<p></p>\n<p><br><a href=\"https://juejin.im/entry/5bc71b3d6fb9a05cf23029b8\" target=\"_blank\" rel=\"noopener\"> K8S </a><br><a href=\"https://cizixs.com/2016/10/25/kubernetes-intro-kubelet/\" target=\"_blank\" rel=\"noopener\">kubernetes  kubelet  pod</a><br><a href=\"https://blog.csdn.net/jettery/article/details/78891733\" target=\"_blank\" rel=\"noopener\">Kubelet </a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>kubelet  kubelet Master  PodSpec Pod PodSpec  pod  YAML  JSON </p>\n<p>kubelet  apiserver  PodSpec  PodSpec </p>\n<h2 id=\"kubelet-\"><a href=\"#kubelet-\" class=\"headerlink\" title=\"kubelet \"></a>kubelet </h2><p>1kubelet   10250 10255102484194</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">LISTEN     0      128          *:10250                    *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=28))</span><br><span class=\"line\">LISTEN     0      128          *:10255                    *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=26))</span><br><span class=\"line\">LISTEN     0      128          *:4194                     *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=13))</span><br><span class=\"line\">LISTEN     0      128    127.0.0.1:10248                    *:*                   users:((&quot;kubelet&quot;,pid=48500,fd=23))</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>10250kubelet APIkubelet server  apiserver  apiserver  node </p>\n</li>\n<li><p>10248 kubelet ,  kubelet  <code>--healthz-port</code>  <code>--healthz-bind-address</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl http://127.0.0.1:10248/healthz</span><br><span class=\"line\">ok</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>4194cAdvisor kublet  node  <a href=\"http://localhost:4194\" target=\"_blank\" rel=\"noopener\">http://localhost:4194</a>  cAdvisor , kubelet  <code>--cadvisor-port</code> </p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ curl  http://127.0.0.1:4194/metrics</span><br></pre></td></tr></table></figure>\n<ul>\n<li>10255 readonly API pod  node <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">//   pod  apiserver  </span><br><span class=\"line\">// http://127.0.0.1:8080/api/v1/pods?fieldSelector=spec.nodeName=  </span><br><span class=\"line\">$ curl  http://127.0.0.1:10255/pods</span><br><span class=\"line\"></span><br><span class=\"line\">// ,CPU</span><br><span class=\"line\">$ curl http://127.0.0.1:10255/spec/</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>2kubelet </p>\n<ul>\n<li><p>pod kubelet  pod/container </p>\n</li>\n<li><p>kubelet  pod </p>\n</li>\n<li><p>kubelet  master  cAdvisor  pod </p>\n</li>\n</ul>\n<h2 id=\"kubelet-\"><a href=\"#kubelet-\" class=\"headerlink\" title=\"kubelet \"></a>kubelet </h2><p> <img src=\"https://upload-images.jianshu.io/upload_images/1262158-91b13623d3cf45ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet \"></p>\n<p> kubelet </p>\n<ul>\n<li><p>1PLEG(Pod Lifecycle Event Generator<br>PLEG  kubelet ,PLEG  container runtime  containers/sandboxes  pods cache  PodLifecycleEvent eventChannel  eventChannel  kubelet syncLoop  kubelet syncPod  pod </p>\n</li>\n<li><p>2cAdvisor<br>cAdvisor<a href=\"https://github.com/google/cadvisor\" target=\"_blank\" rel=\"noopener\">https://github.com/google/cadvisor</a> google  kubelet  cAdvisor  cAvisor  interface  imageManagerOOMWatchercontainerManager </p>\n</li>\n<li><p>3OOMWatcher<br> OOM  cadvisor  SystemOOM, Watch cadvisor  OOM </p>\n</li>\n<li><p>4probeManager<br>probeManager  statusManager,livenessManager,containerRefManager pod livenessProbe readinessProbe<br>livenessProbekubelet  kill <br>readinessProbe pod  service  endpoints readinessProbe  livenessProbe httptcp  cmd </p>\n</li>\n<li><p>5statusManager<br>statusManager  pod  apiserver pod  probeManager</p>\n</li>\n<li><p>6containerRefManager<br>Manager map  containerID  v1.ObjectReferece </p>\n</li>\n<li><p>7evictionManager<br> inode  evict  node  pressure  kubelet  qosClass  pod kubelet  <code>--eviction-hard=</code>  evict </p>\n</li>\n<li><p>8imageGC<br>imageGC  node  pod  kubelet  <code>--image-gc-high-threshold</code>  <code>--image-gc-low-threshold</code> </p>\n</li>\n<li><p>9containerGC<br>containerGC  node  container GC runtime </p>\n</li>\n<li><p>10imageManager<br> kubecontainer PullImage/GetImageRef/ListImages/RemoveImage/ImageStates pod </p>\n</li>\n<li><p>11volumeManager<br> node  pod  volume volume  pod  pod  volume  mount/umount/attach/detach kubernetes  volume Plugins </p>\n</li>\n<li><p>12containerManager<br> node  cgroup kubelet  <code>--cgroups-per-qos</code> kubelet  goroutine  pod  cgroup  <code>true</code> pod Guaranteed/BestEffort/Burstable  Qos</p>\n</li>\n<li><p>13runtimeManager<br>containerRuntime  kubelet  runtime  container  runtime  kubelet  <code>--container-runtime</code> docker  rkt <code>docker</code></p>\n</li>\n<li><p>14podManager<br>podManager  pod  static pod  mirror pods podManager statusManager/volumeManager/runtimeManager podManager  secretManager  configMapManager </p>\n</li>\n</ul>\n<p> v1.12 kubelet 18 manager</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">certificateManager</span><br><span class=\"line\">cgroupManager</span><br><span class=\"line\">containerManager</span><br><span class=\"line\">cpuManager</span><br><span class=\"line\">nodeContainerManager</span><br><span class=\"line\">configmapManager</span><br><span class=\"line\">containerReferenceManager</span><br><span class=\"line\">evictionManager</span><br><span class=\"line\">nvidiaGpuManager</span><br><span class=\"line\">imageGCManager</span><br><span class=\"line\">kuberuntimeManager</span><br><span class=\"line\">hostportManager</span><br><span class=\"line\">podManager</span><br><span class=\"line\">proberManager</span><br><span class=\"line\">secretManager</span><br><span class=\"line\">statusManager</span><br><span class=\"line\">volumeManager\t</span><br><span class=\"line\">tokenManager</span><br></pre></td></tr></table></figure>\n<p></p>\n<p><br><a href=\"https://juejin.im/entry/5bc71b3d6fb9a05cf23029b8\" target=\"_blank\" rel=\"noopener\"> K8S </a><br><a href=\"https://cizixs.com/2016/10/25/kubernetes-intro-kubelet/\" target=\"_blank\" rel=\"noopener\">kubernetes  kubelet  pod</a><br><a href=\"https://blog.csdn.net/jettery/article/details/78891733\" target=\"_blank\" rel=\"noopener\">Kubelet </a></p>\n"},{"title":"kubernets ","date":"2019-03-12T23:49:30.000Z","type":"component-HA","_content":"k8s  apiserver kube-controller-manager  kube-scheduler  leader  kube-scheduler  kube-manager-controller  leaderleader leader  leader leader \n\n> kubernetes  v1.12 \n\n#### \n\nk8s  kube-controller-managerkube-scheduler  `--leader-elect=true`  HA \n\n```\nI0306 19:17:14.109511  161798 flags.go:33] FLAG: --leader-elect=\"true\"\nI0306 19:17:14.109513  161798 flags.go:33] FLAG: --leader-elect-lease-duration=\"15s\"\nI0306 19:17:14.109516  161798 flags.go:33] FLAG: --leader-elect-renew-deadline=\"10s\"\nI0306 19:17:14.109518  161798 flags.go:33] FLAG: --leader-elect-resource-lock=\"endpoints\"\nI0306 19:17:14.109520  161798 flags.go:33] FLAG: --leader-elect-retry-period=\"2s\"\n```\n\nkubernetes  leader \n\n\n```\n$ kubectl get endpoints kube-controller-manager --namespace=kube-system -o yaml && \n  kubectl get endpoints kube-scheduler --namespace=kube-system -o yaml\n```\n\n leader  hostname  annotation  control-plane.alpha.kubernetes.io/leader \n\n\n#### Leader Election \n\nLeader Election  Kubernetes  Endpoint \n\n\n\n kube-controller-manager  leader cm  run  `k8s.io/kubernetes/cmd/kube-controller-manager/app/controllermanager.go` \n\n```\n// Run runs the KubeControllerManagerOptions.  This should never exit.\nfunc Run(c *config.CompletedConfig, stopCh <-chan struct{}) error {\n\t\t...\n\t\t// kube-controller-manager \n\t\trun := func(ctx context.Context) {\n\t\trootClientBuilder := controller.SimpleControllerClientBuilder{\n\t\t\tClientConfig: c.Kubeconfig,\n\t\t}\n\t\tvar clientBuilder controller.ControllerClientBuilder\n\t\tif c.ComponentConfig.KubeCloudShared.UseServiceAccountCredentials {\n\t\t\tif len(c.ComponentConfig.SAController.ServiceAccountKeyFile) == 0 {\n\t\t\t\t// It'c possible another controller process is creating the tokens for us.\n\t\t\t\t// If one isn't, we'll timeout and exit when our client builder is unable to create the tokens.\n\t\t\t\tglog.Warningf(\"--use-service-account-credentials was specified without providing a --service-account-private-key-file\")\n\t\t\t}\n\t\t\tclientBuilder = controller.SAControllerClientBuilder{\n\t\t\t\tClientConfig:         restclient.AnonymousClientConfig(c.Kubeconfig),\n\t\t\t\tCoreClient:           c.Client.CoreV1(),\n\t\t\t\tAuthenticationClient: c.Client.AuthenticationV1(),\n\t\t\t\tNamespace:            \"kube-system\",\n\t\t\t}\n\t\t} else {\n\t\t\tclientBuilder = rootClientBuilder\n\t\t}\n\t\tcontrollerContext, err := CreateControllerContext(c, rootClientBuilder, clientBuilder, ctx.Done())\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"error building controller context: %v\", err)\n\t\t}\n\t\tsaTokenControllerInitFunc := serviceAccountTokenControllerStarter{rootClientBuilder: rootClientBuilder}.startServiceAccountTokenController\n\t\t//  controller\n\t\tif err := StartControllers(controllerContext, saTokenControllerInitFunc, NewControllerInitializers(controllerContext.LoopMode), unsecuredMux); err != nil {\n\t\t\tglog.Fatalf(\"error starting controllers: %v\", err)\n\t\t}\n\n\t\tcontrollerContext.InformerFactory.Start(controllerContext.Stop)\n\t\tclose(controllerContext.InformersStarted)\n\n\t\tselect {}\n\t}\n\n    //  LeaderElect , controller-manager \n    //  run \n    if !c.ComponentConfig.Generic.LeaderElection.LeaderElect {\n        run(context.TODO())\n        panic(\"unreachable\")\n    }\n\n\t//  LeaderElect  true, controller-manager  HA \n\t//  leader  leader  run \n    id, err := os.Hostname()\n    if err != nil {\n        return err\n    }\n\n    // add a uniquifier so that two processes on the same host don't accidentally both become active\n    id = id + \"_\" + string(uuid.NewUUID())\n    \n    // \n    rl, err := resourcelock.New(c.ComponentConfig.Generic.LeaderElection.ResourceLock,\n        \"kube-system\",\n        \"kube-controller-manager\",\n        c.LeaderElectionClient.CoreV1(),\n        resourcelock.ResourceLockConfig{\n            Identity:      id,\n            EventRecorder: c.EventRecorder,\n        })\n    if err != nil {\n        glog.Fatalf(\"error creating lock: %v\", err)\n    }\n    // \n    leaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig{\n        Lock:          rl,\n        LeaseDuration: c.ComponentConfig.Generic.LeaderElection.LeaseDuration.Duration,\n        RenewDeadline: c.ComponentConfig.Generic.LeaderElection.RenewDeadline.Duration,\n        RetryPeriod:   c.ComponentConfig.Generic.LeaderElection.RetryPeriod.Duration,\n        Callbacks: leaderelection.LeaderCallbacks{\n            OnStartedLeading: run,\n            OnStoppedLeading: func() {\n                glog.Fatalf(\"leaderelection lost\")\n            },\n        },\n        WatchDog: electionChecker,\n        Name:     \"kube-controller-manager\",\n    })\n    panic(\"unreachable\")\n}\n```\n\n- 1kubernetes  `endpoints` c.ComponentConfig.Generic.LeaderElection.ResourceLock  \"endpoints\" ResourceLock \n\n![](https://upload-images.jianshu.io/upload_images/1262158-402b3215eb022307.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n EventRecorder leader  events  apiserver\n\n\n- 2rl  controller-manager  leader RunOrDie  leader \n\n- 3Callbacks  leader  OnStartedLeading  run run  controller-manager run  controller kube-controller-manager  controller\n\n```\nfunc NewControllerInitializers(loopMode ControllerLoopMode) map[string]InitFunc {\n\tcontrollers := map[string]InitFunc{}\n\tcontrollers[\"endpoint\"] = startEndpointController\n\tcontrollers[\"replicationcontroller\"] = startReplicationController\n\tcontrollers[\"podgc\"] = startPodGCController\n\tcontrollers[\"resourcequota\"] = startResourceQuotaController\n\tcontrollers[\"namespace\"] = startNamespaceController\n\tcontrollers[\"serviceaccount\"] = startServiceAccountController\n\tcontrollers[\"garbagecollector\"] = startGarbageCollectorController\n\tcontrollers[\"daemonset\"] = startDaemonSetController\n\tcontrollers[\"job\"] = startJobController\n\tcontrollers[\"deployment\"] = startDeploymentController\n\tcontrollers[\"replicaset\"] = startReplicaSetController\n\tcontrollers[\"horizontalpodautoscaling\"] = startHPAController\n\tcontrollers[\"disruption\"] = startDisruptionController\n\tcontrollers[\"statefulset\"] = startStatefulSetController\n\tcontrollers[\"cronjob\"] = startCronJobController\n\tcontrollers[\"csrsigning\"] = startCSRSigningController\n\tcontrollers[\"csrapproving\"] = startCSRApprovingController\n\tcontrollers[\"csrcleaner\"] = startCSRCleanerController\n\tcontrollers[\"ttl\"] = startTTLController\n\tcontrollers[\"bootstrapsigner\"] = startBootstrapSignerController\n\tcontrollers[\"tokencleaner\"] = startTokenCleanerController\n\tcontrollers[\"nodeipam\"] = startNodeIpamController\n\tif loopMode == IncludeCloudLoops {\n\t\tcontrollers[\"service\"] = startServiceController\n\t\tcontrollers[\"route\"] = startRouteController\n\t}\n\tcontrollers[\"nodelifecycle\"] = startNodeLifecycleController\n\tcontrollers[\"persistentvolume-binder\"] = startPersistentVolumeBinderController\n\tcontrollers[\"attachdetach\"] = startAttachDetachController\n\tcontrollers[\"persistentvolume-expander\"] = startVolumeExpandController\n\tcontrollers[\"clusterrole-aggregation\"] = startClusterRoleAggregrationController\n\tcontrollers[\"pvc-protection\"] = startPVCProtectionController\n\tcontrollers[\"pv-protection\"] = startPVProtectionController\n\tcontrollers[\"ttl-after-finished\"] = startTTLAfterFinishedController\n\n\treturn controllers\n}\n```\n\nOnStoppedLeading  leader  slave \n\n\n\n```\nfunc RunOrDie(ctx context.Context, lec LeaderElectionConfig) {\n    le, err := NewLeaderElector(lec)\n    if err != nil {\n        panic(err)\n    }\n    if lec.WatchDog != nil {\n        lec.WatchDog.SetLeaderElection(le)\n    }\n    le.Run(ctx)\n}\n```\n\n RunOrDie  NewLeaderElector  LeaderElector  LeaderElector  run \n\n\n```\nfunc (le *LeaderElector) Run(ctx context.Context) {\n\tdefer func() {\n\t\truntime.HandleCrash()\n\t\tle.config.Callbacks.OnStoppedLeading()\n\t}()\n\tif !le.acquire(ctx) {\n\t\treturn // ctx signalled done\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tgo le.config.Callbacks.OnStartedLeading(ctx)\n\tle.renew(ctx)\n}\n```\n\nRun  acquire  OnStartedLeading  controller renew  leader \n\n\n```\nfunc (le *LeaderElector) acquire(ctx context.Context) bool {\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tsucceeded := false\n\tdesc := le.config.Lock.Describe()\n\tglog.Infof(\"attempting to acquire leader lease  %v...\", desc)\n\twait.JitterUntil(func() {\n\t\t// \n\t\tsucceeded = le.tryAcquireOrRenew()\n\t\t// leader  maybeReportTransition \n\t\t//  OnNewLeader() , OnNewLeader() \n\t\tle.maybeReportTransition()\n\t\tif !succeeded {\n\t\t\tglog.V(4).Infof(\"failed to acquire lease %v\", desc)\n\t\t\treturn\n\t\t}\n\t\tle.config.Lock.RecordEvent(\"became leader\")\n\t\tglog.Infof(\"successfully acquired lease %v\", desc)\n\t\tcancel()\n\t}, le.config.RetryPeriod, JitterFactor, true, ctx.Done())\n\treturn succeeded\n}\n```\n acquire  ctx wait.JitterUntil  le.tryAcquireOrRenew  RetryPeriod  ctx  wait.JitterUntil tryAcquireOrRenew \n\n\n\n```\nfunc (le *LeaderElector) tryAcquireOrRenew() bool {\n\tnow := metav1.Now()\n\tleaderElectionRecord := rl.LeaderElectionRecord{\n\t\tHolderIdentity:       le.config.Lock.Identity(),\n\t\tLeaseDurationSeconds: int(le.config.LeaseDuration / time.Second),\n\t\tRenewTime:            now,\n\t\tAcquireTime:          now,\n\t}\n\n\t// 1\n\toldLeaderElectionRecord, err := le.config.Lock.Get()\n\tif err != nil {\n\t\tif !errors.IsNotFound(err) {\n\t\t\tglog.Errorf(\"error retrieving resource lock %v: %v\", le.config.Lock.Describe(), err)\n\t\t\treturn false\n\t\t}\n\t\t//  leader \n\t\tif err = le.config.Lock.Create(leaderElectionRecord); err != nil {\n\t\t\tglog.Errorf(\"error initially creating leader election record: %v\", err)\n\t\t\treturn false\n\t\t}\n\t\tle.observedRecord = leaderElectionRecord\n\t\tle.observedTime = le.clock.Now()\n\t\treturn true\n\t}\n\n\t// 2 id  leader\n\tif !reflect.DeepEqual(le.observedRecord, *oldLeaderElectionRecord) {\n\t\tle.observedRecord = *oldLeaderElectionRecord\n\t\tle.observedTime = le.clock.Now()\n\t}\n\t//  id  Leader\n\tif le.observedTime.Add(le.config.LeaseDuration).After(now.Time) &&\n\t\t!le.IsLeader() {\n\t\tglog.V(4).Infof(\"lock is held by %v and has not yet expired\", oldLeaderElectionRecord.HolderIdentity)\n\t\treturn false\n\t}\n\n\t// 3 id  Leader\n\t//  Leader \n\tif le.IsLeader() {\n\t\tleaderElectionRecord.AcquireTime = oldLeaderElectionRecord.AcquireTime\n\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions\n\t} else {\n\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions + 1\n\t}\n\n\t// \n    //  Leader \n    //  Leader \n\tif err = le.config.Lock.Update(leaderElectionRecord); err != nil {\n\t\tglog.Errorf(\"Failed to update lock: %v\", err)\n\t\treturn false\n\t}\n\tle.observedRecord = leaderElectionRecord\n\tle.observedTime = le.clock.Now()\n\treturn true\n}\n```\n\n\n- 1 ElectionRecord  ElectionRecord  leader \n- 2 id  leader  id  Leader\n- 3 id  Leader\n- 4 id  Leader  leader \n\n\n renew \n\n```\nfunc (le *LeaderElector) renew(ctx context.Context) {\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\twait.Until(func() {\n\t\ttimeoutCtx, timeoutCancel := context.WithTimeout(ctx, le.config.RenewDeadline)\n\t\tdefer timeoutCancel()\n\t\t//  RetryPeriod  tryAcquireOrRenew()\n        //  tryAcquireOrRenew()  false \n\t\terr := wait.PollImmediateUntil(le.config.RetryPeriod, func() (bool, error) {\n\t\t\tdone := make(chan bool, 1)\n\t\t\tgo func() {\n\t\t\t\tdefer close(done)\n\t\t\t\tdone <- le.tryAcquireOrRenew()\n\t\t\t}()\n\n\t\t\tselect {\n\t\t\tcase <-timeoutCtx.Done():\n\t\t\t\treturn false, fmt.Errorf(\"failed to tryAcquireOrRenew %s\", timeoutCtx.Err())\n\t\t\tcase result := <-done:\n\t\t\t\treturn result, nil\n\t\t\t}\n\t\t}, timeoutCtx.Done())\n\n\t\tle.maybeReportTransition()\n\t\tdesc := le.config.Lock.Describe()\n\t\tif err == nil {\n\t\t\tglog.V(4).Infof(\"successfully renewed lease %v\", desc)\n\t\t\treturn\n\t\t}\n\t\t//  Leader panic\n\t\tle.config.Lock.RecordEvent(\"stopped leading\")\n\t\tglog.Infof(\"failed to renew lease %v: %v\", desc, err)\n\t\tcancel()\n\t}, le.config.RetryPeriod, ctx.Done())\n}\n```\nrenew  leader \n\n\n\n#### Leader Election \n\n demo k8s  `k8s.io/client-go/tools/leaderelection` \n\n\n```\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/golang/glog\"\n\t\"k8s.io/api/core/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/kubernetes/scheme\"\n\tv1core \"k8s.io/client-go/kubernetes/typed/core/v1\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\t\"k8s.io/client-go/tools/leaderelection\"\n\t\"k8s.io/client-go/tools/leaderelection/resourcelock\"\n\t\"k8s.io/client-go/tools/record\"\n)\n\nvar (\n\tmasterURL  string\n\tkubeconfig string\n)\n\nfunc init() {\n\tflag.StringVar(&kubeconfig, \"kubeconfig\", \"\", \"Path to a kubeconfig. Only required if out-of-cluster.\")\n\tflag.StringVar(&masterURL, \"master\", \"\", \"The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\")\n\n\tflag.Set(\"logtostderr\", \"true\")\n}\n\nfunc main() {\n\tflag.Parse()\n\tdefer glog.Flush()\n\n\tid, err := os.Hostname()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t\n\t//  kubeconfig \n\tcfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig)\n\tif err != nil {\n\t\tglog.Fatalf(\"Error building kubeconfig: %s\", err.Error())\n\t}\n\n\t//  kubeclient\n\tkubeClient, err := kubernetes.NewForConfig(cfg)\n\tif err != nil {\n\t\tglog.Fatalf(\"Error building kubernetes clientset: %s\", err.Error())\n\t}\n\n\t//  eventRecorder\n\teventBroadcaster := record.NewBroadcaster()\n\teventRecorder := eventBroadcaster.NewRecorder(scheme.Scheme, v1.EventSource{Component: \"test-1\"})\n\teventBroadcaster.StartLogging(glog.Infof)\n\teventBroadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: kubeClient.CoreV1().Events(\"\")})\n\n\trun := func(ctx context.Context) {\n\t\tfmt.Println(\"run.........\")\n\t\tselect {}\n\t}\n\n\tid = id + \"_\" + \"1\"\n\trl, err := resourcelock.New(\"endpoints\",\n\t\t\"kube-system\",\n\t\t\"test\",\n\t\tkubeClient.CoreV1(),\n\t\tresourcelock.ResourceLockConfig{\n\t\t\tIdentity:      id,\n\t\t\tEventRecorder: eventRecorder,\n\t\t})\n\tif err != nil {\n\t\tglog.Fatalf(\"error creating lock: %v\", err)\n\t}\n\n\tleaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig{\n\t\tLock:          rl,\n\t\tLeaseDuration: 15 * time.Second,\n\t\tRenewDeadline: 10 * time.Second,\n\t\tRetryPeriod:   2 * time.Second,\n\t\tCallbacks: leaderelection.LeaderCallbacks{\n\t\t\tOnStartedLeading: run,\n\t\t\tOnStoppedLeading: func() {\n\t\t\t\tglog.Info(\"leaderelection lost\")\n\t\t\t},\n\t\t},\n\t\tName: \"test-1\",\n\t})\n}\n```\n\n hostname  leader  events  leader \n\n\n```\n# kubectl describe endpoints test  -n kube-system\nName:         test\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  control-plane.alpha.kubernetes.io/leader={\"holderIdentity\":\"localhost_2\",\"leaseDurationSeconds\":15,\"acquireTime\":\"2019-03-10T08:47:42Z\",\"renewTime\":\"2019-03-10T08:47:44Z\",\"leaderTransitions\":2}\nSubsets:\nEvents:\n  Type    Reason          Age   From    Message\n  ----    ------          ----  ----    -------\n  Normal  LeaderElection  50s   test-1  localhost_1 became leader\n  Normal  LeaderElection  5s    test-2  localhost_2 became leader\n```\n\n\n#### \n\n kube-controller-manager  HA  leader k8s  endpoints  rediszookeeperetcd  k8s k8s  etcd  update  resourceVersion \n\n![api resource](https://upload-images.jianshu.io/upload_images/1262158-7ec427b37b6b6a10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n\n\n[API OVERVIEW](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/)\n[Simple leader election with Kubernetes and Docker](https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/)\n\n\n","source":"_posts/k8s_leader_election.md","raw":"---\ntitle: kubernets \ndate: 2019-03-13 07:49:30\ntags: [\"leader-election\",\"component\"]\ntype: \"component-HA\"\n\n---\nk8s  apiserver kube-controller-manager  kube-scheduler  leader  kube-scheduler  kube-manager-controller  leaderleader leader  leader leader \n\n> kubernetes  v1.12 \n\n#### \n\nk8s  kube-controller-managerkube-scheduler  `--leader-elect=true`  HA \n\n```\nI0306 19:17:14.109511  161798 flags.go:33] FLAG: --leader-elect=\"true\"\nI0306 19:17:14.109513  161798 flags.go:33] FLAG: --leader-elect-lease-duration=\"15s\"\nI0306 19:17:14.109516  161798 flags.go:33] FLAG: --leader-elect-renew-deadline=\"10s\"\nI0306 19:17:14.109518  161798 flags.go:33] FLAG: --leader-elect-resource-lock=\"endpoints\"\nI0306 19:17:14.109520  161798 flags.go:33] FLAG: --leader-elect-retry-period=\"2s\"\n```\n\nkubernetes  leader \n\n\n```\n$ kubectl get endpoints kube-controller-manager --namespace=kube-system -o yaml && \n  kubectl get endpoints kube-scheduler --namespace=kube-system -o yaml\n```\n\n leader  hostname  annotation  control-plane.alpha.kubernetes.io/leader \n\n\n#### Leader Election \n\nLeader Election  Kubernetes  Endpoint \n\n\n\n kube-controller-manager  leader cm  run  `k8s.io/kubernetes/cmd/kube-controller-manager/app/controllermanager.go` \n\n```\n// Run runs the KubeControllerManagerOptions.  This should never exit.\nfunc Run(c *config.CompletedConfig, stopCh <-chan struct{}) error {\n\t\t...\n\t\t// kube-controller-manager \n\t\trun := func(ctx context.Context) {\n\t\trootClientBuilder := controller.SimpleControllerClientBuilder{\n\t\t\tClientConfig: c.Kubeconfig,\n\t\t}\n\t\tvar clientBuilder controller.ControllerClientBuilder\n\t\tif c.ComponentConfig.KubeCloudShared.UseServiceAccountCredentials {\n\t\t\tif len(c.ComponentConfig.SAController.ServiceAccountKeyFile) == 0 {\n\t\t\t\t// It'c possible another controller process is creating the tokens for us.\n\t\t\t\t// If one isn't, we'll timeout and exit when our client builder is unable to create the tokens.\n\t\t\t\tglog.Warningf(\"--use-service-account-credentials was specified without providing a --service-account-private-key-file\")\n\t\t\t}\n\t\t\tclientBuilder = controller.SAControllerClientBuilder{\n\t\t\t\tClientConfig:         restclient.AnonymousClientConfig(c.Kubeconfig),\n\t\t\t\tCoreClient:           c.Client.CoreV1(),\n\t\t\t\tAuthenticationClient: c.Client.AuthenticationV1(),\n\t\t\t\tNamespace:            \"kube-system\",\n\t\t\t}\n\t\t} else {\n\t\t\tclientBuilder = rootClientBuilder\n\t\t}\n\t\tcontrollerContext, err := CreateControllerContext(c, rootClientBuilder, clientBuilder, ctx.Done())\n\t\tif err != nil {\n\t\t\tglog.Fatalf(\"error building controller context: %v\", err)\n\t\t}\n\t\tsaTokenControllerInitFunc := serviceAccountTokenControllerStarter{rootClientBuilder: rootClientBuilder}.startServiceAccountTokenController\n\t\t//  controller\n\t\tif err := StartControllers(controllerContext, saTokenControllerInitFunc, NewControllerInitializers(controllerContext.LoopMode), unsecuredMux); err != nil {\n\t\t\tglog.Fatalf(\"error starting controllers: %v\", err)\n\t\t}\n\n\t\tcontrollerContext.InformerFactory.Start(controllerContext.Stop)\n\t\tclose(controllerContext.InformersStarted)\n\n\t\tselect {}\n\t}\n\n    //  LeaderElect , controller-manager \n    //  run \n    if !c.ComponentConfig.Generic.LeaderElection.LeaderElect {\n        run(context.TODO())\n        panic(\"unreachable\")\n    }\n\n\t//  LeaderElect  true, controller-manager  HA \n\t//  leader  leader  run \n    id, err := os.Hostname()\n    if err != nil {\n        return err\n    }\n\n    // add a uniquifier so that two processes on the same host don't accidentally both become active\n    id = id + \"_\" + string(uuid.NewUUID())\n    \n    // \n    rl, err := resourcelock.New(c.ComponentConfig.Generic.LeaderElection.ResourceLock,\n        \"kube-system\",\n        \"kube-controller-manager\",\n        c.LeaderElectionClient.CoreV1(),\n        resourcelock.ResourceLockConfig{\n            Identity:      id,\n            EventRecorder: c.EventRecorder,\n        })\n    if err != nil {\n        glog.Fatalf(\"error creating lock: %v\", err)\n    }\n    // \n    leaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig{\n        Lock:          rl,\n        LeaseDuration: c.ComponentConfig.Generic.LeaderElection.LeaseDuration.Duration,\n        RenewDeadline: c.ComponentConfig.Generic.LeaderElection.RenewDeadline.Duration,\n        RetryPeriod:   c.ComponentConfig.Generic.LeaderElection.RetryPeriod.Duration,\n        Callbacks: leaderelection.LeaderCallbacks{\n            OnStartedLeading: run,\n            OnStoppedLeading: func() {\n                glog.Fatalf(\"leaderelection lost\")\n            },\n        },\n        WatchDog: electionChecker,\n        Name:     \"kube-controller-manager\",\n    })\n    panic(\"unreachable\")\n}\n```\n\n- 1kubernetes  `endpoints` c.ComponentConfig.Generic.LeaderElection.ResourceLock  \"endpoints\" ResourceLock \n\n![](https://upload-images.jianshu.io/upload_images/1262158-402b3215eb022307.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n EventRecorder leader  events  apiserver\n\n\n- 2rl  controller-manager  leader RunOrDie  leader \n\n- 3Callbacks  leader  OnStartedLeading  run run  controller-manager run  controller kube-controller-manager  controller\n\n```\nfunc NewControllerInitializers(loopMode ControllerLoopMode) map[string]InitFunc {\n\tcontrollers := map[string]InitFunc{}\n\tcontrollers[\"endpoint\"] = startEndpointController\n\tcontrollers[\"replicationcontroller\"] = startReplicationController\n\tcontrollers[\"podgc\"] = startPodGCController\n\tcontrollers[\"resourcequota\"] = startResourceQuotaController\n\tcontrollers[\"namespace\"] = startNamespaceController\n\tcontrollers[\"serviceaccount\"] = startServiceAccountController\n\tcontrollers[\"garbagecollector\"] = startGarbageCollectorController\n\tcontrollers[\"daemonset\"] = startDaemonSetController\n\tcontrollers[\"job\"] = startJobController\n\tcontrollers[\"deployment\"] = startDeploymentController\n\tcontrollers[\"replicaset\"] = startReplicaSetController\n\tcontrollers[\"horizontalpodautoscaling\"] = startHPAController\n\tcontrollers[\"disruption\"] = startDisruptionController\n\tcontrollers[\"statefulset\"] = startStatefulSetController\n\tcontrollers[\"cronjob\"] = startCronJobController\n\tcontrollers[\"csrsigning\"] = startCSRSigningController\n\tcontrollers[\"csrapproving\"] = startCSRApprovingController\n\tcontrollers[\"csrcleaner\"] = startCSRCleanerController\n\tcontrollers[\"ttl\"] = startTTLController\n\tcontrollers[\"bootstrapsigner\"] = startBootstrapSignerController\n\tcontrollers[\"tokencleaner\"] = startTokenCleanerController\n\tcontrollers[\"nodeipam\"] = startNodeIpamController\n\tif loopMode == IncludeCloudLoops {\n\t\tcontrollers[\"service\"] = startServiceController\n\t\tcontrollers[\"route\"] = startRouteController\n\t}\n\tcontrollers[\"nodelifecycle\"] = startNodeLifecycleController\n\tcontrollers[\"persistentvolume-binder\"] = startPersistentVolumeBinderController\n\tcontrollers[\"attachdetach\"] = startAttachDetachController\n\tcontrollers[\"persistentvolume-expander\"] = startVolumeExpandController\n\tcontrollers[\"clusterrole-aggregation\"] = startClusterRoleAggregrationController\n\tcontrollers[\"pvc-protection\"] = startPVCProtectionController\n\tcontrollers[\"pv-protection\"] = startPVProtectionController\n\tcontrollers[\"ttl-after-finished\"] = startTTLAfterFinishedController\n\n\treturn controllers\n}\n```\n\nOnStoppedLeading  leader  slave \n\n\n\n```\nfunc RunOrDie(ctx context.Context, lec LeaderElectionConfig) {\n    le, err := NewLeaderElector(lec)\n    if err != nil {\n        panic(err)\n    }\n    if lec.WatchDog != nil {\n        lec.WatchDog.SetLeaderElection(le)\n    }\n    le.Run(ctx)\n}\n```\n\n RunOrDie  NewLeaderElector  LeaderElector  LeaderElector  run \n\n\n```\nfunc (le *LeaderElector) Run(ctx context.Context) {\n\tdefer func() {\n\t\truntime.HandleCrash()\n\t\tle.config.Callbacks.OnStoppedLeading()\n\t}()\n\tif !le.acquire(ctx) {\n\t\treturn // ctx signalled done\n\t}\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tgo le.config.Callbacks.OnStartedLeading(ctx)\n\tle.renew(ctx)\n}\n```\n\nRun  acquire  OnStartedLeading  controller renew  leader \n\n\n```\nfunc (le *LeaderElector) acquire(ctx context.Context) bool {\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tsucceeded := false\n\tdesc := le.config.Lock.Describe()\n\tglog.Infof(\"attempting to acquire leader lease  %v...\", desc)\n\twait.JitterUntil(func() {\n\t\t// \n\t\tsucceeded = le.tryAcquireOrRenew()\n\t\t// leader  maybeReportTransition \n\t\t//  OnNewLeader() , OnNewLeader() \n\t\tle.maybeReportTransition()\n\t\tif !succeeded {\n\t\t\tglog.V(4).Infof(\"failed to acquire lease %v\", desc)\n\t\t\treturn\n\t\t}\n\t\tle.config.Lock.RecordEvent(\"became leader\")\n\t\tglog.Infof(\"successfully acquired lease %v\", desc)\n\t\tcancel()\n\t}, le.config.RetryPeriod, JitterFactor, true, ctx.Done())\n\treturn succeeded\n}\n```\n acquire  ctx wait.JitterUntil  le.tryAcquireOrRenew  RetryPeriod  ctx  wait.JitterUntil tryAcquireOrRenew \n\n\n\n```\nfunc (le *LeaderElector) tryAcquireOrRenew() bool {\n\tnow := metav1.Now()\n\tleaderElectionRecord := rl.LeaderElectionRecord{\n\t\tHolderIdentity:       le.config.Lock.Identity(),\n\t\tLeaseDurationSeconds: int(le.config.LeaseDuration / time.Second),\n\t\tRenewTime:            now,\n\t\tAcquireTime:          now,\n\t}\n\n\t// 1\n\toldLeaderElectionRecord, err := le.config.Lock.Get()\n\tif err != nil {\n\t\tif !errors.IsNotFound(err) {\n\t\t\tglog.Errorf(\"error retrieving resource lock %v: %v\", le.config.Lock.Describe(), err)\n\t\t\treturn false\n\t\t}\n\t\t//  leader \n\t\tif err = le.config.Lock.Create(leaderElectionRecord); err != nil {\n\t\t\tglog.Errorf(\"error initially creating leader election record: %v\", err)\n\t\t\treturn false\n\t\t}\n\t\tle.observedRecord = leaderElectionRecord\n\t\tle.observedTime = le.clock.Now()\n\t\treturn true\n\t}\n\n\t// 2 id  leader\n\tif !reflect.DeepEqual(le.observedRecord, *oldLeaderElectionRecord) {\n\t\tle.observedRecord = *oldLeaderElectionRecord\n\t\tle.observedTime = le.clock.Now()\n\t}\n\t//  id  Leader\n\tif le.observedTime.Add(le.config.LeaseDuration).After(now.Time) &&\n\t\t!le.IsLeader() {\n\t\tglog.V(4).Infof(\"lock is held by %v and has not yet expired\", oldLeaderElectionRecord.HolderIdentity)\n\t\treturn false\n\t}\n\n\t// 3 id  Leader\n\t//  Leader \n\tif le.IsLeader() {\n\t\tleaderElectionRecord.AcquireTime = oldLeaderElectionRecord.AcquireTime\n\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions\n\t} else {\n\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions + 1\n\t}\n\n\t// \n    //  Leader \n    //  Leader \n\tif err = le.config.Lock.Update(leaderElectionRecord); err != nil {\n\t\tglog.Errorf(\"Failed to update lock: %v\", err)\n\t\treturn false\n\t}\n\tle.observedRecord = leaderElectionRecord\n\tle.observedTime = le.clock.Now()\n\treturn true\n}\n```\n\n\n- 1 ElectionRecord  ElectionRecord  leader \n- 2 id  leader  id  Leader\n- 3 id  Leader\n- 4 id  Leader  leader \n\n\n renew \n\n```\nfunc (le *LeaderElector) renew(ctx context.Context) {\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\twait.Until(func() {\n\t\ttimeoutCtx, timeoutCancel := context.WithTimeout(ctx, le.config.RenewDeadline)\n\t\tdefer timeoutCancel()\n\t\t//  RetryPeriod  tryAcquireOrRenew()\n        //  tryAcquireOrRenew()  false \n\t\terr := wait.PollImmediateUntil(le.config.RetryPeriod, func() (bool, error) {\n\t\t\tdone := make(chan bool, 1)\n\t\t\tgo func() {\n\t\t\t\tdefer close(done)\n\t\t\t\tdone <- le.tryAcquireOrRenew()\n\t\t\t}()\n\n\t\t\tselect {\n\t\t\tcase <-timeoutCtx.Done():\n\t\t\t\treturn false, fmt.Errorf(\"failed to tryAcquireOrRenew %s\", timeoutCtx.Err())\n\t\t\tcase result := <-done:\n\t\t\t\treturn result, nil\n\t\t\t}\n\t\t}, timeoutCtx.Done())\n\n\t\tle.maybeReportTransition()\n\t\tdesc := le.config.Lock.Describe()\n\t\tif err == nil {\n\t\t\tglog.V(4).Infof(\"successfully renewed lease %v\", desc)\n\t\t\treturn\n\t\t}\n\t\t//  Leader panic\n\t\tle.config.Lock.RecordEvent(\"stopped leading\")\n\t\tglog.Infof(\"failed to renew lease %v: %v\", desc, err)\n\t\tcancel()\n\t}, le.config.RetryPeriod, ctx.Done())\n}\n```\nrenew  leader \n\n\n\n#### Leader Election \n\n demo k8s  `k8s.io/client-go/tools/leaderelection` \n\n\n```\npackage main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/golang/glog\"\n\t\"k8s.io/api/core/v1\"\n\t\"k8s.io/client-go/kubernetes\"\n\t\"k8s.io/client-go/kubernetes/scheme\"\n\tv1core \"k8s.io/client-go/kubernetes/typed/core/v1\"\n\t\"k8s.io/client-go/tools/clientcmd\"\n\t\"k8s.io/client-go/tools/leaderelection\"\n\t\"k8s.io/client-go/tools/leaderelection/resourcelock\"\n\t\"k8s.io/client-go/tools/record\"\n)\n\nvar (\n\tmasterURL  string\n\tkubeconfig string\n)\n\nfunc init() {\n\tflag.StringVar(&kubeconfig, \"kubeconfig\", \"\", \"Path to a kubeconfig. Only required if out-of-cluster.\")\n\tflag.StringVar(&masterURL, \"master\", \"\", \"The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.\")\n\n\tflag.Set(\"logtostderr\", \"true\")\n}\n\nfunc main() {\n\tflag.Parse()\n\tdefer glog.Flush()\n\n\tid, err := os.Hostname()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\t\n\t//  kubeconfig \n\tcfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig)\n\tif err != nil {\n\t\tglog.Fatalf(\"Error building kubeconfig: %s\", err.Error())\n\t}\n\n\t//  kubeclient\n\tkubeClient, err := kubernetes.NewForConfig(cfg)\n\tif err != nil {\n\t\tglog.Fatalf(\"Error building kubernetes clientset: %s\", err.Error())\n\t}\n\n\t//  eventRecorder\n\teventBroadcaster := record.NewBroadcaster()\n\teventRecorder := eventBroadcaster.NewRecorder(scheme.Scheme, v1.EventSource{Component: \"test-1\"})\n\teventBroadcaster.StartLogging(glog.Infof)\n\teventBroadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: kubeClient.CoreV1().Events(\"\")})\n\n\trun := func(ctx context.Context) {\n\t\tfmt.Println(\"run.........\")\n\t\tselect {}\n\t}\n\n\tid = id + \"_\" + \"1\"\n\trl, err := resourcelock.New(\"endpoints\",\n\t\t\"kube-system\",\n\t\t\"test\",\n\t\tkubeClient.CoreV1(),\n\t\tresourcelock.ResourceLockConfig{\n\t\t\tIdentity:      id,\n\t\t\tEventRecorder: eventRecorder,\n\t\t})\n\tif err != nil {\n\t\tglog.Fatalf(\"error creating lock: %v\", err)\n\t}\n\n\tleaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig{\n\t\tLock:          rl,\n\t\tLeaseDuration: 15 * time.Second,\n\t\tRenewDeadline: 10 * time.Second,\n\t\tRetryPeriod:   2 * time.Second,\n\t\tCallbacks: leaderelection.LeaderCallbacks{\n\t\t\tOnStartedLeading: run,\n\t\t\tOnStoppedLeading: func() {\n\t\t\t\tglog.Info(\"leaderelection lost\")\n\t\t\t},\n\t\t},\n\t\tName: \"test-1\",\n\t})\n}\n```\n\n hostname  leader  events  leader \n\n\n```\n# kubectl describe endpoints test  -n kube-system\nName:         test\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  control-plane.alpha.kubernetes.io/leader={\"holderIdentity\":\"localhost_2\",\"leaseDurationSeconds\":15,\"acquireTime\":\"2019-03-10T08:47:42Z\",\"renewTime\":\"2019-03-10T08:47:44Z\",\"leaderTransitions\":2}\nSubsets:\nEvents:\n  Type    Reason          Age   From    Message\n  ----    ------          ----  ----    -------\n  Normal  LeaderElection  50s   test-1  localhost_1 became leader\n  Normal  LeaderElection  5s    test-2  localhost_2 became leader\n```\n\n\n#### \n\n kube-controller-manager  HA  leader k8s  endpoints  rediszookeeperetcd  k8s k8s  etcd  update  resourceVersion \n\n![api resource](https://upload-images.jianshu.io/upload_images/1262158-7ec427b37b6b6a10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n\n\n[API OVERVIEW](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/)\n[Simple leader election with Kubernetes and Docker](https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/)\n\n\n","slug":"k8s_leader_election","published":1,"updated":"2019-03-12T23:54:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyt02000ytadvh7hc5sqh","content":"<p>k8s  apiserver kube-controller-manager  kube-scheduler  leader  kube-scheduler  kube-manager-controller  leaderleader leader  leader leader </p>\n<blockquote>\n<p>kubernetes  v1.12 </p>\n</blockquote>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>k8s  kube-controller-managerkube-scheduler  <code>--leader-elect=true</code>  HA </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">I0306 19:17:14.109511  161798 flags.go:33] FLAG: --leader-elect=&quot;true&quot;</span><br><span class=\"line\">I0306 19:17:14.109513  161798 flags.go:33] FLAG: --leader-elect-lease-duration=&quot;15s&quot;</span><br><span class=\"line\">I0306 19:17:14.109516  161798 flags.go:33] FLAG: --leader-elect-renew-deadline=&quot;10s&quot;</span><br><span class=\"line\">I0306 19:17:14.109518  161798 flags.go:33] FLAG: --leader-elect-resource-lock=&quot;endpoints&quot;</span><br><span class=\"line\">I0306 19:17:14.109520  161798 flags.go:33] FLAG: --leader-elect-retry-period=&quot;2s&quot;</span><br></pre></td></tr></table></figure>\n<p>kubernetes  leader </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get endpoints kube-controller-manager --namespace=kube-system -o yaml &amp;&amp; </span><br><span class=\"line\">  kubectl get endpoints kube-scheduler --namespace=kube-system -o yaml</span><br></pre></td></tr></table></figure>\n<p> leader  hostname  annotation  control-plane.alpha.kubernetes.io/leader </p>\n<h4 id=\"Leader-Election-\"><a href=\"#Leader-Election-\" class=\"headerlink\" title=\"Leader Election \"></a>Leader Election </h4><p>Leader Election  Kubernetes  Endpoint </p>\n<p> kube-controller-manager  leader cm  run  <code>k8s.io/kubernetes/cmd/kube-controller-manager/app/controllermanager.go</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Run runs the KubeControllerManagerOptions.  This should never exit.</span><br><span class=\"line\">func Run(c *config.CompletedConfig, stopCh &lt;-chan struct&#123;&#125;) error &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t// kube-controller-manager </span><br><span class=\"line\">\t\trun := func(ctx context.Context) &#123;</span><br><span class=\"line\">\t\trootClientBuilder := controller.SimpleControllerClientBuilder&#123;</span><br><span class=\"line\">\t\t\tClientConfig: c.Kubeconfig,</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tvar clientBuilder controller.ControllerClientBuilder</span><br><span class=\"line\">\t\tif c.ComponentConfig.KubeCloudShared.UseServiceAccountCredentials &#123;</span><br><span class=\"line\">\t\t\tif len(c.ComponentConfig.SAController.ServiceAccountKeyFile) == 0 &#123;</span><br><span class=\"line\">\t\t\t\t// It&apos;c possible another controller process is creating the tokens for us.</span><br><span class=\"line\">\t\t\t\t// If one isn&apos;t, we&apos;ll timeout and exit when our client builder is unable to create the tokens.</span><br><span class=\"line\">\t\t\t\tglog.Warningf(&quot;--use-service-account-credentials was specified without providing a --service-account-private-key-file&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tclientBuilder = controller.SAControllerClientBuilder&#123;</span><br><span class=\"line\">\t\t\t\tClientConfig:         restclient.AnonymousClientConfig(c.Kubeconfig),</span><br><span class=\"line\">\t\t\t\tCoreClient:           c.Client.CoreV1(),</span><br><span class=\"line\">\t\t\t\tAuthenticationClient: c.Client.AuthenticationV1(),</span><br><span class=\"line\">\t\t\t\tNamespace:            &quot;kube-system&quot;,</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\tclientBuilder = rootClientBuilder</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcontrollerContext, err := CreateControllerContext(c, rootClientBuilder, clientBuilder, ctx.Done())</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Fatalf(&quot;error building controller context: %v&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tsaTokenControllerInitFunc := serviceAccountTokenControllerStarter&#123;rootClientBuilder: rootClientBuilder&#125;.startServiceAccountTokenController</span><br><span class=\"line\">\t\t//  controller</span><br><span class=\"line\">\t\tif err := StartControllers(controllerContext, saTokenControllerInitFunc, NewControllerInitializers(controllerContext.LoopMode), unsecuredMux); err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Fatalf(&quot;error starting controllers: %v&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tcontrollerContext.InformerFactory.Start(controllerContext.Stop)</span><br><span class=\"line\">\t\tclose(controllerContext.InformersStarted)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tselect &#123;&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    //  LeaderElect , controller-manager </span><br><span class=\"line\">    //  run </span><br><span class=\"line\">    if !c.ComponentConfig.Generic.LeaderElection.LeaderElect &#123;</span><br><span class=\"line\">        run(context.TODO())</span><br><span class=\"line\">        panic(&quot;unreachable&quot;)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  LeaderElect  true, controller-manager  HA </span><br><span class=\"line\">\t//  leader  leader  run </span><br><span class=\"line\">    id, err := os.Hostname()</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        return err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // add a uniquifier so that two processes on the same host don&apos;t accidentally both become active</span><br><span class=\"line\">    id = id + &quot;_&quot; + string(uuid.NewUUID())</span><br><span class=\"line\">    </span><br><span class=\"line\">    // </span><br><span class=\"line\">    rl, err := resourcelock.New(c.ComponentConfig.Generic.LeaderElection.ResourceLock,</span><br><span class=\"line\">        &quot;kube-system&quot;,</span><br><span class=\"line\">        &quot;kube-controller-manager&quot;,</span><br><span class=\"line\">        c.LeaderElectionClient.CoreV1(),</span><br><span class=\"line\">        resourcelock.ResourceLockConfig&#123;</span><br><span class=\"line\">            Identity:      id,</span><br><span class=\"line\">            EventRecorder: c.EventRecorder,</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        glog.Fatalf(&quot;error creating lock: %v&quot;, err)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // </span><br><span class=\"line\">    leaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig&#123;</span><br><span class=\"line\">        Lock:          rl,</span><br><span class=\"line\">        LeaseDuration: c.ComponentConfig.Generic.LeaderElection.LeaseDuration.Duration,</span><br><span class=\"line\">        RenewDeadline: c.ComponentConfig.Generic.LeaderElection.RenewDeadline.Duration,</span><br><span class=\"line\">        RetryPeriod:   c.ComponentConfig.Generic.LeaderElection.RetryPeriod.Duration,</span><br><span class=\"line\">        Callbacks: leaderelection.LeaderCallbacks&#123;</span><br><span class=\"line\">            OnStartedLeading: run,</span><br><span class=\"line\">            OnStoppedLeading: func() &#123;</span><br><span class=\"line\">                glog.Fatalf(&quot;leaderelection lost&quot;)</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        WatchDog: electionChecker,</span><br><span class=\"line\">        Name:     &quot;kube-controller-manager&quot;,</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">    panic(&quot;unreachable&quot;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>1kubernetes  <code>endpoints</code> c.ComponentConfig.Generic.LeaderElection.ResourceLock  endpoints ResourceLock </li>\n</ul>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-402b3215eb022307.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p> EventRecorder leader  events  apiserver</p>\n<ul>\n<li><p>2rl  controller-manager  leader RunOrDie  leader </p>\n</li>\n<li><p>3Callbacks  leader  OnStartedLeading  run run  controller-manager run  controller kube-controller-manager  controller</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewControllerInitializers(loopMode ControllerLoopMode) map[string]InitFunc &#123;</span><br><span class=\"line\">\tcontrollers := map[string]InitFunc&#123;&#125;</span><br><span class=\"line\">\tcontrollers[&quot;endpoint&quot;] = startEndpointController</span><br><span class=\"line\">\tcontrollers[&quot;replicationcontroller&quot;] = startReplicationController</span><br><span class=\"line\">\tcontrollers[&quot;podgc&quot;] = startPodGCController</span><br><span class=\"line\">\tcontrollers[&quot;resourcequota&quot;] = startResourceQuotaController</span><br><span class=\"line\">\tcontrollers[&quot;namespace&quot;] = startNamespaceController</span><br><span class=\"line\">\tcontrollers[&quot;serviceaccount&quot;] = startServiceAccountController</span><br><span class=\"line\">\tcontrollers[&quot;garbagecollector&quot;] = startGarbageCollectorController</span><br><span class=\"line\">\tcontrollers[&quot;daemonset&quot;] = startDaemonSetController</span><br><span class=\"line\">\tcontrollers[&quot;job&quot;] = startJobController</span><br><span class=\"line\">\tcontrollers[&quot;deployment&quot;] = startDeploymentController</span><br><span class=\"line\">\tcontrollers[&quot;replicaset&quot;] = startReplicaSetController</span><br><span class=\"line\">\tcontrollers[&quot;horizontalpodautoscaling&quot;] = startHPAController</span><br><span class=\"line\">\tcontrollers[&quot;disruption&quot;] = startDisruptionController</span><br><span class=\"line\">\tcontrollers[&quot;statefulset&quot;] = startStatefulSetController</span><br><span class=\"line\">\tcontrollers[&quot;cronjob&quot;] = startCronJobController</span><br><span class=\"line\">\tcontrollers[&quot;csrsigning&quot;] = startCSRSigningController</span><br><span class=\"line\">\tcontrollers[&quot;csrapproving&quot;] = startCSRApprovingController</span><br><span class=\"line\">\tcontrollers[&quot;csrcleaner&quot;] = startCSRCleanerController</span><br><span class=\"line\">\tcontrollers[&quot;ttl&quot;] = startTTLController</span><br><span class=\"line\">\tcontrollers[&quot;bootstrapsigner&quot;] = startBootstrapSignerController</span><br><span class=\"line\">\tcontrollers[&quot;tokencleaner&quot;] = startTokenCleanerController</span><br><span class=\"line\">\tcontrollers[&quot;nodeipam&quot;] = startNodeIpamController</span><br><span class=\"line\">\tif loopMode == IncludeCloudLoops &#123;</span><br><span class=\"line\">\t\tcontrollers[&quot;service&quot;] = startServiceController</span><br><span class=\"line\">\t\tcontrollers[&quot;route&quot;] = startRouteController</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tcontrollers[&quot;nodelifecycle&quot;] = startNodeLifecycleController</span><br><span class=\"line\">\tcontrollers[&quot;persistentvolume-binder&quot;] = startPersistentVolumeBinderController</span><br><span class=\"line\">\tcontrollers[&quot;attachdetach&quot;] = startAttachDetachController</span><br><span class=\"line\">\tcontrollers[&quot;persistentvolume-expander&quot;] = startVolumeExpandController</span><br><span class=\"line\">\tcontrollers[&quot;clusterrole-aggregation&quot;] = startClusterRoleAggregrationController</span><br><span class=\"line\">\tcontrollers[&quot;pvc-protection&quot;] = startPVCProtectionController</span><br><span class=\"line\">\tcontrollers[&quot;pv-protection&quot;] = startPVProtectionController</span><br><span class=\"line\">\tcontrollers[&quot;ttl-after-finished&quot;] = startTTLAfterFinishedController</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn controllers</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>OnStoppedLeading  leader  slave </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func RunOrDie(ctx context.Context, lec LeaderElectionConfig) &#123;</span><br><span class=\"line\">    le, err := NewLeaderElector(lec)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        panic(err)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if lec.WatchDog != nil &#123;</span><br><span class=\"line\">        lec.WatchDog.SetLeaderElection(le)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    le.Run(ctx)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> RunOrDie  NewLeaderElector  LeaderElector  LeaderElector  run </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) Run(ctx context.Context) &#123;</span><br><span class=\"line\">\tdefer func() &#123;</span><br><span class=\"line\">\t\truntime.HandleCrash()</span><br><span class=\"line\">\t\tle.config.Callbacks.OnStoppedLeading()</span><br><span class=\"line\">\t&#125;()</span><br><span class=\"line\">\tif !le.acquire(ctx) &#123;</span><br><span class=\"line\">\t\treturn // ctx signalled done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tctx, cancel := context.WithCancel(ctx)</span><br><span class=\"line\">\tdefer cancel()</span><br><span class=\"line\">\tgo le.config.Callbacks.OnStartedLeading(ctx)</span><br><span class=\"line\">\tle.renew(ctx)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Run  acquire  OnStartedLeading  controller renew  leader </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) acquire(ctx context.Context) bool &#123;</span><br><span class=\"line\">\tctx, cancel := context.WithCancel(ctx)</span><br><span class=\"line\">\tdefer cancel()</span><br><span class=\"line\">\tsucceeded := false</span><br><span class=\"line\">\tdesc := le.config.Lock.Describe()</span><br><span class=\"line\">\tglog.Infof(&quot;attempting to acquire leader lease  %v...&quot;, desc)</span><br><span class=\"line\">\twait.JitterUntil(func() &#123;</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tsucceeded = le.tryAcquireOrRenew()</span><br><span class=\"line\">\t\t// leader  maybeReportTransition </span><br><span class=\"line\">\t\t//  OnNewLeader() , OnNewLeader() </span><br><span class=\"line\">\t\tle.maybeReportTransition()</span><br><span class=\"line\">\t\tif !succeeded &#123;</span><br><span class=\"line\">\t\t\tglog.V(4).Infof(&quot;failed to acquire lease %v&quot;, desc)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tle.config.Lock.RecordEvent(&quot;became leader&quot;)</span><br><span class=\"line\">\t\tglog.Infof(&quot;successfully acquired lease %v&quot;, desc)</span><br><span class=\"line\">\t\tcancel()</span><br><span class=\"line\">\t&#125;, le.config.RetryPeriod, JitterFactor, true, ctx.Done())</span><br><span class=\"line\">\treturn succeeded</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> acquire  ctx wait.JitterUntil  le.tryAcquireOrRenew  RetryPeriod  ctx  wait.JitterUntil tryAcquireOrRenew </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) tryAcquireOrRenew() bool &#123;</span><br><span class=\"line\">\tnow := metav1.Now()</span><br><span class=\"line\">\tleaderElectionRecord := rl.LeaderElectionRecord&#123;</span><br><span class=\"line\">\t\tHolderIdentity:       le.config.Lock.Identity(),</span><br><span class=\"line\">\t\tLeaseDurationSeconds: int(le.config.LeaseDuration / time.Second),</span><br><span class=\"line\">\t\tRenewTime:            now,</span><br><span class=\"line\">\t\tAcquireTime:          now,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 1</span><br><span class=\"line\">\toldLeaderElectionRecord, err := le.config.Lock.Get()</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tif !errors.IsNotFound(err) &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;error retrieving resource lock %v: %v&quot;, le.config.Lock.Describe(), err)</span><br><span class=\"line\">\t\t\treturn false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//  leader </span><br><span class=\"line\">\t\tif err = le.config.Lock.Create(leaderElectionRecord); err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;error initially creating leader election record: %v&quot;, err)</span><br><span class=\"line\">\t\t\treturn false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tle.observedRecord = leaderElectionRecord</span><br><span class=\"line\">\t\tle.observedTime = le.clock.Now()</span><br><span class=\"line\">\t\treturn true</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 2 id  leader</span><br><span class=\"line\">\tif !reflect.DeepEqual(le.observedRecord, *oldLeaderElectionRecord) &#123;</span><br><span class=\"line\">\t\tle.observedRecord = *oldLeaderElectionRecord</span><br><span class=\"line\">\t\tle.observedTime = le.clock.Now()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//  id  Leader</span><br><span class=\"line\">\tif le.observedTime.Add(le.config.LeaseDuration).After(now.Time) &amp;&amp;</span><br><span class=\"line\">\t\t!le.IsLeader() &#123;</span><br><span class=\"line\">\t\tglog.V(4).Infof(&quot;lock is held by %v and has not yet expired&quot;, oldLeaderElectionRecord.HolderIdentity)</span><br><span class=\"line\">\t\treturn false</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 3 id  Leader</span><br><span class=\"line\">\t//  Leader </span><br><span class=\"line\">\tif le.IsLeader() &#123;</span><br><span class=\"line\">\t\tleaderElectionRecord.AcquireTime = oldLeaderElectionRecord.AcquireTime</span><br><span class=\"line\">\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions + 1</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">    //  Leader </span><br><span class=\"line\">    //  Leader </span><br><span class=\"line\">\tif err = le.config.Lock.Update(leaderElectionRecord); err != nil &#123;</span><br><span class=\"line\">\t\tglog.Errorf(&quot;Failed to update lock: %v&quot;, err)</span><br><span class=\"line\">\t\treturn false</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tle.observedRecord = leaderElectionRecord</span><br><span class=\"line\">\tle.observedTime = le.clock.Now()</span><br><span class=\"line\">\treturn true</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>1 ElectionRecord  ElectionRecord  leader </li>\n<li>2 id  leader  id  Leader</li>\n<li>3 id  Leader</li>\n<li>4 id  Leader  leader </li>\n</ul>\n<p> renew </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) renew(ctx context.Context) &#123;</span><br><span class=\"line\">\tctx, cancel := context.WithCancel(ctx)</span><br><span class=\"line\">\tdefer cancel()</span><br><span class=\"line\">\twait.Until(func() &#123;</span><br><span class=\"line\">\t\ttimeoutCtx, timeoutCancel := context.WithTimeout(ctx, le.config.RenewDeadline)</span><br><span class=\"line\">\t\tdefer timeoutCancel()</span><br><span class=\"line\">\t\t//  RetryPeriod  tryAcquireOrRenew()</span><br><span class=\"line\">        //  tryAcquireOrRenew()  false </span><br><span class=\"line\">\t\terr := wait.PollImmediateUntil(le.config.RetryPeriod, func() (bool, error) &#123;</span><br><span class=\"line\">\t\t\tdone := make(chan bool, 1)</span><br><span class=\"line\">\t\t\tgo func() &#123;</span><br><span class=\"line\">\t\t\t\tdefer close(done)</span><br><span class=\"line\">\t\t\t\tdone &lt;- le.tryAcquireOrRenew()</span><br><span class=\"line\">\t\t\t&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tselect &#123;</span><br><span class=\"line\">\t\t\tcase &lt;-timeoutCtx.Done():</span><br><span class=\"line\">\t\t\t\treturn false, fmt.Errorf(&quot;failed to tryAcquireOrRenew %s&quot;, timeoutCtx.Err())</span><br><span class=\"line\">\t\t\tcase result := &lt;-done:</span><br><span class=\"line\">\t\t\t\treturn result, nil</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;, timeoutCtx.Done())</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tle.maybeReportTransition()</span><br><span class=\"line\">\t\tdesc := le.config.Lock.Describe()</span><br><span class=\"line\">\t\tif err == nil &#123;</span><br><span class=\"line\">\t\t\tglog.V(4).Infof(&quot;successfully renewed lease %v&quot;, desc)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//  Leader panic</span><br><span class=\"line\">\t\tle.config.Lock.RecordEvent(&quot;stopped leading&quot;)</span><br><span class=\"line\">\t\tglog.Infof(&quot;failed to renew lease %v: %v&quot;, desc, err)</span><br><span class=\"line\">\t\tcancel()</span><br><span class=\"line\">\t&#125;, le.config.RetryPeriod, ctx.Done())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>renew  leader </p>\n<h4 id=\"Leader-Election-\"><a href=\"#Leader-Election-\" class=\"headerlink\" title=\"Leader Election \"></a>Leader Election </h4><p> demo k8s  <code>k8s.io/client-go/tools/leaderelection</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;context&quot;</span><br><span class=\"line\">\t&quot;flag&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">\t&quot;time&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&quot;github.com/golang/glog&quot;</span><br><span class=\"line\">\t&quot;k8s.io/api/core/v1&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/kubernetes&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class=\"line\">\tv1core &quot;k8s.io/client-go/kubernetes/typed/core/v1&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/clientcmd&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/leaderelection&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/leaderelection/resourcelock&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/record&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var (</span><br><span class=\"line\">\tmasterURL  string</span><br><span class=\"line\">\tkubeconfig string</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tflag.StringVar(&amp;kubeconfig, &quot;kubeconfig&quot;, &quot;&quot;, &quot;Path to a kubeconfig. Only required if out-of-cluster.&quot;)</span><br><span class=\"line\">\tflag.StringVar(&amp;masterURL, &quot;master&quot;, &quot;&quot;, &quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\tflag.Set(&quot;logtostderr&quot;, &quot;true&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tflag.Parse()</span><br><span class=\"line\">\tdefer glog.Flush()</span><br><span class=\"line\"></span><br><span class=\"line\">\tid, err := os.Hostname()</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tpanic(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t//  kubeconfig </span><br><span class=\"line\">\tcfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Fatalf(&quot;Error building kubeconfig: %s&quot;, err.Error())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  kubeclient</span><br><span class=\"line\">\tkubeClient, err := kubernetes.NewForConfig(cfg)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Fatalf(&quot;Error building kubernetes clientset: %s&quot;, err.Error())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  eventRecorder</span><br><span class=\"line\">\teventBroadcaster := record.NewBroadcaster()</span><br><span class=\"line\">\teventRecorder := eventBroadcaster.NewRecorder(scheme.Scheme, v1.EventSource&#123;Component: &quot;test-1&quot;&#125;)</span><br><span class=\"line\">\teventBroadcaster.StartLogging(glog.Infof)</span><br><span class=\"line\">\teventBroadcaster.StartRecordingToSink(&amp;v1core.EventSinkImpl&#123;Interface: kubeClient.CoreV1().Events(&quot;&quot;)&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\trun := func(ctx context.Context) &#123;</span><br><span class=\"line\">\t\tfmt.Println(&quot;run.........&quot;)</span><br><span class=\"line\">\t\tselect &#123;&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tid = id + &quot;_&quot; + &quot;1&quot;</span><br><span class=\"line\">\trl, err := resourcelock.New(&quot;endpoints&quot;,</span><br><span class=\"line\">\t\t&quot;kube-system&quot;,</span><br><span class=\"line\">\t\t&quot;test&quot;,</span><br><span class=\"line\">\t\tkubeClient.CoreV1(),</span><br><span class=\"line\">\t\tresourcelock.ResourceLockConfig&#123;</span><br><span class=\"line\">\t\t\tIdentity:      id,</span><br><span class=\"line\">\t\t\tEventRecorder: eventRecorder,</span><br><span class=\"line\">\t\t&#125;)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Fatalf(&quot;error creating lock: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tleaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig&#123;</span><br><span class=\"line\">\t\tLock:          rl,</span><br><span class=\"line\">\t\tLeaseDuration: 15 * time.Second,</span><br><span class=\"line\">\t\tRenewDeadline: 10 * time.Second,</span><br><span class=\"line\">\t\tRetryPeriod:   2 * time.Second,</span><br><span class=\"line\">\t\tCallbacks: leaderelection.LeaderCallbacks&#123;</span><br><span class=\"line\">\t\t\tOnStartedLeading: run,</span><br><span class=\"line\">\t\t\tOnStoppedLeading: func() &#123;</span><br><span class=\"line\">\t\t\t\tglog.Info(&quot;leaderelection lost&quot;)</span><br><span class=\"line\">\t\t\t&#125;,</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t\tName: &quot;test-1&quot;,</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> hostname  leader  events  leader </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl describe endpoints test  -n kube-system</span><br><span class=\"line\">Name:         test</span><br><span class=\"line\">Namespace:    kube-system</span><br><span class=\"line\">Labels:       &lt;none&gt;</span><br><span class=\"line\">Annotations:  control-plane.alpha.kubernetes.io/leader=&#123;&quot;holderIdentity&quot;:&quot;localhost_2&quot;,&quot;leaseDurationSeconds&quot;:15,&quot;acquireTime&quot;:&quot;2019-03-10T08:47:42Z&quot;,&quot;renewTime&quot;:&quot;2019-03-10T08:47:44Z&quot;,&quot;leaderTransitions&quot;:2&#125;</span><br><span class=\"line\">Subsets:</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type    Reason          Age   From    Message</span><br><span class=\"line\">  ----    ------          ----  ----    -------</span><br><span class=\"line\">  Normal  LeaderElection  50s   test-1  localhost_1 became leader</span><br><span class=\"line\">  Normal  LeaderElection  5s    test-2  localhost_2 became leader</span><br></pre></td></tr></table></figure>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> kube-controller-manager  HA  leader k8s  endpoints  rediszookeeperetcd  k8s k8s  etcd  update  resourceVersion </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-7ec427b37b6b6a10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"api resource\"></p>\n<p><br><a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/\" target=\"_blank\" rel=\"noopener\">API OVERVIEW</a><br><a href=\"https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/\" target=\"_blank\" rel=\"noopener\">Simple leader election with Kubernetes and Docker</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>k8s  apiserver kube-controller-manager  kube-scheduler  leader  kube-scheduler  kube-manager-controller  leaderleader leader  leader leader </p>\n<blockquote>\n<p>kubernetes  v1.12 </p>\n</blockquote>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>k8s  kube-controller-managerkube-scheduler  <code>--leader-elect=true</code>  HA </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">I0306 19:17:14.109511  161798 flags.go:33] FLAG: --leader-elect=&quot;true&quot;</span><br><span class=\"line\">I0306 19:17:14.109513  161798 flags.go:33] FLAG: --leader-elect-lease-duration=&quot;15s&quot;</span><br><span class=\"line\">I0306 19:17:14.109516  161798 flags.go:33] FLAG: --leader-elect-renew-deadline=&quot;10s&quot;</span><br><span class=\"line\">I0306 19:17:14.109518  161798 flags.go:33] FLAG: --leader-elect-resource-lock=&quot;endpoints&quot;</span><br><span class=\"line\">I0306 19:17:14.109520  161798 flags.go:33] FLAG: --leader-elect-retry-period=&quot;2s&quot;</span><br></pre></td></tr></table></figure>\n<p>kubernetes  leader </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl get endpoints kube-controller-manager --namespace=kube-system -o yaml &amp;&amp; </span><br><span class=\"line\">  kubectl get endpoints kube-scheduler --namespace=kube-system -o yaml</span><br></pre></td></tr></table></figure>\n<p> leader  hostname  annotation  control-plane.alpha.kubernetes.io/leader </p>\n<h4 id=\"Leader-Election-\"><a href=\"#Leader-Election-\" class=\"headerlink\" title=\"Leader Election \"></a>Leader Election </h4><p>Leader Election  Kubernetes  Endpoint </p>\n<p> kube-controller-manager  leader cm  run  <code>k8s.io/kubernetes/cmd/kube-controller-manager/app/controllermanager.go</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Run runs the KubeControllerManagerOptions.  This should never exit.</span><br><span class=\"line\">func Run(c *config.CompletedConfig, stopCh &lt;-chan struct&#123;&#125;) error &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t// kube-controller-manager </span><br><span class=\"line\">\t\trun := func(ctx context.Context) &#123;</span><br><span class=\"line\">\t\trootClientBuilder := controller.SimpleControllerClientBuilder&#123;</span><br><span class=\"line\">\t\t\tClientConfig: c.Kubeconfig,</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tvar clientBuilder controller.ControllerClientBuilder</span><br><span class=\"line\">\t\tif c.ComponentConfig.KubeCloudShared.UseServiceAccountCredentials &#123;</span><br><span class=\"line\">\t\t\tif len(c.ComponentConfig.SAController.ServiceAccountKeyFile) == 0 &#123;</span><br><span class=\"line\">\t\t\t\t// It&apos;c possible another controller process is creating the tokens for us.</span><br><span class=\"line\">\t\t\t\t// If one isn&apos;t, we&apos;ll timeout and exit when our client builder is unable to create the tokens.</span><br><span class=\"line\">\t\t\t\tglog.Warningf(&quot;--use-service-account-credentials was specified without providing a --service-account-private-key-file&quot;)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tclientBuilder = controller.SAControllerClientBuilder&#123;</span><br><span class=\"line\">\t\t\t\tClientConfig:         restclient.AnonymousClientConfig(c.Kubeconfig),</span><br><span class=\"line\">\t\t\t\tCoreClient:           c.Client.CoreV1(),</span><br><span class=\"line\">\t\t\t\tAuthenticationClient: c.Client.AuthenticationV1(),</span><br><span class=\"line\">\t\t\t\tNamespace:            &quot;kube-system&quot;,</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125; else &#123;</span><br><span class=\"line\">\t\t\tclientBuilder = rootClientBuilder</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tcontrollerContext, err := CreateControllerContext(c, rootClientBuilder, clientBuilder, ctx.Done())</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Fatalf(&quot;error building controller context: %v&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tsaTokenControllerInitFunc := serviceAccountTokenControllerStarter&#123;rootClientBuilder: rootClientBuilder&#125;.startServiceAccountTokenController</span><br><span class=\"line\">\t\t//  controller</span><br><span class=\"line\">\t\tif err := StartControllers(controllerContext, saTokenControllerInitFunc, NewControllerInitializers(controllerContext.LoopMode), unsecuredMux); err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Fatalf(&quot;error starting controllers: %v&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tcontrollerContext.InformerFactory.Start(controllerContext.Stop)</span><br><span class=\"line\">\t\tclose(controllerContext.InformersStarted)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tselect &#123;&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    //  LeaderElect , controller-manager </span><br><span class=\"line\">    //  run </span><br><span class=\"line\">    if !c.ComponentConfig.Generic.LeaderElection.LeaderElect &#123;</span><br><span class=\"line\">        run(context.TODO())</span><br><span class=\"line\">        panic(&quot;unreachable&quot;)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  LeaderElect  true, controller-manager  HA </span><br><span class=\"line\">\t//  leader  leader  run </span><br><span class=\"line\">    id, err := os.Hostname()</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        return err</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    // add a uniquifier so that two processes on the same host don&apos;t accidentally both become active</span><br><span class=\"line\">    id = id + &quot;_&quot; + string(uuid.NewUUID())</span><br><span class=\"line\">    </span><br><span class=\"line\">    // </span><br><span class=\"line\">    rl, err := resourcelock.New(c.ComponentConfig.Generic.LeaderElection.ResourceLock,</span><br><span class=\"line\">        &quot;kube-system&quot;,</span><br><span class=\"line\">        &quot;kube-controller-manager&quot;,</span><br><span class=\"line\">        c.LeaderElectionClient.CoreV1(),</span><br><span class=\"line\">        resourcelock.ResourceLockConfig&#123;</span><br><span class=\"line\">            Identity:      id,</span><br><span class=\"line\">            EventRecorder: c.EventRecorder,</span><br><span class=\"line\">        &#125;)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        glog.Fatalf(&quot;error creating lock: %v&quot;, err)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    // </span><br><span class=\"line\">    leaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig&#123;</span><br><span class=\"line\">        Lock:          rl,</span><br><span class=\"line\">        LeaseDuration: c.ComponentConfig.Generic.LeaderElection.LeaseDuration.Duration,</span><br><span class=\"line\">        RenewDeadline: c.ComponentConfig.Generic.LeaderElection.RenewDeadline.Duration,</span><br><span class=\"line\">        RetryPeriod:   c.ComponentConfig.Generic.LeaderElection.RetryPeriod.Duration,</span><br><span class=\"line\">        Callbacks: leaderelection.LeaderCallbacks&#123;</span><br><span class=\"line\">            OnStartedLeading: run,</span><br><span class=\"line\">            OnStoppedLeading: func() &#123;</span><br><span class=\"line\">                glog.Fatalf(&quot;leaderelection lost&quot;)</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        WatchDog: electionChecker,</span><br><span class=\"line\">        Name:     &quot;kube-controller-manager&quot;,</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">    panic(&quot;unreachable&quot;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>1kubernetes  <code>endpoints</code> c.ComponentConfig.Generic.LeaderElection.ResourceLock  endpoints ResourceLock </li>\n</ul>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-402b3215eb022307.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p> EventRecorder leader  events  apiserver</p>\n<ul>\n<li><p>2rl  controller-manager  leader RunOrDie  leader </p>\n</li>\n<li><p>3Callbacks  leader  OnStartedLeading  run run  controller-manager run  controller kube-controller-manager  controller</p>\n</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewControllerInitializers(loopMode ControllerLoopMode) map[string]InitFunc &#123;</span><br><span class=\"line\">\tcontrollers := map[string]InitFunc&#123;&#125;</span><br><span class=\"line\">\tcontrollers[&quot;endpoint&quot;] = startEndpointController</span><br><span class=\"line\">\tcontrollers[&quot;replicationcontroller&quot;] = startReplicationController</span><br><span class=\"line\">\tcontrollers[&quot;podgc&quot;] = startPodGCController</span><br><span class=\"line\">\tcontrollers[&quot;resourcequota&quot;] = startResourceQuotaController</span><br><span class=\"line\">\tcontrollers[&quot;namespace&quot;] = startNamespaceController</span><br><span class=\"line\">\tcontrollers[&quot;serviceaccount&quot;] = startServiceAccountController</span><br><span class=\"line\">\tcontrollers[&quot;garbagecollector&quot;] = startGarbageCollectorController</span><br><span class=\"line\">\tcontrollers[&quot;daemonset&quot;] = startDaemonSetController</span><br><span class=\"line\">\tcontrollers[&quot;job&quot;] = startJobController</span><br><span class=\"line\">\tcontrollers[&quot;deployment&quot;] = startDeploymentController</span><br><span class=\"line\">\tcontrollers[&quot;replicaset&quot;] = startReplicaSetController</span><br><span class=\"line\">\tcontrollers[&quot;horizontalpodautoscaling&quot;] = startHPAController</span><br><span class=\"line\">\tcontrollers[&quot;disruption&quot;] = startDisruptionController</span><br><span class=\"line\">\tcontrollers[&quot;statefulset&quot;] = startStatefulSetController</span><br><span class=\"line\">\tcontrollers[&quot;cronjob&quot;] = startCronJobController</span><br><span class=\"line\">\tcontrollers[&quot;csrsigning&quot;] = startCSRSigningController</span><br><span class=\"line\">\tcontrollers[&quot;csrapproving&quot;] = startCSRApprovingController</span><br><span class=\"line\">\tcontrollers[&quot;csrcleaner&quot;] = startCSRCleanerController</span><br><span class=\"line\">\tcontrollers[&quot;ttl&quot;] = startTTLController</span><br><span class=\"line\">\tcontrollers[&quot;bootstrapsigner&quot;] = startBootstrapSignerController</span><br><span class=\"line\">\tcontrollers[&quot;tokencleaner&quot;] = startTokenCleanerController</span><br><span class=\"line\">\tcontrollers[&quot;nodeipam&quot;] = startNodeIpamController</span><br><span class=\"line\">\tif loopMode == IncludeCloudLoops &#123;</span><br><span class=\"line\">\t\tcontrollers[&quot;service&quot;] = startServiceController</span><br><span class=\"line\">\t\tcontrollers[&quot;route&quot;] = startRouteController</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tcontrollers[&quot;nodelifecycle&quot;] = startNodeLifecycleController</span><br><span class=\"line\">\tcontrollers[&quot;persistentvolume-binder&quot;] = startPersistentVolumeBinderController</span><br><span class=\"line\">\tcontrollers[&quot;attachdetach&quot;] = startAttachDetachController</span><br><span class=\"line\">\tcontrollers[&quot;persistentvolume-expander&quot;] = startVolumeExpandController</span><br><span class=\"line\">\tcontrollers[&quot;clusterrole-aggregation&quot;] = startClusterRoleAggregrationController</span><br><span class=\"line\">\tcontrollers[&quot;pvc-protection&quot;] = startPVCProtectionController</span><br><span class=\"line\">\tcontrollers[&quot;pv-protection&quot;] = startPVProtectionController</span><br><span class=\"line\">\tcontrollers[&quot;ttl-after-finished&quot;] = startTTLAfterFinishedController</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn controllers</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>OnStoppedLeading  leader  slave </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func RunOrDie(ctx context.Context, lec LeaderElectionConfig) &#123;</span><br><span class=\"line\">    le, err := NewLeaderElector(lec)</span><br><span class=\"line\">    if err != nil &#123;</span><br><span class=\"line\">        panic(err)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    if lec.WatchDog != nil &#123;</span><br><span class=\"line\">        lec.WatchDog.SetLeaderElection(le)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    le.Run(ctx)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> RunOrDie  NewLeaderElector  LeaderElector  LeaderElector  run </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) Run(ctx context.Context) &#123;</span><br><span class=\"line\">\tdefer func() &#123;</span><br><span class=\"line\">\t\truntime.HandleCrash()</span><br><span class=\"line\">\t\tle.config.Callbacks.OnStoppedLeading()</span><br><span class=\"line\">\t&#125;()</span><br><span class=\"line\">\tif !le.acquire(ctx) &#123;</span><br><span class=\"line\">\t\treturn // ctx signalled done</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tctx, cancel := context.WithCancel(ctx)</span><br><span class=\"line\">\tdefer cancel()</span><br><span class=\"line\">\tgo le.config.Callbacks.OnStartedLeading(ctx)</span><br><span class=\"line\">\tle.renew(ctx)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Run  acquire  OnStartedLeading  controller renew  leader </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) acquire(ctx context.Context) bool &#123;</span><br><span class=\"line\">\tctx, cancel := context.WithCancel(ctx)</span><br><span class=\"line\">\tdefer cancel()</span><br><span class=\"line\">\tsucceeded := false</span><br><span class=\"line\">\tdesc := le.config.Lock.Describe()</span><br><span class=\"line\">\tglog.Infof(&quot;attempting to acquire leader lease  %v...&quot;, desc)</span><br><span class=\"line\">\twait.JitterUntil(func() &#123;</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tsucceeded = le.tryAcquireOrRenew()</span><br><span class=\"line\">\t\t// leader  maybeReportTransition </span><br><span class=\"line\">\t\t//  OnNewLeader() , OnNewLeader() </span><br><span class=\"line\">\t\tle.maybeReportTransition()</span><br><span class=\"line\">\t\tif !succeeded &#123;</span><br><span class=\"line\">\t\t\tglog.V(4).Infof(&quot;failed to acquire lease %v&quot;, desc)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tle.config.Lock.RecordEvent(&quot;became leader&quot;)</span><br><span class=\"line\">\t\tglog.Infof(&quot;successfully acquired lease %v&quot;, desc)</span><br><span class=\"line\">\t\tcancel()</span><br><span class=\"line\">\t&#125;, le.config.RetryPeriod, JitterFactor, true, ctx.Done())</span><br><span class=\"line\">\treturn succeeded</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> acquire  ctx wait.JitterUntil  le.tryAcquireOrRenew  RetryPeriod  ctx  wait.JitterUntil tryAcquireOrRenew </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) tryAcquireOrRenew() bool &#123;</span><br><span class=\"line\">\tnow := metav1.Now()</span><br><span class=\"line\">\tleaderElectionRecord := rl.LeaderElectionRecord&#123;</span><br><span class=\"line\">\t\tHolderIdentity:       le.config.Lock.Identity(),</span><br><span class=\"line\">\t\tLeaseDurationSeconds: int(le.config.LeaseDuration / time.Second),</span><br><span class=\"line\">\t\tRenewTime:            now,</span><br><span class=\"line\">\t\tAcquireTime:          now,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 1</span><br><span class=\"line\">\toldLeaderElectionRecord, err := le.config.Lock.Get()</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tif !errors.IsNotFound(err) &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;error retrieving resource lock %v: %v&quot;, le.config.Lock.Describe(), err)</span><br><span class=\"line\">\t\t\treturn false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//  leader </span><br><span class=\"line\">\t\tif err = le.config.Lock.Create(leaderElectionRecord); err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;error initially creating leader election record: %v&quot;, err)</span><br><span class=\"line\">\t\t\treturn false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tle.observedRecord = leaderElectionRecord</span><br><span class=\"line\">\t\tle.observedTime = le.clock.Now()</span><br><span class=\"line\">\t\treturn true</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 2 id  leader</span><br><span class=\"line\">\tif !reflect.DeepEqual(le.observedRecord, *oldLeaderElectionRecord) &#123;</span><br><span class=\"line\">\t\tle.observedRecord = *oldLeaderElectionRecord</span><br><span class=\"line\">\t\tle.observedTime = le.clock.Now()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//  id  Leader</span><br><span class=\"line\">\tif le.observedTime.Add(le.config.LeaseDuration).After(now.Time) &amp;&amp;</span><br><span class=\"line\">\t\t!le.IsLeader() &#123;</span><br><span class=\"line\">\t\tglog.V(4).Infof(&quot;lock is held by %v and has not yet expired&quot;, oldLeaderElectionRecord.HolderIdentity)</span><br><span class=\"line\">\t\treturn false</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 3 id  Leader</span><br><span class=\"line\">\t//  Leader </span><br><span class=\"line\">\tif le.IsLeader() &#123;</span><br><span class=\"line\">\t\tleaderElectionRecord.AcquireTime = oldLeaderElectionRecord.AcquireTime</span><br><span class=\"line\">\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tleaderElectionRecord.LeaderTransitions = oldLeaderElectionRecord.LeaderTransitions + 1</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">    //  Leader </span><br><span class=\"line\">    //  Leader </span><br><span class=\"line\">\tif err = le.config.Lock.Update(leaderElectionRecord); err != nil &#123;</span><br><span class=\"line\">\t\tglog.Errorf(&quot;Failed to update lock: %v&quot;, err)</span><br><span class=\"line\">\t\treturn false</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tle.observedRecord = leaderElectionRecord</span><br><span class=\"line\">\tle.observedTime = le.clock.Now()</span><br><span class=\"line\">\treturn true</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p></p>\n<ul>\n<li>1 ElectionRecord  ElectionRecord  leader </li>\n<li>2 id  leader  id  Leader</li>\n<li>3 id  Leader</li>\n<li>4 id  Leader  leader </li>\n</ul>\n<p> renew </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (le *LeaderElector) renew(ctx context.Context) &#123;</span><br><span class=\"line\">\tctx, cancel := context.WithCancel(ctx)</span><br><span class=\"line\">\tdefer cancel()</span><br><span class=\"line\">\twait.Until(func() &#123;</span><br><span class=\"line\">\t\ttimeoutCtx, timeoutCancel := context.WithTimeout(ctx, le.config.RenewDeadline)</span><br><span class=\"line\">\t\tdefer timeoutCancel()</span><br><span class=\"line\">\t\t//  RetryPeriod  tryAcquireOrRenew()</span><br><span class=\"line\">        //  tryAcquireOrRenew()  false </span><br><span class=\"line\">\t\terr := wait.PollImmediateUntil(le.config.RetryPeriod, func() (bool, error) &#123;</span><br><span class=\"line\">\t\t\tdone := make(chan bool, 1)</span><br><span class=\"line\">\t\t\tgo func() &#123;</span><br><span class=\"line\">\t\t\t\tdefer close(done)</span><br><span class=\"line\">\t\t\t\tdone &lt;- le.tryAcquireOrRenew()</span><br><span class=\"line\">\t\t\t&#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tselect &#123;</span><br><span class=\"line\">\t\t\tcase &lt;-timeoutCtx.Done():</span><br><span class=\"line\">\t\t\t\treturn false, fmt.Errorf(&quot;failed to tryAcquireOrRenew %s&quot;, timeoutCtx.Err())</span><br><span class=\"line\">\t\t\tcase result := &lt;-done:</span><br><span class=\"line\">\t\t\t\treturn result, nil</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;, timeoutCtx.Done())</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tle.maybeReportTransition()</span><br><span class=\"line\">\t\tdesc := le.config.Lock.Describe()</span><br><span class=\"line\">\t\tif err == nil &#123;</span><br><span class=\"line\">\t\t\tglog.V(4).Infof(&quot;successfully renewed lease %v&quot;, desc)</span><br><span class=\"line\">\t\t\treturn</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//  Leader panic</span><br><span class=\"line\">\t\tle.config.Lock.RecordEvent(&quot;stopped leading&quot;)</span><br><span class=\"line\">\t\tglog.Infof(&quot;failed to renew lease %v: %v&quot;, desc, err)</span><br><span class=\"line\">\t\tcancel()</span><br><span class=\"line\">\t&#125;, le.config.RetryPeriod, ctx.Done())</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>renew  leader </p>\n<h4 id=\"Leader-Election-\"><a href=\"#Leader-Election-\" class=\"headerlink\" title=\"Leader Election \"></a>Leader Election </h4><p> demo k8s  <code>k8s.io/client-go/tools/leaderelection</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;context&quot;</span><br><span class=\"line\">\t&quot;flag&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">\t&quot;os&quot;</span><br><span class=\"line\">\t&quot;time&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&quot;github.com/golang/glog&quot;</span><br><span class=\"line\">\t&quot;k8s.io/api/core/v1&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/kubernetes&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/kubernetes/scheme&quot;</span><br><span class=\"line\">\tv1core &quot;k8s.io/client-go/kubernetes/typed/core/v1&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/clientcmd&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/leaderelection&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/leaderelection/resourcelock&quot;</span><br><span class=\"line\">\t&quot;k8s.io/client-go/tools/record&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var (</span><br><span class=\"line\">\tmasterURL  string</span><br><span class=\"line\">\tkubeconfig string</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">func init() &#123;</span><br><span class=\"line\">\tflag.StringVar(&amp;kubeconfig, &quot;kubeconfig&quot;, &quot;&quot;, &quot;Path to a kubeconfig. Only required if out-of-cluster.&quot;)</span><br><span class=\"line\">\tflag.StringVar(&amp;masterURL, &quot;master&quot;, &quot;&quot;, &quot;The address of the Kubernetes API server. Overrides any value in kubeconfig. Only required if out-of-cluster.&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\tflag.Set(&quot;logtostderr&quot;, &quot;true&quot;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\tflag.Parse()</span><br><span class=\"line\">\tdefer glog.Flush()</span><br><span class=\"line\"></span><br><span class=\"line\">\tid, err := os.Hostname()</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tpanic(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t//  kubeconfig </span><br><span class=\"line\">\tcfg, err := clientcmd.BuildConfigFromFlags(masterURL, kubeconfig)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Fatalf(&quot;Error building kubeconfig: %s&quot;, err.Error())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  kubeclient</span><br><span class=\"line\">\tkubeClient, err := kubernetes.NewForConfig(cfg)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Fatalf(&quot;Error building kubernetes clientset: %s&quot;, err.Error())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  eventRecorder</span><br><span class=\"line\">\teventBroadcaster := record.NewBroadcaster()</span><br><span class=\"line\">\teventRecorder := eventBroadcaster.NewRecorder(scheme.Scheme, v1.EventSource&#123;Component: &quot;test-1&quot;&#125;)</span><br><span class=\"line\">\teventBroadcaster.StartLogging(glog.Infof)</span><br><span class=\"line\">\teventBroadcaster.StartRecordingToSink(&amp;v1core.EventSinkImpl&#123;Interface: kubeClient.CoreV1().Events(&quot;&quot;)&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\trun := func(ctx context.Context) &#123;</span><br><span class=\"line\">\t\tfmt.Println(&quot;run.........&quot;)</span><br><span class=\"line\">\t\tselect &#123;&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tid = id + &quot;_&quot; + &quot;1&quot;</span><br><span class=\"line\">\trl, err := resourcelock.New(&quot;endpoints&quot;,</span><br><span class=\"line\">\t\t&quot;kube-system&quot;,</span><br><span class=\"line\">\t\t&quot;test&quot;,</span><br><span class=\"line\">\t\tkubeClient.CoreV1(),</span><br><span class=\"line\">\t\tresourcelock.ResourceLockConfig&#123;</span><br><span class=\"line\">\t\t\tIdentity:      id,</span><br><span class=\"line\">\t\t\tEventRecorder: eventRecorder,</span><br><span class=\"line\">\t\t&#125;)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tglog.Fatalf(&quot;error creating lock: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tleaderelection.RunOrDie(context.TODO(), leaderelection.LeaderElectionConfig&#123;</span><br><span class=\"line\">\t\tLock:          rl,</span><br><span class=\"line\">\t\tLeaseDuration: 15 * time.Second,</span><br><span class=\"line\">\t\tRenewDeadline: 10 * time.Second,</span><br><span class=\"line\">\t\tRetryPeriod:   2 * time.Second,</span><br><span class=\"line\">\t\tCallbacks: leaderelection.LeaderCallbacks&#123;</span><br><span class=\"line\">\t\t\tOnStartedLeading: run,</span><br><span class=\"line\">\t\t\tOnStoppedLeading: func() &#123;</span><br><span class=\"line\">\t\t\t\tglog.Info(&quot;leaderelection lost&quot;)</span><br><span class=\"line\">\t\t\t&#125;,</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t\tName: &quot;test-1&quot;,</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> hostname  leader  events  leader </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># kubectl describe endpoints test  -n kube-system</span><br><span class=\"line\">Name:         test</span><br><span class=\"line\">Namespace:    kube-system</span><br><span class=\"line\">Labels:       &lt;none&gt;</span><br><span class=\"line\">Annotations:  control-plane.alpha.kubernetes.io/leader=&#123;&quot;holderIdentity&quot;:&quot;localhost_2&quot;,&quot;leaseDurationSeconds&quot;:15,&quot;acquireTime&quot;:&quot;2019-03-10T08:47:42Z&quot;,&quot;renewTime&quot;:&quot;2019-03-10T08:47:44Z&quot;,&quot;leaderTransitions&quot;:2&#125;</span><br><span class=\"line\">Subsets:</span><br><span class=\"line\">Events:</span><br><span class=\"line\">  Type    Reason          Age   From    Message</span><br><span class=\"line\">  ----    ------          ----  ----    -------</span><br><span class=\"line\">  Normal  LeaderElection  50s   test-1  localhost_1 became leader</span><br><span class=\"line\">  Normal  LeaderElection  5s    test-2  localhost_2 became leader</span><br></pre></td></tr></table></figure>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p> kube-controller-manager  HA  leader k8s  endpoints  rediszookeeperetcd  k8s k8s  etcd  update  resourceVersion </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-7ec427b37b6b6a10.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"api resource\"></p>\n<p><br><a href=\"https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/\" target=\"_blank\" rel=\"noopener\">API OVERVIEW</a><br><a href=\"https://kubernetes.io/blog/2016/01/simple-leader-election-with-kubernetes/\" target=\"_blank\" rel=\"noopener\">Simple leader election with Kubernetes and Docker</a></p>\n"},{"title":"kubernets ","date":"2019-02-26T12:49:30.000Z","type":"k8s-events","_content":"\n node  pod  kubectl  events events  k8s  apiserver k8s  kubectl describe  events k8s  events  \n\n `k8s.io/kubernetes/cmd`  events\n```\n$ grep -R -n -i \"EventRecorder\" .\n```\n\ncontroller-managekube-proxykube-schedulerkubelet  EventRecorder kubelet  Events \n\n\n\n##### 1Events \n\nevents  `k8s.io/api/core/v1/types.go` ,\n\n```\ntype Event struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata\" protobuf:\"bytes,1,opt,name=metadata\"`\n    InvolvedObject ObjectReference `json:\"involvedObject\" protobuf:\"bytes,2,opt,name=involvedObject\"`\n    Reason string `json:\"reason,omitempty\" protobuf:\"bytes,3,opt,name=reason\"`\n    Message string `json:\"message,omitempty\" protobuf:\"bytes,4,opt,name=message\"`\n    Source EventSource `json:\"source,omitempty\" protobuf:\"bytes,5,opt,name=source\"`\n    FirstTimestamp metav1.Time `json:\"firstTimestamp,omitempty\" protobuf:\"bytes,6,opt,name=firstTimestamp\"`\n    LastTimestamp metav1.Time `json:\"lastTimestamp,omitempty\" protobuf:\"bytes,7,opt,name=lastTimestamp\"`\n    Count int32 `json:\"count,omitempty\" protobuf:\"varint,8,opt,name=count\"`\n    Type string `json:\"type,omitempty\" protobuf:\"bytes,9,opt,name=type\"`\n    EventTime metav1.MicroTime `json:\"eventTime,omitempty\" protobuf:\"bytes,10,opt,name=eventTime\"`\n    Series *EventSeries `json:\"series,omitempty\" protobuf:\"bytes,11,opt,name=series\"`\n    Action string `json:\"action,omitempty\" protobuf:\"bytes,12,opt,name=action\"`\n    Related *ObjectReference `json:\"related,omitempty\" protobuf:\"bytes,13,opt,name=related\"`\n    ReportingController string `json:\"reportingComponent\" protobuf:\"bytes,14,opt,name=reportingComponent\"`\n    ReportingInstance string `json:\"reportingInstance\" protobuf:\"bytes,15,opt,name=reportingInstance\"`\n    ReportingInstance string `json:\"reportingInstance\" protobuf:\"bytes,15,opt,name=reportingInstance\"`\n}\n```\n\n InvolvedObject source  kubectl  TypeReasonAgeFromMessage \n\nk8s  events \"Normal\"  \"Warning\"\n\n![events ](https://upload-images.jianshu.io/upload_images/1262158-c42d7442b2bc38d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n##### 2EventBroadcaster \n\nevents  EventBroadcaster kubelet  EventBroadcaster `k8s.io/kubernetes/cmd/kubelet/app/server.go`\n\n\n```\nfunc RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error {\n  ...\n  // event \n  makeEventRecorder(kubeDeps, nodeName)\n  ...\n}\n\n\nfunc makeEventRecorder(kubeDeps *kubelet.Dependencies, nodeName types.NodeName) {\n  if kubeDeps.Recorder != nil {\n    return\n  }\n  //  EventBroadcaster \n  eventBroadcaster := record.NewBroadcaster()\n  //  EventRecorder\n  kubeDeps.Recorder = eventBroadcaster.NewRecorder(legacyscheme.Scheme, v1.EventSource{Component: componentKubelet, Host: string(nodeName)})\n  //  events \n  eventBroadcaster.StartLogging(glog.V(3).Infof)\n  if kubeDeps.EventClient != nil {\n    glog.V(4).Infof(\"Sending events to api server.\")\n    //  events  apiserver\n  eventBroadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: kubeDeps.EventClient.Events(\"\")})\n  } else {\n    glog.Warning(\"No api server defined - no events will be sent to API server.\")\n  }\n}\n```\n\nKubelet  EventBroadcaster events (EventBroadcaster  kubelet  events  `k8s.io/client-go/tools/record/event.go` \n\n```\ntype eventBroadcasterImpl struct {\n  *watch.Broadcaster\n  sleepDuration time.Duration\n}\n\n// EventBroadcaster knows how to receive events and send them to any EventSink, watcher, or log.\ntype EventBroadcaster interface {\n  StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface\n\n  StartRecordingToSink(sink EventSink) watch.Interface\n\n  StartLogging(logf func(format string, args ...interface{})) watch.Interface\n\n  NewRecorder(scheme *runtime.Scheme, source v1.EventSource) EventRecorder\n}\n```\n\nEventBroadcaster \n- StartEventWatcher()  EventBroadcaster  events events  StartEventWatcher()  events  handle \n- StartRecordingToSink()   StartEventWatcher()  events events  apiserver \n- StartLogging()  StartEventWatcher()  events events \n- NewRecorder()  EventSource  EventRecorderEventSource \n\n\neventBroadcasterImpl  eventBroadcaster  EventBroadcaster  BroadcasterBroadcaster  goroutine  events  watcher\n\n```\nfunc NewBroadcaster() EventBroadcaster {\n  return &eventBroadcasterImpl{watch.NewBroadcaster(maxQueuedEvents, watch.DropIfChannelFull), defaultSleepDuration}\n}\n```\n\nkubelet  EventBroadcaster  StartRecordingToSink()  StartLogging() StartRecordingToSink()  events  apiserverStartLogging()  events  kubelet \n\n##### 3Events \n\n EventBroadcaster  kubelet  EventBroadcaster  EventRecorder Broadcaster  EventRecorderEventBroadcasterEventRecorderBroadcaster EventRecorder  events\n\n```\ntype recorderImpl struct {\n  scheme *runtime.Scheme\n  source v1.EventSource\n  *watch.Broadcaster\n  clock clock.Clock\n}\n\ntype EventRecorder interface {\n  Event(object runtime.Object, eventtype, reason, message string)\n\n  Eventf(object runtime.Object, eventtype, reason, messageFmt string, args ...interface{})\n\n  PastEventf(object runtime.Object, timestamp metav1.Time, eventtype, reason, messageFmt string, args ...interface{})\n\n  AnnotatedEventf(object runtime.Object, annotations map[string]string, eventtype, reason, messageFmt string, args ...interface{})\n}\n```\n\nEventRecorder  eventsEvent()  Eventf()  fmt.Println()  fmt.Printf()kubelet  EventRecorder  eventsrecorderImpl  EventRecorder EventRecorder  generateEvent generateEvent  events \n\n events \n\n```\nfunc (recorder *recorderImpl) generateEvent(object runtime.Object, annotations map[string]string, timestamp metav1.Time, eventtype, reason, message string) {\n  ref, err := ref.GetReference(recorder.scheme, object)\n  if err != nil {\n    glog.Errorf(\"Could not construct reference to: '%#v' due to: '%v'. Will not report event: '%v' '%v' '%v'\", object, err, eventtype, reason, message)\n    return\n  }\n\n  if !validateEventType(eventtype) {\n    glog.Errorf(\"Unsupported event type: '%v'\", eventtype)\n    return\n  }\n\n  event := recorder.makeEvent(ref, annotations, eventtype, reason, message)\n  event.Source = recorder.source\n\n  go func() {\n    // NOTE: events should be a non-blocking operation\n    defer utilruntime.HandleCrash()\n    // \n    recorder.Action(watch.Added, event)\n  }()\n}\n\nfunc (recorder *recorderImpl) makeEvent(ref *v1.ObjectReference, annotations map[string]string, eventtype, reason, message string) *v1.Event {\n  t := metav1.Time{Time: recorder.clock.Now()}\n  namespace := ref.Namespace\n  if namespace == \"\" {\n    namespace = metav1.NamespaceDefault\n  }\n  return &v1.Event{\n    ObjectMeta: metav1.ObjectMeta{\n      Name:        fmt.Sprintf(\"%v.%x\", ref.Name, t.UnixNano()),\n      Namespace:   namespace,\n      Annotations: annotations,\n    },\n    InvolvedObject: *ref,\n    Reason:         reason,\n    Message:        message,\n    FirstTimestamp: t,\n    LastTimestamp:  t,\n    Count:          1,\n    Type:           eventtype,\n  }\n}\n```\n events  recorder.Action()  events  Broadcaster , Action()  Broadcaster \n\n Action() \n\n```\nfunc (m *Broadcaster) Action(action EventType, obj runtime.Object) {\n  m.incoming <- Event{action, obj}\n}\n```\n\n##### 4Events \n\nEventBroadcaster  BroadcasterBroadcaster  events Broadcaster  `k8s.io/apimachinery/pkg/watch/mux.go ` Broadcaster  goroutine EventRecorder  eventsBroadcaster  map  watcher  events  watcher watcher  channelwatcher  ResultChan()  channel \n\n\n Broadcaster  events \n```\nfunc (m *Broadcaster) loop() {\n  for event := range m.incoming {\n    if event.Type == internalRunFunctionMarker {\n      event.Object.(functionFakeRuntimeObject)()\n      continue\n    }\n    m.distribute(event)\n  }\n  m.closeAll()\n  m.distributing.Done()\n}\n\n// distribute sends event to all watchers. Blocking.\nfunc (m *Broadcaster) distribute(event Event) {\n  m.lock.Lock()\n  defer m.lock.Unlock()\n  if m.fullChannelBehavior == DropIfChannelFull {\n    for _, w := range m.watchers {\n      select {\n      case w.result <- event:\n      case <-w.stopped:\n      default: // Don't block if the event can't be queued.\n      }\n    }\n  } else {\n    for _, w := range m.watchers {\n      select {\n      case w.result <- event:\n      case <-w.stopped:\n      }\n    }\n  }\n}\n```\n\n\n##### 5Events \n\n watcher  events  client  watcher events  EventBroadcaster  EventBroadcaster  events \n\n```\nfunc (eventBroadcaster *eventBroadcasterImpl) StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface {\n  watcher := eventBroadcaster.Watch()\n  go func() {\n    defer utilruntime.HandleCrash()\n    for watchEvent := range watcher.ResultChan() {\n      event, ok := watchEvent.Object.(*v1.Event)\n      if !ok {\n        // This is all local, so there's no reason this should\n        // ever happen.\n        continue\n      }\n      eventHandler(event)\n    }\n  }()\n  return watcher\n}\n```\n\nStartEventWatcher()  watcher watcher  Broadcaster  watcher watcher  Broadcaster  channel  events eventHandler StartLogging()  StartRecordingToSink()  StartEventWatcher() \n\n\n\n```\nfunc (eventBroadcaster *eventBroadcasterImpl) StartLogging(logf func(format string, args ...interface{})) watch.Interface {\n  return eventBroadcaster.StartEventWatcher(\n    func(e *v1.Event) {\n      logf(\"Event(%#v): type: '%v' reason: '%v' %v\", e.InvolvedObject, e.Type, e.Reason, e.Message)\n    })\n}\n```\n\nStartLogging()  eventHandler  events \n\n```\nfunc (eventBroadcaster *eventBroadcasterImpl) StartRecordingToSink(sink EventSink) watch.Interface {\n  // The default math/rand package functions aren't thread safe, so create a\n  // new Rand object for each StartRecording call.\n  randGen := rand.New(rand.NewSource(time.Now().UnixNano()))\n  eventCorrelator := NewEventCorrelator(clock.RealClock{})\n  return eventBroadcaster.StartEventWatcher(\n    func(event *v1.Event) {\n      recordToSink(sink, event, eventCorrelator, randGen, eventBroadcaster.sleepDuration)\n    })\n}\n\nfunc recordToSink(sink EventSink, event *v1.Event, eventCorrelator *EventCorrelator, randGen *rand.Rand, sleepDuration time.Duration) {\n  eventCopy := *event\n  event = &eventCopy\n  result, err := eventCorrelator.EventCorrelate(event)\n  if err != nil {\n    utilruntime.HandleError(err)\n  }\n  if result.Skip {\n    return\n  }\n  tries := 0\n  for {\n    if recordEvent(sink, result.Event, result.Patch, result.Event.Count > 1, eventCorrelator) {\n      break\n    }\n    tries++\n    if tries >= maxTriesPerEvent {\n      glog.Errorf(\"Unable to write event '%#v' (retry limit exceeded!)\", event)\n      break\n    }\n    //  apiserver \n    if tries == 1 {\n      time.Sleep(time.Duration(float64(sleepDuration) * randGen.Float64()))\n    } else {\n      time.Sleep(sleepDuration)\n    }\n  }\n}\n```\n\nStartRecordingToSink()  randGen apiserver EventCorrelatorEventCorrelator  recordToSink() recordToSink()  events  apiserver StartEventWatcher() \n\n\n##### 6Events \n\n events  demo events \n\n- 1\n- 2\n- 3\n- 4\n- 5\n\n```\npackage main\n\nimport (\n  \"fmt\"\n  \"sync\"\n  \"time\"\n)\n\n// watcher queue\nconst queueLength = int64(1)\n\n// Events xxx\ntype Events struct {\n  Reason    string\n  Message   string\n  Source    string\n  Type      string\n  Count     int64\n  Timestamp time.Time\n}\n\n// EventBroadcaster xxx\ntype EventBroadcaster interface {\n  Event(etype, reason, message string)\n  StartLogging() Interface\n  Stop()\n}\n\n// eventBroadcaster xxx\ntype eventBroadcasterImpl struct {\n  *Broadcaster\n}\n\nfunc NewEventBroadcaster() EventBroadcaster {\n  return &eventBroadcasterImpl{NewBroadcaster(queueLength)}\n}\n\nfunc (eventBroadcaster *eventBroadcasterImpl) Stop() {\n  eventBroadcaster.Shutdown()\n}\n\n// generate event\nfunc (eventBroadcaster *eventBroadcasterImpl) Event(etype, reason, message string) {\n  events := &Events{Type: etype, Reason: reason, Message: message}\n  // send event to broadcast\n  eventBroadcaster.Action(events)\n}\n\n//  StartLogging() \nfunc (eventBroadcaster *eventBroadcasterImpl) StartLogging() Interface {\n  // register a watcher\n  watcher := eventBroadcaster.Watch()\n  go func() {\n    for watchEvent := range watcher.ResultChan() {\n      fmt.Printf(\"%v\\n\", watchEvent)\n    }\n  }()\n\n  go func() {\n    time.Sleep(time.Second * 4)\n    watcher.Stop()\n  }()\n\n  return watcher\n}\n\n// --------------------\n// Broadcaster \n//  events channel \nconst incomingQueuLength = 100\n\ntype Broadcaster struct {\n  lock             sync.Mutex\n  incoming         chan Events\n  watchers         map[int64]*broadcasterWatcher\n  watchersQueue    int64\n  watchQueueLength int64\n  distributing     sync.WaitGroup\n}\n\nfunc NewBroadcaster(queueLength int64) *Broadcaster {\n  m := &Broadcaster{\n    incoming:         make(chan Events, incomingQueuLength),\n    watchers:         map[int64]*broadcasterWatcher{},\n    watchQueueLength: queueLength,\n  }\n  m.distributing.Add(1)\n  //  goroutine  events\n  go m.loop()\n  return m\n}\n\n// Broadcaster  events\nfunc (m *Broadcaster) Action(event *Events) {\n  m.incoming <- *event\n}\n\n//  events  watcher\nfunc (m *Broadcaster) loop() {\n  //  incoming channel  events\n  for event := range m.incoming {\n    //  events  watcher\n    for _, w := range m.watchers {\n      select {\n      case w.result <- event:\n      case <-w.stopped:\n      default:\n      }\n    }\n  }\n  m.closeAll()\n  m.distributing.Done()\n}\n\nfunc (m *Broadcaster) Shutdown() {\n  close(m.incoming)\n  m.distributing.Wait()\n}\n\nfunc (m *Broadcaster) closeAll() {\n  // TODO\n  m.lock.Lock()\n  defer m.lock.Unlock()\n  for _, w := range m.watchers {\n    close(w.result)\n  }\n  m.watchers = map[int64]*broadcasterWatcher{}\n}\n\nfunc (m *Broadcaster) stopWatching(id int64) {\n  m.lock.Lock()\n  defer m.lock.Unlock()\n  w, ok := m.watchers[id]\n  if !ok {\n    return\n  }\n  delete(m.watchers, id)\n  close(w.result)\n}\n\n//  Watch( watcher\nfunc (m *Broadcaster) Watch() Interface {\n  watcher := &broadcasterWatcher{\n    result:  make(chan Events, incomingQueuLength),\n    stopped: make(chan struct{}),\n    id:      m.watchQueueLength,\n    m:       m,\n  }\n  m.watchers[m.watchersQueue] = watcher\n  m.watchQueueLength++\n  return watcher\n}\n\n// watcher \ntype Interface interface {\n  Stop()\n  ResultChan() <-chan Events\n}\n\ntype broadcasterWatcher struct {\n  result  chan Events\n  stopped chan struct{}\n  stop    sync.Once\n  id      int64\n  m       *Broadcaster\n}\n\n//  watcher  channel  events\nfunc (b *broadcasterWatcher) ResultChan() <-chan Events {\n  return b.result\n}\n\nfunc (b *broadcasterWatcher) Stop() {\n  b.stop.Do(func() {\n    close(b.stopped)\n    b.m.stopWatching(b.id)\n  })\n}\n\n// --------------------\n\nfunc main() {\n  eventBroadcast := NewEventBroadcaster()\n\n  var wg sync.WaitGroup\n  wg.Add(1)\n  // producer event\n  go func() {\n    defer wg.Done()\n    time.Sleep(time.Second)\n    eventBroadcast.Event(\"add\", \"test\", \"1\")\n    time.Sleep(time.Second * 2)\n    eventBroadcast.Event(\"add\", \"test\", \"2\")\n    time.Sleep(time.Second * 3)\n    eventBroadcast.Event(\"add\", \"test\", \"3\")\n    //eventBroadcast.Stop()\n  }()\n\n  eventBroadcast.StartLogging()\n  wg.Wait()\n}\n```\n\n EventRecorder  events  EventBroadcaster  events  StartLogging()Broadcaster  k8s  EventCorrelator \n\n\nhttps://github.com/gosoon/k8s-learning-notes/tree/master/k8s-package/events\n\n##### 7\n\n k8s  events  demo kubelet  events  EventBroadcasterEventRecorderBroadcaster\n\n- 1kubelet  EventBroadcaster  Broadcaster \n- 2kubelet  EventBroadcaster  NewRecorder()  EventRecorder EventRecorder  events  Action()  events  Broadcaster  channel \n- 3Broadcaster  events Broadcaster  goroutine EventRecorder  events\n- 4EventBroadcaster  events StartEventWatcher()StartRecordingToSink()StartLogging()StartEventWatcher()  watcher  Broadcaster StartEventWatcher() \n- 5 Broadcaster  map  watcher events  watcher watcher  ResultChan()  channel  events\n- 6kubelet  StartRecordingToSink()  StartLogging()  events StartRecordingToSink()  events  apiserverapiserver  events  etcd  kubectl StartLogging()  events  kubelet \n","source":"_posts/k8s_events.md","raw":"---\ntitle: kubernets \ndate: 2019-02-26 20:49:30\ntags: [\"events\",\"kubelet\"]\ntype: \"k8s-events\"\n\n---\n\n node  pod  kubectl  events events  k8s  apiserver k8s  kubectl describe  events k8s  events  \n\n `k8s.io/kubernetes/cmd`  events\n```\n$ grep -R -n -i \"EventRecorder\" .\n```\n\ncontroller-managekube-proxykube-schedulerkubelet  EventRecorder kubelet  Events \n\n\n\n##### 1Events \n\nevents  `k8s.io/api/core/v1/types.go` ,\n\n```\ntype Event struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata\" protobuf:\"bytes,1,opt,name=metadata\"`\n    InvolvedObject ObjectReference `json:\"involvedObject\" protobuf:\"bytes,2,opt,name=involvedObject\"`\n    Reason string `json:\"reason,omitempty\" protobuf:\"bytes,3,opt,name=reason\"`\n    Message string `json:\"message,omitempty\" protobuf:\"bytes,4,opt,name=message\"`\n    Source EventSource `json:\"source,omitempty\" protobuf:\"bytes,5,opt,name=source\"`\n    FirstTimestamp metav1.Time `json:\"firstTimestamp,omitempty\" protobuf:\"bytes,6,opt,name=firstTimestamp\"`\n    LastTimestamp metav1.Time `json:\"lastTimestamp,omitempty\" protobuf:\"bytes,7,opt,name=lastTimestamp\"`\n    Count int32 `json:\"count,omitempty\" protobuf:\"varint,8,opt,name=count\"`\n    Type string `json:\"type,omitempty\" protobuf:\"bytes,9,opt,name=type\"`\n    EventTime metav1.MicroTime `json:\"eventTime,omitempty\" protobuf:\"bytes,10,opt,name=eventTime\"`\n    Series *EventSeries `json:\"series,omitempty\" protobuf:\"bytes,11,opt,name=series\"`\n    Action string `json:\"action,omitempty\" protobuf:\"bytes,12,opt,name=action\"`\n    Related *ObjectReference `json:\"related,omitempty\" protobuf:\"bytes,13,opt,name=related\"`\n    ReportingController string `json:\"reportingComponent\" protobuf:\"bytes,14,opt,name=reportingComponent\"`\n    ReportingInstance string `json:\"reportingInstance\" protobuf:\"bytes,15,opt,name=reportingInstance\"`\n    ReportingInstance string `json:\"reportingInstance\" protobuf:\"bytes,15,opt,name=reportingInstance\"`\n}\n```\n\n InvolvedObject source  kubectl  TypeReasonAgeFromMessage \n\nk8s  events \"Normal\"  \"Warning\"\n\n![events ](https://upload-images.jianshu.io/upload_images/1262158-c42d7442b2bc38d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n##### 2EventBroadcaster \n\nevents  EventBroadcaster kubelet  EventBroadcaster `k8s.io/kubernetes/cmd/kubelet/app/server.go`\n\n\n```\nfunc RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error {\n  ...\n  // event \n  makeEventRecorder(kubeDeps, nodeName)\n  ...\n}\n\n\nfunc makeEventRecorder(kubeDeps *kubelet.Dependencies, nodeName types.NodeName) {\n  if kubeDeps.Recorder != nil {\n    return\n  }\n  //  EventBroadcaster \n  eventBroadcaster := record.NewBroadcaster()\n  //  EventRecorder\n  kubeDeps.Recorder = eventBroadcaster.NewRecorder(legacyscheme.Scheme, v1.EventSource{Component: componentKubelet, Host: string(nodeName)})\n  //  events \n  eventBroadcaster.StartLogging(glog.V(3).Infof)\n  if kubeDeps.EventClient != nil {\n    glog.V(4).Infof(\"Sending events to api server.\")\n    //  events  apiserver\n  eventBroadcaster.StartRecordingToSink(&v1core.EventSinkImpl{Interface: kubeDeps.EventClient.Events(\"\")})\n  } else {\n    glog.Warning(\"No api server defined - no events will be sent to API server.\")\n  }\n}\n```\n\nKubelet  EventBroadcaster events (EventBroadcaster  kubelet  events  `k8s.io/client-go/tools/record/event.go` \n\n```\ntype eventBroadcasterImpl struct {\n  *watch.Broadcaster\n  sleepDuration time.Duration\n}\n\n// EventBroadcaster knows how to receive events and send them to any EventSink, watcher, or log.\ntype EventBroadcaster interface {\n  StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface\n\n  StartRecordingToSink(sink EventSink) watch.Interface\n\n  StartLogging(logf func(format string, args ...interface{})) watch.Interface\n\n  NewRecorder(scheme *runtime.Scheme, source v1.EventSource) EventRecorder\n}\n```\n\nEventBroadcaster \n- StartEventWatcher()  EventBroadcaster  events events  StartEventWatcher()  events  handle \n- StartRecordingToSink()   StartEventWatcher()  events events  apiserver \n- StartLogging()  StartEventWatcher()  events events \n- NewRecorder()  EventSource  EventRecorderEventSource \n\n\neventBroadcasterImpl  eventBroadcaster  EventBroadcaster  BroadcasterBroadcaster  goroutine  events  watcher\n\n```\nfunc NewBroadcaster() EventBroadcaster {\n  return &eventBroadcasterImpl{watch.NewBroadcaster(maxQueuedEvents, watch.DropIfChannelFull), defaultSleepDuration}\n}\n```\n\nkubelet  EventBroadcaster  StartRecordingToSink()  StartLogging() StartRecordingToSink()  events  apiserverStartLogging()  events  kubelet \n\n##### 3Events \n\n EventBroadcaster  kubelet  EventBroadcaster  EventRecorder Broadcaster  EventRecorderEventBroadcasterEventRecorderBroadcaster EventRecorder  events\n\n```\ntype recorderImpl struct {\n  scheme *runtime.Scheme\n  source v1.EventSource\n  *watch.Broadcaster\n  clock clock.Clock\n}\n\ntype EventRecorder interface {\n  Event(object runtime.Object, eventtype, reason, message string)\n\n  Eventf(object runtime.Object, eventtype, reason, messageFmt string, args ...interface{})\n\n  PastEventf(object runtime.Object, timestamp metav1.Time, eventtype, reason, messageFmt string, args ...interface{})\n\n  AnnotatedEventf(object runtime.Object, annotations map[string]string, eventtype, reason, messageFmt string, args ...interface{})\n}\n```\n\nEventRecorder  eventsEvent()  Eventf()  fmt.Println()  fmt.Printf()kubelet  EventRecorder  eventsrecorderImpl  EventRecorder EventRecorder  generateEvent generateEvent  events \n\n events \n\n```\nfunc (recorder *recorderImpl) generateEvent(object runtime.Object, annotations map[string]string, timestamp metav1.Time, eventtype, reason, message string) {\n  ref, err := ref.GetReference(recorder.scheme, object)\n  if err != nil {\n    glog.Errorf(\"Could not construct reference to: '%#v' due to: '%v'. Will not report event: '%v' '%v' '%v'\", object, err, eventtype, reason, message)\n    return\n  }\n\n  if !validateEventType(eventtype) {\n    glog.Errorf(\"Unsupported event type: '%v'\", eventtype)\n    return\n  }\n\n  event := recorder.makeEvent(ref, annotations, eventtype, reason, message)\n  event.Source = recorder.source\n\n  go func() {\n    // NOTE: events should be a non-blocking operation\n    defer utilruntime.HandleCrash()\n    // \n    recorder.Action(watch.Added, event)\n  }()\n}\n\nfunc (recorder *recorderImpl) makeEvent(ref *v1.ObjectReference, annotations map[string]string, eventtype, reason, message string) *v1.Event {\n  t := metav1.Time{Time: recorder.clock.Now()}\n  namespace := ref.Namespace\n  if namespace == \"\" {\n    namespace = metav1.NamespaceDefault\n  }\n  return &v1.Event{\n    ObjectMeta: metav1.ObjectMeta{\n      Name:        fmt.Sprintf(\"%v.%x\", ref.Name, t.UnixNano()),\n      Namespace:   namespace,\n      Annotations: annotations,\n    },\n    InvolvedObject: *ref,\n    Reason:         reason,\n    Message:        message,\n    FirstTimestamp: t,\n    LastTimestamp:  t,\n    Count:          1,\n    Type:           eventtype,\n  }\n}\n```\n events  recorder.Action()  events  Broadcaster , Action()  Broadcaster \n\n Action() \n\n```\nfunc (m *Broadcaster) Action(action EventType, obj runtime.Object) {\n  m.incoming <- Event{action, obj}\n}\n```\n\n##### 4Events \n\nEventBroadcaster  BroadcasterBroadcaster  events Broadcaster  `k8s.io/apimachinery/pkg/watch/mux.go ` Broadcaster  goroutine EventRecorder  eventsBroadcaster  map  watcher  events  watcher watcher  channelwatcher  ResultChan()  channel \n\n\n Broadcaster  events \n```\nfunc (m *Broadcaster) loop() {\n  for event := range m.incoming {\n    if event.Type == internalRunFunctionMarker {\n      event.Object.(functionFakeRuntimeObject)()\n      continue\n    }\n    m.distribute(event)\n  }\n  m.closeAll()\n  m.distributing.Done()\n}\n\n// distribute sends event to all watchers. Blocking.\nfunc (m *Broadcaster) distribute(event Event) {\n  m.lock.Lock()\n  defer m.lock.Unlock()\n  if m.fullChannelBehavior == DropIfChannelFull {\n    for _, w := range m.watchers {\n      select {\n      case w.result <- event:\n      case <-w.stopped:\n      default: // Don't block if the event can't be queued.\n      }\n    }\n  } else {\n    for _, w := range m.watchers {\n      select {\n      case w.result <- event:\n      case <-w.stopped:\n      }\n    }\n  }\n}\n```\n\n\n##### 5Events \n\n watcher  events  client  watcher events  EventBroadcaster  EventBroadcaster  events \n\n```\nfunc (eventBroadcaster *eventBroadcasterImpl) StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface {\n  watcher := eventBroadcaster.Watch()\n  go func() {\n    defer utilruntime.HandleCrash()\n    for watchEvent := range watcher.ResultChan() {\n      event, ok := watchEvent.Object.(*v1.Event)\n      if !ok {\n        // This is all local, so there's no reason this should\n        // ever happen.\n        continue\n      }\n      eventHandler(event)\n    }\n  }()\n  return watcher\n}\n```\n\nStartEventWatcher()  watcher watcher  Broadcaster  watcher watcher  Broadcaster  channel  events eventHandler StartLogging()  StartRecordingToSink()  StartEventWatcher() \n\n\n\n```\nfunc (eventBroadcaster *eventBroadcasterImpl) StartLogging(logf func(format string, args ...interface{})) watch.Interface {\n  return eventBroadcaster.StartEventWatcher(\n    func(e *v1.Event) {\n      logf(\"Event(%#v): type: '%v' reason: '%v' %v\", e.InvolvedObject, e.Type, e.Reason, e.Message)\n    })\n}\n```\n\nStartLogging()  eventHandler  events \n\n```\nfunc (eventBroadcaster *eventBroadcasterImpl) StartRecordingToSink(sink EventSink) watch.Interface {\n  // The default math/rand package functions aren't thread safe, so create a\n  // new Rand object for each StartRecording call.\n  randGen := rand.New(rand.NewSource(time.Now().UnixNano()))\n  eventCorrelator := NewEventCorrelator(clock.RealClock{})\n  return eventBroadcaster.StartEventWatcher(\n    func(event *v1.Event) {\n      recordToSink(sink, event, eventCorrelator, randGen, eventBroadcaster.sleepDuration)\n    })\n}\n\nfunc recordToSink(sink EventSink, event *v1.Event, eventCorrelator *EventCorrelator, randGen *rand.Rand, sleepDuration time.Duration) {\n  eventCopy := *event\n  event = &eventCopy\n  result, err := eventCorrelator.EventCorrelate(event)\n  if err != nil {\n    utilruntime.HandleError(err)\n  }\n  if result.Skip {\n    return\n  }\n  tries := 0\n  for {\n    if recordEvent(sink, result.Event, result.Patch, result.Event.Count > 1, eventCorrelator) {\n      break\n    }\n    tries++\n    if tries >= maxTriesPerEvent {\n      glog.Errorf(\"Unable to write event '%#v' (retry limit exceeded!)\", event)\n      break\n    }\n    //  apiserver \n    if tries == 1 {\n      time.Sleep(time.Duration(float64(sleepDuration) * randGen.Float64()))\n    } else {\n      time.Sleep(sleepDuration)\n    }\n  }\n}\n```\n\nStartRecordingToSink()  randGen apiserver EventCorrelatorEventCorrelator  recordToSink() recordToSink()  events  apiserver StartEventWatcher() \n\n\n##### 6Events \n\n events  demo events \n\n- 1\n- 2\n- 3\n- 4\n- 5\n\n```\npackage main\n\nimport (\n  \"fmt\"\n  \"sync\"\n  \"time\"\n)\n\n// watcher queue\nconst queueLength = int64(1)\n\n// Events xxx\ntype Events struct {\n  Reason    string\n  Message   string\n  Source    string\n  Type      string\n  Count     int64\n  Timestamp time.Time\n}\n\n// EventBroadcaster xxx\ntype EventBroadcaster interface {\n  Event(etype, reason, message string)\n  StartLogging() Interface\n  Stop()\n}\n\n// eventBroadcaster xxx\ntype eventBroadcasterImpl struct {\n  *Broadcaster\n}\n\nfunc NewEventBroadcaster() EventBroadcaster {\n  return &eventBroadcasterImpl{NewBroadcaster(queueLength)}\n}\n\nfunc (eventBroadcaster *eventBroadcasterImpl) Stop() {\n  eventBroadcaster.Shutdown()\n}\n\n// generate event\nfunc (eventBroadcaster *eventBroadcasterImpl) Event(etype, reason, message string) {\n  events := &Events{Type: etype, Reason: reason, Message: message}\n  // send event to broadcast\n  eventBroadcaster.Action(events)\n}\n\n//  StartLogging() \nfunc (eventBroadcaster *eventBroadcasterImpl) StartLogging() Interface {\n  // register a watcher\n  watcher := eventBroadcaster.Watch()\n  go func() {\n    for watchEvent := range watcher.ResultChan() {\n      fmt.Printf(\"%v\\n\", watchEvent)\n    }\n  }()\n\n  go func() {\n    time.Sleep(time.Second * 4)\n    watcher.Stop()\n  }()\n\n  return watcher\n}\n\n// --------------------\n// Broadcaster \n//  events channel \nconst incomingQueuLength = 100\n\ntype Broadcaster struct {\n  lock             sync.Mutex\n  incoming         chan Events\n  watchers         map[int64]*broadcasterWatcher\n  watchersQueue    int64\n  watchQueueLength int64\n  distributing     sync.WaitGroup\n}\n\nfunc NewBroadcaster(queueLength int64) *Broadcaster {\n  m := &Broadcaster{\n    incoming:         make(chan Events, incomingQueuLength),\n    watchers:         map[int64]*broadcasterWatcher{},\n    watchQueueLength: queueLength,\n  }\n  m.distributing.Add(1)\n  //  goroutine  events\n  go m.loop()\n  return m\n}\n\n// Broadcaster  events\nfunc (m *Broadcaster) Action(event *Events) {\n  m.incoming <- *event\n}\n\n//  events  watcher\nfunc (m *Broadcaster) loop() {\n  //  incoming channel  events\n  for event := range m.incoming {\n    //  events  watcher\n    for _, w := range m.watchers {\n      select {\n      case w.result <- event:\n      case <-w.stopped:\n      default:\n      }\n    }\n  }\n  m.closeAll()\n  m.distributing.Done()\n}\n\nfunc (m *Broadcaster) Shutdown() {\n  close(m.incoming)\n  m.distributing.Wait()\n}\n\nfunc (m *Broadcaster) closeAll() {\n  // TODO\n  m.lock.Lock()\n  defer m.lock.Unlock()\n  for _, w := range m.watchers {\n    close(w.result)\n  }\n  m.watchers = map[int64]*broadcasterWatcher{}\n}\n\nfunc (m *Broadcaster) stopWatching(id int64) {\n  m.lock.Lock()\n  defer m.lock.Unlock()\n  w, ok := m.watchers[id]\n  if !ok {\n    return\n  }\n  delete(m.watchers, id)\n  close(w.result)\n}\n\n//  Watch( watcher\nfunc (m *Broadcaster) Watch() Interface {\n  watcher := &broadcasterWatcher{\n    result:  make(chan Events, incomingQueuLength),\n    stopped: make(chan struct{}),\n    id:      m.watchQueueLength,\n    m:       m,\n  }\n  m.watchers[m.watchersQueue] = watcher\n  m.watchQueueLength++\n  return watcher\n}\n\n// watcher \ntype Interface interface {\n  Stop()\n  ResultChan() <-chan Events\n}\n\ntype broadcasterWatcher struct {\n  result  chan Events\n  stopped chan struct{}\n  stop    sync.Once\n  id      int64\n  m       *Broadcaster\n}\n\n//  watcher  channel  events\nfunc (b *broadcasterWatcher) ResultChan() <-chan Events {\n  return b.result\n}\n\nfunc (b *broadcasterWatcher) Stop() {\n  b.stop.Do(func() {\n    close(b.stopped)\n    b.m.stopWatching(b.id)\n  })\n}\n\n// --------------------\n\nfunc main() {\n  eventBroadcast := NewEventBroadcaster()\n\n  var wg sync.WaitGroup\n  wg.Add(1)\n  // producer event\n  go func() {\n    defer wg.Done()\n    time.Sleep(time.Second)\n    eventBroadcast.Event(\"add\", \"test\", \"1\")\n    time.Sleep(time.Second * 2)\n    eventBroadcast.Event(\"add\", \"test\", \"2\")\n    time.Sleep(time.Second * 3)\n    eventBroadcast.Event(\"add\", \"test\", \"3\")\n    //eventBroadcast.Stop()\n  }()\n\n  eventBroadcast.StartLogging()\n  wg.Wait()\n}\n```\n\n EventRecorder  events  EventBroadcaster  events  StartLogging()Broadcaster  k8s  EventCorrelator \n\n\nhttps://github.com/gosoon/k8s-learning-notes/tree/master/k8s-package/events\n\n##### 7\n\n k8s  events  demo kubelet  events  EventBroadcasterEventRecorderBroadcaster\n\n- 1kubelet  EventBroadcaster  Broadcaster \n- 2kubelet  EventBroadcaster  NewRecorder()  EventRecorder EventRecorder  events  Action()  events  Broadcaster  channel \n- 3Broadcaster  events Broadcaster  goroutine EventRecorder  events\n- 4EventBroadcaster  events StartEventWatcher()StartRecordingToSink()StartLogging()StartEventWatcher()  watcher  Broadcaster StartEventWatcher() \n- 5 Broadcaster  map  watcher events  watcher watcher  ResultChan()  channel  events\n- 6kubelet  StartRecordingToSink()  StartLogging()  events StartRecordingToSink()  events  apiserverapiserver  events  etcd  kubectl StartLogging()  events  kubelet \n","slug":"k8s_events","published":1,"updated":"2019-02-26T14:37:28.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyt04000ztadvl5mm7rse","content":"<p> node  pod  kubectl  events events  k8s  apiserver k8s  kubectl describe  events k8s  events  </p>\n<p> <code>k8s.io/kubernetes/cmd</code>  events<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ grep -R -n -i &quot;EventRecorder&quot; .</span><br></pre></td></tr></table></figure></p>\n<p>controller-managekube-proxykube-schedulerkubelet  EventRecorder kubelet  Events </p>\n<h5 id=\"1Events-\"><a href=\"#1Events-\" class=\"headerlink\" title=\"1Events \"></a>1Events </h5><p>events  <code>k8s.io/api/core/v1/types.go</code> ,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Event struct &#123;</span><br><span class=\"line\">    metav1.TypeMeta `json:&quot;,inline&quot;`</span><br><span class=\"line\">    metav1.ObjectMeta `json:&quot;metadata&quot; protobuf:&quot;bytes,1,opt,name=metadata&quot;`</span><br><span class=\"line\">    InvolvedObject ObjectReference `json:&quot;involvedObject&quot; protobuf:&quot;bytes,2,opt,name=involvedObject&quot;`</span><br><span class=\"line\">    Reason string `json:&quot;reason,omitempty&quot; protobuf:&quot;bytes,3,opt,name=reason&quot;`</span><br><span class=\"line\">    Message string `json:&quot;message,omitempty&quot; protobuf:&quot;bytes,4,opt,name=message&quot;`</span><br><span class=\"line\">    Source EventSource `json:&quot;source,omitempty&quot; protobuf:&quot;bytes,5,opt,name=source&quot;`</span><br><span class=\"line\">    FirstTimestamp metav1.Time `json:&quot;firstTimestamp,omitempty&quot; protobuf:&quot;bytes,6,opt,name=firstTimestamp&quot;`</span><br><span class=\"line\">    LastTimestamp metav1.Time `json:&quot;lastTimestamp,omitempty&quot; protobuf:&quot;bytes,7,opt,name=lastTimestamp&quot;`</span><br><span class=\"line\">    Count int32 `json:&quot;count,omitempty&quot; protobuf:&quot;varint,8,opt,name=count&quot;`</span><br><span class=\"line\">    Type string `json:&quot;type,omitempty&quot; protobuf:&quot;bytes,9,opt,name=type&quot;`</span><br><span class=\"line\">    EventTime metav1.MicroTime `json:&quot;eventTime,omitempty&quot; protobuf:&quot;bytes,10,opt,name=eventTime&quot;`</span><br><span class=\"line\">    Series *EventSeries `json:&quot;series,omitempty&quot; protobuf:&quot;bytes,11,opt,name=series&quot;`</span><br><span class=\"line\">    Action string `json:&quot;action,omitempty&quot; protobuf:&quot;bytes,12,opt,name=action&quot;`</span><br><span class=\"line\">    Related *ObjectReference `json:&quot;related,omitempty&quot; protobuf:&quot;bytes,13,opt,name=related&quot;`</span><br><span class=\"line\">    ReportingController string `json:&quot;reportingComponent&quot; protobuf:&quot;bytes,14,opt,name=reportingComponent&quot;`</span><br><span class=\"line\">    ReportingInstance string `json:&quot;reportingInstance&quot; protobuf:&quot;bytes,15,opt,name=reportingInstance&quot;`</span><br><span class=\"line\">    ReportingInstance string `json:&quot;reportingInstance&quot; protobuf:&quot;bytes,15,opt,name=reportingInstance&quot;`</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> InvolvedObject source  kubectl  TypeReasonAgeFromMessage </p>\n<p>k8s  events Normal  Warning</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-c42d7442b2bc38d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"events \"></p>\n<h5 id=\"2EventBroadcaster-\"><a href=\"#2EventBroadcaster-\" class=\"headerlink\" title=\"2EventBroadcaster \"></a>2EventBroadcaster </h5><p>events  EventBroadcaster kubelet  EventBroadcaster <code>k8s.io/kubernetes/cmd/kubelet/app/server.go</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // event </span><br><span class=\"line\">  makeEventRecorder(kubeDeps, nodeName)</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">func makeEventRecorder(kubeDeps *kubelet.Dependencies, nodeName types.NodeName) &#123;</span><br><span class=\"line\">  if kubeDeps.Recorder != nil &#123;</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  //  EventBroadcaster </span><br><span class=\"line\">  eventBroadcaster := record.NewBroadcaster()</span><br><span class=\"line\">  //  EventRecorder</span><br><span class=\"line\">  kubeDeps.Recorder = eventBroadcaster.NewRecorder(legacyscheme.Scheme, v1.EventSource&#123;Component: componentKubelet, Host: string(nodeName)&#125;)</span><br><span class=\"line\">  //  events </span><br><span class=\"line\">  eventBroadcaster.StartLogging(glog.V(3).Infof)</span><br><span class=\"line\">  if kubeDeps.EventClient != nil &#123;</span><br><span class=\"line\">    glog.V(4).Infof(&quot;Sending events to api server.&quot;)</span><br><span class=\"line\">    //  events  apiserver</span><br><span class=\"line\">  eventBroadcaster.StartRecordingToSink(&amp;v1core.EventSinkImpl&#123;Interface: kubeDeps.EventClient.Events(&quot;&quot;)&#125;)</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    glog.Warning(&quot;No api server defined - no events will be sent to API server.&quot;)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Kubelet  EventBroadcaster events (EventBroadcaster  kubelet  events  <code>k8s.io/client-go/tools/record/event.go</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type eventBroadcasterImpl struct &#123;</span><br><span class=\"line\">  *watch.Broadcaster</span><br><span class=\"line\">  sleepDuration time.Duration</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// EventBroadcaster knows how to receive events and send them to any EventSink, watcher, or log.</span><br><span class=\"line\">type EventBroadcaster interface &#123;</span><br><span class=\"line\">  StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface</span><br><span class=\"line\"></span><br><span class=\"line\">  StartRecordingToSink(sink EventSink) watch.Interface</span><br><span class=\"line\"></span><br><span class=\"line\">  StartLogging(logf func(format string, args ...interface&#123;&#125;)) watch.Interface</span><br><span class=\"line\"></span><br><span class=\"line\">  NewRecorder(scheme *runtime.Scheme, source v1.EventSource) EventRecorder</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>EventBroadcaster </p>\n<ul>\n<li>StartEventWatcher()  EventBroadcaster  events events  StartEventWatcher()  events  handle </li>\n<li>StartRecordingToSink()   StartEventWatcher()  events events  apiserver </li>\n<li>StartLogging()  StartEventWatcher()  events events </li>\n<li>NewRecorder()  EventSource  EventRecorderEventSource </li>\n</ul>\n<p>eventBroadcasterImpl  eventBroadcaster  EventBroadcaster  BroadcasterBroadcaster  goroutine  events  watcher</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewBroadcaster() EventBroadcaster &#123;</span><br><span class=\"line\">  return &amp;eventBroadcasterImpl&#123;watch.NewBroadcaster(maxQueuedEvents, watch.DropIfChannelFull), defaultSleepDuration&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>kubelet  EventBroadcaster  StartRecordingToSink()  StartLogging() StartRecordingToSink()  events  apiserverStartLogging()  events  kubelet </p>\n<h5 id=\"3Events-\"><a href=\"#3Events-\" class=\"headerlink\" title=\"3Events \"></a>3Events </h5><p> EventBroadcaster  kubelet  EventBroadcaster  EventRecorder Broadcaster  EventRecorderEventBroadcasterEventRecorderBroadcaster EventRecorder  events</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type recorderImpl struct &#123;</span><br><span class=\"line\">  scheme *runtime.Scheme</span><br><span class=\"line\">  source v1.EventSource</span><br><span class=\"line\">  *watch.Broadcaster</span><br><span class=\"line\">  clock clock.Clock</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type EventRecorder interface &#123;</span><br><span class=\"line\">  Event(object runtime.Object, eventtype, reason, message string)</span><br><span class=\"line\"></span><br><span class=\"line\">  Eventf(object runtime.Object, eventtype, reason, messageFmt string, args ...interface&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">  PastEventf(object runtime.Object, timestamp metav1.Time, eventtype, reason, messageFmt string, args ...interface&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">  AnnotatedEventf(object runtime.Object, annotations map[string]string, eventtype, reason, messageFmt string, args ...interface&#123;&#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>EventRecorder  eventsEvent()  Eventf()  fmt.Println()  fmt.Printf()kubelet  EventRecorder  eventsrecorderImpl  EventRecorder EventRecorder  generateEvent generateEvent  events </p>\n<p> events </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (recorder *recorderImpl) generateEvent(object runtime.Object, annotations map[string]string, timestamp metav1.Time, eventtype, reason, message string) &#123;</span><br><span class=\"line\">  ref, err := ref.GetReference(recorder.scheme, object)</span><br><span class=\"line\">  if err != nil &#123;</span><br><span class=\"line\">    glog.Errorf(&quot;Could not construct reference to: &apos;%#v&apos; due to: &apos;%v&apos;. Will not report event: &apos;%v&apos; &apos;%v&apos; &apos;%v&apos;&quot;, object, err, eventtype, reason, message)</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  if !validateEventType(eventtype) &#123;</span><br><span class=\"line\">    glog.Errorf(&quot;Unsupported event type: &apos;%v&apos;&quot;, eventtype)</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  event := recorder.makeEvent(ref, annotations, eventtype, reason, message)</span><br><span class=\"line\">  event.Source = recorder.source</span><br><span class=\"line\"></span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    // NOTE: events should be a non-blocking operation</span><br><span class=\"line\">    defer utilruntime.HandleCrash()</span><br><span class=\"line\">    // </span><br><span class=\"line\">    recorder.Action(watch.Added, event)</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (recorder *recorderImpl) makeEvent(ref *v1.ObjectReference, annotations map[string]string, eventtype, reason, message string) *v1.Event &#123;</span><br><span class=\"line\">  t := metav1.Time&#123;Time: recorder.clock.Now()&#125;</span><br><span class=\"line\">  namespace := ref.Namespace</span><br><span class=\"line\">  if namespace == &quot;&quot; &#123;</span><br><span class=\"line\">    namespace = metav1.NamespaceDefault</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  return &amp;v1.Event&#123;</span><br><span class=\"line\">    ObjectMeta: metav1.ObjectMeta&#123;</span><br><span class=\"line\">      Name:        fmt.Sprintf(&quot;%v.%x&quot;, ref.Name, t.UnixNano()),</span><br><span class=\"line\">      Namespace:   namespace,</span><br><span class=\"line\">      Annotations: annotations,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    InvolvedObject: *ref,</span><br><span class=\"line\">    Reason:         reason,</span><br><span class=\"line\">    Message:        message,</span><br><span class=\"line\">    FirstTimestamp: t,</span><br><span class=\"line\">    LastTimestamp:  t,</span><br><span class=\"line\">    Count:          1,</span><br><span class=\"line\">    Type:           eventtype,</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> events  recorder.Action()  events  Broadcaster , Action()  Broadcaster </p>\n<p> Action() </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *Broadcaster) Action(action EventType, obj runtime.Object) &#123;</span><br><span class=\"line\">  m.incoming &lt;- Event&#123;action, obj&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"4Events-\"><a href=\"#4Events-\" class=\"headerlink\" title=\"4Events \"></a>4Events </h5><p>EventBroadcaster  BroadcasterBroadcaster  events Broadcaster  <code>k8s.io/apimachinery/pkg/watch/mux.go</code> Broadcaster  goroutine EventRecorder  eventsBroadcaster  map  watcher  events  watcher watcher  channelwatcher  ResultChan()  channel </p>\n<p> Broadcaster  events <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *Broadcaster) loop() &#123;</span><br><span class=\"line\">  for event := range m.incoming &#123;</span><br><span class=\"line\">    if event.Type == internalRunFunctionMarker &#123;</span><br><span class=\"line\">      event.Object.(functionFakeRuntimeObject)()</span><br><span class=\"line\">      continue</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    m.distribute(event)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.closeAll()</span><br><span class=\"line\">  m.distributing.Done()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// distribute sends event to all watchers. Blocking.</span><br><span class=\"line\">func (m *Broadcaster) distribute(event Event) &#123;</span><br><span class=\"line\">  m.lock.Lock()</span><br><span class=\"line\">  defer m.lock.Unlock()</span><br><span class=\"line\">  if m.fullChannelBehavior == DropIfChannelFull &#123;</span><br><span class=\"line\">    for _, w := range m.watchers &#123;</span><br><span class=\"line\">      select &#123;</span><br><span class=\"line\">      case w.result &lt;- event:</span><br><span class=\"line\">      case &lt;-w.stopped:</span><br><span class=\"line\">      default: // Don&apos;t block if the event can&apos;t be queued.</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    for _, w := range m.watchers &#123;</span><br><span class=\"line\">      select &#123;</span><br><span class=\"line\">      case w.result &lt;- event:</span><br><span class=\"line\">      case &lt;-w.stopped:</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"5Events-\"><a href=\"#5Events-\" class=\"headerlink\" title=\"5Events \"></a>5Events </h5><p> watcher  events  client  watcher events  EventBroadcaster  EventBroadcaster  events </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface &#123;</span><br><span class=\"line\">  watcher := eventBroadcaster.Watch()</span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    defer utilruntime.HandleCrash()</span><br><span class=\"line\">    for watchEvent := range watcher.ResultChan() &#123;</span><br><span class=\"line\">      event, ok := watchEvent.Object.(*v1.Event)</span><br><span class=\"line\">      if !ok &#123;</span><br><span class=\"line\">        // This is all local, so there&apos;s no reason this should</span><br><span class=\"line\">        // ever happen.</span><br><span class=\"line\">        continue</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      eventHandler(event)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\">  return watcher</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>StartEventWatcher()  watcher watcher  Broadcaster  watcher watcher  Broadcaster  channel  events eventHandler StartLogging()  StartRecordingToSink()  StartEventWatcher() </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartLogging(logf func(format string, args ...interface&#123;&#125;)) watch.Interface &#123;</span><br><span class=\"line\">  return eventBroadcaster.StartEventWatcher(</span><br><span class=\"line\">    func(e *v1.Event) &#123;</span><br><span class=\"line\">      logf(&quot;Event(%#v): type: &apos;%v&apos; reason: &apos;%v&apos; %v&quot;, e.InvolvedObject, e.Type, e.Reason, e.Message)</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>StartLogging()  eventHandler  events </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartRecordingToSink(sink EventSink) watch.Interface &#123;</span><br><span class=\"line\">  // The default math/rand package functions aren&apos;t thread safe, so create a</span><br><span class=\"line\">  // new Rand object for each StartRecording call.</span><br><span class=\"line\">  randGen := rand.New(rand.NewSource(time.Now().UnixNano()))</span><br><span class=\"line\">  eventCorrelator := NewEventCorrelator(clock.RealClock&#123;&#125;)</span><br><span class=\"line\">  return eventBroadcaster.StartEventWatcher(</span><br><span class=\"line\">    func(event *v1.Event) &#123;</span><br><span class=\"line\">      recordToSink(sink, event, eventCorrelator, randGen, eventBroadcaster.sleepDuration)</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func recordToSink(sink EventSink, event *v1.Event, eventCorrelator *EventCorrelator, randGen *rand.Rand, sleepDuration time.Duration) &#123;</span><br><span class=\"line\">  eventCopy := *event</span><br><span class=\"line\">  event = &amp;eventCopy</span><br><span class=\"line\">  result, err := eventCorrelator.EventCorrelate(event)</span><br><span class=\"line\">  if err != nil &#123;</span><br><span class=\"line\">    utilruntime.HandleError(err)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  if result.Skip &#123;</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  tries := 0</span><br><span class=\"line\">  for &#123;</span><br><span class=\"line\">    if recordEvent(sink, result.Event, result.Patch, result.Event.Count &gt; 1, eventCorrelator) &#123;</span><br><span class=\"line\">      break</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    tries++</span><br><span class=\"line\">    if tries &gt;= maxTriesPerEvent &#123;</span><br><span class=\"line\">      glog.Errorf(&quot;Unable to write event &apos;%#v&apos; (retry limit exceeded!)&quot;, event)</span><br><span class=\"line\">      break</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //  apiserver </span><br><span class=\"line\">    if tries == 1 &#123;</span><br><span class=\"line\">      time.Sleep(time.Duration(float64(sleepDuration) * randGen.Float64()))</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      time.Sleep(sleepDuration)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>StartRecordingToSink()  randGen apiserver EventCorrelatorEventCorrelator  recordToSink() recordToSink()  events  apiserver StartEventWatcher() </p>\n<h5 id=\"6Events-\"><a href=\"#6Events-\" class=\"headerlink\" title=\"6Events \"></a>6Events </h5><p> events  demo events </p>\n<ul>\n<li>1</li>\n<li>2</li>\n<li>3</li>\n<li>4</li>\n<li>5</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">  &quot;fmt&quot;</span><br><span class=\"line\">  &quot;sync&quot;</span><br><span class=\"line\">  &quot;time&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">// watcher queue</span><br><span class=\"line\">const queueLength = int64(1)</span><br><span class=\"line\"></span><br><span class=\"line\">// Events xxx</span><br><span class=\"line\">type Events struct &#123;</span><br><span class=\"line\">  Reason    string</span><br><span class=\"line\">  Message   string</span><br><span class=\"line\">  Source    string</span><br><span class=\"line\">  Type      string</span><br><span class=\"line\">  Count     int64</span><br><span class=\"line\">  Timestamp time.Time</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// EventBroadcaster xxx</span><br><span class=\"line\">type EventBroadcaster interface &#123;</span><br><span class=\"line\">  Event(etype, reason, message string)</span><br><span class=\"line\">  StartLogging() Interface</span><br><span class=\"line\">  Stop()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// eventBroadcaster xxx</span><br><span class=\"line\">type eventBroadcasterImpl struct &#123;</span><br><span class=\"line\">  *Broadcaster</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func NewEventBroadcaster() EventBroadcaster &#123;</span><br><span class=\"line\">  return &amp;eventBroadcasterImpl&#123;NewBroadcaster(queueLength)&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) Stop() &#123;</span><br><span class=\"line\">  eventBroadcaster.Shutdown()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// generate event</span><br><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) Event(etype, reason, message string) &#123;</span><br><span class=\"line\">  events := &amp;Events&#123;Type: etype, Reason: reason, Message: message&#125;</span><br><span class=\"line\">  // send event to broadcast</span><br><span class=\"line\">  eventBroadcaster.Action(events)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  StartLogging() </span><br><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartLogging() Interface &#123;</span><br><span class=\"line\">  // register a watcher</span><br><span class=\"line\">  watcher := eventBroadcaster.Watch()</span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    for watchEvent := range watcher.ResultChan() &#123;</span><br><span class=\"line\">      fmt.Printf(&quot;%v\\n&quot;, watchEvent)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    time.Sleep(time.Second * 4)</span><br><span class=\"line\">    watcher.Stop()</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">  return watcher</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// --------------------</span><br><span class=\"line\">// Broadcaster </span><br><span class=\"line\">//  events channel </span><br><span class=\"line\">const incomingQueuLength = 100</span><br><span class=\"line\"></span><br><span class=\"line\">type Broadcaster struct &#123;</span><br><span class=\"line\">  lock             sync.Mutex</span><br><span class=\"line\">  incoming         chan Events</span><br><span class=\"line\">  watchers         map[int64]*broadcasterWatcher</span><br><span class=\"line\">  watchersQueue    int64</span><br><span class=\"line\">  watchQueueLength int64</span><br><span class=\"line\">  distributing     sync.WaitGroup</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func NewBroadcaster(queueLength int64) *Broadcaster &#123;</span><br><span class=\"line\">  m := &amp;Broadcaster&#123;</span><br><span class=\"line\">    incoming:         make(chan Events, incomingQueuLength),</span><br><span class=\"line\">    watchers:         map[int64]*broadcasterWatcher&#123;&#125;,</span><br><span class=\"line\">    watchQueueLength: queueLength,</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.distributing.Add(1)</span><br><span class=\"line\">  //  goroutine  events</span><br><span class=\"line\">  go m.loop()</span><br><span class=\"line\">  return m</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// Broadcaster  events</span><br><span class=\"line\">func (m *Broadcaster) Action(event *Events) &#123;</span><br><span class=\"line\">  m.incoming &lt;- *event</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  events  watcher</span><br><span class=\"line\">func (m *Broadcaster) loop() &#123;</span><br><span class=\"line\">  //  incoming channel  events</span><br><span class=\"line\">  for event := range m.incoming &#123;</span><br><span class=\"line\">    //  events  watcher</span><br><span class=\"line\">    for _, w := range m.watchers &#123;</span><br><span class=\"line\">      select &#123;</span><br><span class=\"line\">      case w.result &lt;- event:</span><br><span class=\"line\">      case &lt;-w.stopped:</span><br><span class=\"line\">      default:</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.closeAll()</span><br><span class=\"line\">  m.distributing.Done()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (m *Broadcaster) Shutdown() &#123;</span><br><span class=\"line\">  close(m.incoming)</span><br><span class=\"line\">  m.distributing.Wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (m *Broadcaster) closeAll() &#123;</span><br><span class=\"line\">  // TODO</span><br><span class=\"line\">  m.lock.Lock()</span><br><span class=\"line\">  defer m.lock.Unlock()</span><br><span class=\"line\">  for _, w := range m.watchers &#123;</span><br><span class=\"line\">    close(w.result)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.watchers = map[int64]*broadcasterWatcher&#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (m *Broadcaster) stopWatching(id int64) &#123;</span><br><span class=\"line\">  m.lock.Lock()</span><br><span class=\"line\">  defer m.lock.Unlock()</span><br><span class=\"line\">  w, ok := m.watchers[id]</span><br><span class=\"line\">  if !ok &#123;</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  delete(m.watchers, id)</span><br><span class=\"line\">  close(w.result)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  Watch( watcher</span><br><span class=\"line\">func (m *Broadcaster) Watch() Interface &#123;</span><br><span class=\"line\">  watcher := &amp;broadcasterWatcher&#123;</span><br><span class=\"line\">    result:  make(chan Events, incomingQueuLength),</span><br><span class=\"line\">    stopped: make(chan struct&#123;&#125;),</span><br><span class=\"line\">    id:      m.watchQueueLength,</span><br><span class=\"line\">    m:       m,</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.watchers[m.watchersQueue] = watcher</span><br><span class=\"line\">  m.watchQueueLength++</span><br><span class=\"line\">  return watcher</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// watcher </span><br><span class=\"line\">type Interface interface &#123;</span><br><span class=\"line\">  Stop()</span><br><span class=\"line\">  ResultChan() &lt;-chan Events</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type broadcasterWatcher struct &#123;</span><br><span class=\"line\">  result  chan Events</span><br><span class=\"line\">  stopped chan struct&#123;&#125;</span><br><span class=\"line\">  stop    sync.Once</span><br><span class=\"line\">  id      int64</span><br><span class=\"line\">  m       *Broadcaster</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  watcher  channel  events</span><br><span class=\"line\">func (b *broadcasterWatcher) ResultChan() &lt;-chan Events &#123;</span><br><span class=\"line\">  return b.result</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (b *broadcasterWatcher) Stop() &#123;</span><br><span class=\"line\">  b.stop.Do(func() &#123;</span><br><span class=\"line\">    close(b.stopped)</span><br><span class=\"line\">    b.m.stopWatching(b.id)</span><br><span class=\"line\">  &#125;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// --------------------</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">  eventBroadcast := NewEventBroadcaster()</span><br><span class=\"line\"></span><br><span class=\"line\">  var wg sync.WaitGroup</span><br><span class=\"line\">  wg.Add(1)</span><br><span class=\"line\">  // producer event</span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    defer wg.Done()</span><br><span class=\"line\">    time.Sleep(time.Second)</span><br><span class=\"line\">    eventBroadcast.Event(&quot;add&quot;, &quot;test&quot;, &quot;1&quot;)</span><br><span class=\"line\">    time.Sleep(time.Second * 2)</span><br><span class=\"line\">    eventBroadcast.Event(&quot;add&quot;, &quot;test&quot;, &quot;2&quot;)</span><br><span class=\"line\">    time.Sleep(time.Second * 3)</span><br><span class=\"line\">    eventBroadcast.Event(&quot;add&quot;, &quot;test&quot;, &quot;3&quot;)</span><br><span class=\"line\">    //eventBroadcast.Stop()</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">  eventBroadcast.StartLogging()</span><br><span class=\"line\">  wg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> EventRecorder  events  EventBroadcaster  events  StartLogging()Broadcaster  k8s  EventCorrelator </p>\n<p><a href=\"https://github.com/gosoon/k8s-learning-notes/tree/master/k8s-package/events\" target=\"_blank\" rel=\"noopener\">https://github.com/gosoon/k8s-learning-notes/tree/master/k8s-package/events</a></p>\n<h5 id=\"7\"><a href=\"#7\" class=\"headerlink\" title=\"7\"></a>7</h5><p> k8s  events  demo kubelet  events  EventBroadcasterEventRecorderBroadcaster</p>\n<ul>\n<li>1kubelet  EventBroadcaster  Broadcaster </li>\n<li>2kubelet  EventBroadcaster  NewRecorder()  EventRecorder EventRecorder  events  Action()  events  Broadcaster  channel </li>\n<li>3Broadcaster  events Broadcaster  goroutine EventRecorder  events</li>\n<li>4EventBroadcaster  events StartEventWatcher()StartRecordingToSink()StartLogging()StartEventWatcher()  watcher  Broadcaster StartEventWatcher() </li>\n<li>5 Broadcaster  map  watcher events  watcher watcher  ResultChan()  channel  events</li>\n<li>6kubelet  StartRecordingToSink()  StartLogging()  events StartRecordingToSink()  events  apiserverapiserver  events  etcd  kubectl StartLogging()  events  kubelet </li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p> node  pod  kubectl  events events  k8s  apiserver k8s  kubectl describe  events k8s  events  </p>\n<p> <code>k8s.io/kubernetes/cmd</code>  events<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ grep -R -n -i &quot;EventRecorder&quot; .</span><br></pre></td></tr></table></figure></p>\n<p>controller-managekube-proxykube-schedulerkubelet  EventRecorder kubelet  Events </p>\n<h5 id=\"1Events-\"><a href=\"#1Events-\" class=\"headerlink\" title=\"1Events \"></a>1Events </h5><p>events  <code>k8s.io/api/core/v1/types.go</code> ,</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type Event struct &#123;</span><br><span class=\"line\">    metav1.TypeMeta `json:&quot;,inline&quot;`</span><br><span class=\"line\">    metav1.ObjectMeta `json:&quot;metadata&quot; protobuf:&quot;bytes,1,opt,name=metadata&quot;`</span><br><span class=\"line\">    InvolvedObject ObjectReference `json:&quot;involvedObject&quot; protobuf:&quot;bytes,2,opt,name=involvedObject&quot;`</span><br><span class=\"line\">    Reason string `json:&quot;reason,omitempty&quot; protobuf:&quot;bytes,3,opt,name=reason&quot;`</span><br><span class=\"line\">    Message string `json:&quot;message,omitempty&quot; protobuf:&quot;bytes,4,opt,name=message&quot;`</span><br><span class=\"line\">    Source EventSource `json:&quot;source,omitempty&quot; protobuf:&quot;bytes,5,opt,name=source&quot;`</span><br><span class=\"line\">    FirstTimestamp metav1.Time `json:&quot;firstTimestamp,omitempty&quot; protobuf:&quot;bytes,6,opt,name=firstTimestamp&quot;`</span><br><span class=\"line\">    LastTimestamp metav1.Time `json:&quot;lastTimestamp,omitempty&quot; protobuf:&quot;bytes,7,opt,name=lastTimestamp&quot;`</span><br><span class=\"line\">    Count int32 `json:&quot;count,omitempty&quot; protobuf:&quot;varint,8,opt,name=count&quot;`</span><br><span class=\"line\">    Type string `json:&quot;type,omitempty&quot; protobuf:&quot;bytes,9,opt,name=type&quot;`</span><br><span class=\"line\">    EventTime metav1.MicroTime `json:&quot;eventTime,omitempty&quot; protobuf:&quot;bytes,10,opt,name=eventTime&quot;`</span><br><span class=\"line\">    Series *EventSeries `json:&quot;series,omitempty&quot; protobuf:&quot;bytes,11,opt,name=series&quot;`</span><br><span class=\"line\">    Action string `json:&quot;action,omitempty&quot; protobuf:&quot;bytes,12,opt,name=action&quot;`</span><br><span class=\"line\">    Related *ObjectReference `json:&quot;related,omitempty&quot; protobuf:&quot;bytes,13,opt,name=related&quot;`</span><br><span class=\"line\">    ReportingController string `json:&quot;reportingComponent&quot; protobuf:&quot;bytes,14,opt,name=reportingComponent&quot;`</span><br><span class=\"line\">    ReportingInstance string `json:&quot;reportingInstance&quot; protobuf:&quot;bytes,15,opt,name=reportingInstance&quot;`</span><br><span class=\"line\">    ReportingInstance string `json:&quot;reportingInstance&quot; protobuf:&quot;bytes,15,opt,name=reportingInstance&quot;`</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> InvolvedObject source  kubectl  TypeReasonAgeFromMessage </p>\n<p>k8s  events Normal  Warning</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-c42d7442b2bc38d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"events \"></p>\n<h5 id=\"2EventBroadcaster-\"><a href=\"#2EventBroadcaster-\" class=\"headerlink\" title=\"2EventBroadcaster \"></a>2EventBroadcaster </h5><p>events  EventBroadcaster kubelet  EventBroadcaster <code>k8s.io/kubernetes/cmd/kubelet/app/server.go</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error &#123;</span><br><span class=\"line\">  ...</span><br><span class=\"line\">  // event </span><br><span class=\"line\">  makeEventRecorder(kubeDeps, nodeName)</span><br><span class=\"line\">  ...</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">func makeEventRecorder(kubeDeps *kubelet.Dependencies, nodeName types.NodeName) &#123;</span><br><span class=\"line\">  if kubeDeps.Recorder != nil &#123;</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  //  EventBroadcaster </span><br><span class=\"line\">  eventBroadcaster := record.NewBroadcaster()</span><br><span class=\"line\">  //  EventRecorder</span><br><span class=\"line\">  kubeDeps.Recorder = eventBroadcaster.NewRecorder(legacyscheme.Scheme, v1.EventSource&#123;Component: componentKubelet, Host: string(nodeName)&#125;)</span><br><span class=\"line\">  //  events </span><br><span class=\"line\">  eventBroadcaster.StartLogging(glog.V(3).Infof)</span><br><span class=\"line\">  if kubeDeps.EventClient != nil &#123;</span><br><span class=\"line\">    glog.V(4).Infof(&quot;Sending events to api server.&quot;)</span><br><span class=\"line\">    //  events  apiserver</span><br><span class=\"line\">  eventBroadcaster.StartRecordingToSink(&amp;v1core.EventSinkImpl&#123;Interface: kubeDeps.EventClient.Events(&quot;&quot;)&#125;)</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    glog.Warning(&quot;No api server defined - no events will be sent to API server.&quot;)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Kubelet  EventBroadcaster events (EventBroadcaster  kubelet  events  <code>k8s.io/client-go/tools/record/event.go</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type eventBroadcasterImpl struct &#123;</span><br><span class=\"line\">  *watch.Broadcaster</span><br><span class=\"line\">  sleepDuration time.Duration</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// EventBroadcaster knows how to receive events and send them to any EventSink, watcher, or log.</span><br><span class=\"line\">type EventBroadcaster interface &#123;</span><br><span class=\"line\">  StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface</span><br><span class=\"line\"></span><br><span class=\"line\">  StartRecordingToSink(sink EventSink) watch.Interface</span><br><span class=\"line\"></span><br><span class=\"line\">  StartLogging(logf func(format string, args ...interface&#123;&#125;)) watch.Interface</span><br><span class=\"line\"></span><br><span class=\"line\">  NewRecorder(scheme *runtime.Scheme, source v1.EventSource) EventRecorder</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>EventBroadcaster </p>\n<ul>\n<li>StartEventWatcher()  EventBroadcaster  events events  StartEventWatcher()  events  handle </li>\n<li>StartRecordingToSink()   StartEventWatcher()  events events  apiserver </li>\n<li>StartLogging()  StartEventWatcher()  events events </li>\n<li>NewRecorder()  EventSource  EventRecorderEventSource </li>\n</ul>\n<p>eventBroadcasterImpl  eventBroadcaster  EventBroadcaster  BroadcasterBroadcaster  goroutine  events  watcher</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewBroadcaster() EventBroadcaster &#123;</span><br><span class=\"line\">  return &amp;eventBroadcasterImpl&#123;watch.NewBroadcaster(maxQueuedEvents, watch.DropIfChannelFull), defaultSleepDuration&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>kubelet  EventBroadcaster  StartRecordingToSink()  StartLogging() StartRecordingToSink()  events  apiserverStartLogging()  events  kubelet </p>\n<h5 id=\"3Events-\"><a href=\"#3Events-\" class=\"headerlink\" title=\"3Events \"></a>3Events </h5><p> EventBroadcaster  kubelet  EventBroadcaster  EventRecorder Broadcaster  EventRecorderEventBroadcasterEventRecorderBroadcaster EventRecorder  events</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">type recorderImpl struct &#123;</span><br><span class=\"line\">  scheme *runtime.Scheme</span><br><span class=\"line\">  source v1.EventSource</span><br><span class=\"line\">  *watch.Broadcaster</span><br><span class=\"line\">  clock clock.Clock</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type EventRecorder interface &#123;</span><br><span class=\"line\">  Event(object runtime.Object, eventtype, reason, message string)</span><br><span class=\"line\"></span><br><span class=\"line\">  Eventf(object runtime.Object, eventtype, reason, messageFmt string, args ...interface&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">  PastEventf(object runtime.Object, timestamp metav1.Time, eventtype, reason, messageFmt string, args ...interface&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">  AnnotatedEventf(object runtime.Object, annotations map[string]string, eventtype, reason, messageFmt string, args ...interface&#123;&#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>EventRecorder  eventsEvent()  Eventf()  fmt.Println()  fmt.Printf()kubelet  EventRecorder  eventsrecorderImpl  EventRecorder EventRecorder  generateEvent generateEvent  events </p>\n<p> events </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (recorder *recorderImpl) generateEvent(object runtime.Object, annotations map[string]string, timestamp metav1.Time, eventtype, reason, message string) &#123;</span><br><span class=\"line\">  ref, err := ref.GetReference(recorder.scheme, object)</span><br><span class=\"line\">  if err != nil &#123;</span><br><span class=\"line\">    glog.Errorf(&quot;Could not construct reference to: &apos;%#v&apos; due to: &apos;%v&apos;. Will not report event: &apos;%v&apos; &apos;%v&apos; &apos;%v&apos;&quot;, object, err, eventtype, reason, message)</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  if !validateEventType(eventtype) &#123;</span><br><span class=\"line\">    glog.Errorf(&quot;Unsupported event type: &apos;%v&apos;&quot;, eventtype)</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">  event := recorder.makeEvent(ref, annotations, eventtype, reason, message)</span><br><span class=\"line\">  event.Source = recorder.source</span><br><span class=\"line\"></span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    // NOTE: events should be a non-blocking operation</span><br><span class=\"line\">    defer utilruntime.HandleCrash()</span><br><span class=\"line\">    // </span><br><span class=\"line\">    recorder.Action(watch.Added, event)</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (recorder *recorderImpl) makeEvent(ref *v1.ObjectReference, annotations map[string]string, eventtype, reason, message string) *v1.Event &#123;</span><br><span class=\"line\">  t := metav1.Time&#123;Time: recorder.clock.Now()&#125;</span><br><span class=\"line\">  namespace := ref.Namespace</span><br><span class=\"line\">  if namespace == &quot;&quot; &#123;</span><br><span class=\"line\">    namespace = metav1.NamespaceDefault</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  return &amp;v1.Event&#123;</span><br><span class=\"line\">    ObjectMeta: metav1.ObjectMeta&#123;</span><br><span class=\"line\">      Name:        fmt.Sprintf(&quot;%v.%x&quot;, ref.Name, t.UnixNano()),</span><br><span class=\"line\">      Namespace:   namespace,</span><br><span class=\"line\">      Annotations: annotations,</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">    InvolvedObject: *ref,</span><br><span class=\"line\">    Reason:         reason,</span><br><span class=\"line\">    Message:        message,</span><br><span class=\"line\">    FirstTimestamp: t,</span><br><span class=\"line\">    LastTimestamp:  t,</span><br><span class=\"line\">    Count:          1,</span><br><span class=\"line\">    Type:           eventtype,</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> events  recorder.Action()  events  Broadcaster , Action()  Broadcaster </p>\n<p> Action() </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *Broadcaster) Action(action EventType, obj runtime.Object) &#123;</span><br><span class=\"line\">  m.incoming &lt;- Event&#123;action, obj&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h5 id=\"4Events-\"><a href=\"#4Events-\" class=\"headerlink\" title=\"4Events \"></a>4Events </h5><p>EventBroadcaster  BroadcasterBroadcaster  events Broadcaster  <code>k8s.io/apimachinery/pkg/watch/mux.go</code> Broadcaster  goroutine EventRecorder  eventsBroadcaster  map  watcher  events  watcher watcher  channelwatcher  ResultChan()  channel </p>\n<p> Broadcaster  events <br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *Broadcaster) loop() &#123;</span><br><span class=\"line\">  for event := range m.incoming &#123;</span><br><span class=\"line\">    if event.Type == internalRunFunctionMarker &#123;</span><br><span class=\"line\">      event.Object.(functionFakeRuntimeObject)()</span><br><span class=\"line\">      continue</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    m.distribute(event)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.closeAll()</span><br><span class=\"line\">  m.distributing.Done()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// distribute sends event to all watchers. Blocking.</span><br><span class=\"line\">func (m *Broadcaster) distribute(event Event) &#123;</span><br><span class=\"line\">  m.lock.Lock()</span><br><span class=\"line\">  defer m.lock.Unlock()</span><br><span class=\"line\">  if m.fullChannelBehavior == DropIfChannelFull &#123;</span><br><span class=\"line\">    for _, w := range m.watchers &#123;</span><br><span class=\"line\">      select &#123;</span><br><span class=\"line\">      case w.result &lt;- event:</span><br><span class=\"line\">      case &lt;-w.stopped:</span><br><span class=\"line\">      default: // Don&apos;t block if the event can&apos;t be queued.</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125; else &#123;</span><br><span class=\"line\">    for _, w := range m.watchers &#123;</span><br><span class=\"line\">      select &#123;</span><br><span class=\"line\">      case w.result &lt;- event:</span><br><span class=\"line\">      case &lt;-w.stopped:</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"5Events-\"><a href=\"#5Events-\" class=\"headerlink\" title=\"5Events \"></a>5Events </h5><p> watcher  events  client  watcher events  EventBroadcaster  EventBroadcaster  events </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartEventWatcher(eventHandler func(*v1.Event)) watch.Interface &#123;</span><br><span class=\"line\">  watcher := eventBroadcaster.Watch()</span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    defer utilruntime.HandleCrash()</span><br><span class=\"line\">    for watchEvent := range watcher.ResultChan() &#123;</span><br><span class=\"line\">      event, ok := watchEvent.Object.(*v1.Event)</span><br><span class=\"line\">      if !ok &#123;</span><br><span class=\"line\">        // This is all local, so there&apos;s no reason this should</span><br><span class=\"line\">        // ever happen.</span><br><span class=\"line\">        continue</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      eventHandler(event)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\">  return watcher</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>StartEventWatcher()  watcher watcher  Broadcaster  watcher watcher  Broadcaster  channel  events eventHandler StartLogging()  StartRecordingToSink()  StartEventWatcher() </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartLogging(logf func(format string, args ...interface&#123;&#125;)) watch.Interface &#123;</span><br><span class=\"line\">  return eventBroadcaster.StartEventWatcher(</span><br><span class=\"line\">    func(e *v1.Event) &#123;</span><br><span class=\"line\">      logf(&quot;Event(%#v): type: &apos;%v&apos; reason: &apos;%v&apos; %v&quot;, e.InvolvedObject, e.Type, e.Reason, e.Message)</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>StartLogging()  eventHandler  events </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartRecordingToSink(sink EventSink) watch.Interface &#123;</span><br><span class=\"line\">  // The default math/rand package functions aren&apos;t thread safe, so create a</span><br><span class=\"line\">  // new Rand object for each StartRecording call.</span><br><span class=\"line\">  randGen := rand.New(rand.NewSource(time.Now().UnixNano()))</span><br><span class=\"line\">  eventCorrelator := NewEventCorrelator(clock.RealClock&#123;&#125;)</span><br><span class=\"line\">  return eventBroadcaster.StartEventWatcher(</span><br><span class=\"line\">    func(event *v1.Event) &#123;</span><br><span class=\"line\">      recordToSink(sink, event, eventCorrelator, randGen, eventBroadcaster.sleepDuration)</span><br><span class=\"line\">    &#125;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func recordToSink(sink EventSink, event *v1.Event, eventCorrelator *EventCorrelator, randGen *rand.Rand, sleepDuration time.Duration) &#123;</span><br><span class=\"line\">  eventCopy := *event</span><br><span class=\"line\">  event = &amp;eventCopy</span><br><span class=\"line\">  result, err := eventCorrelator.EventCorrelate(event)</span><br><span class=\"line\">  if err != nil &#123;</span><br><span class=\"line\">    utilruntime.HandleError(err)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  if result.Skip &#123;</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  tries := 0</span><br><span class=\"line\">  for &#123;</span><br><span class=\"line\">    if recordEvent(sink, result.Event, result.Patch, result.Event.Count &gt; 1, eventCorrelator) &#123;</span><br><span class=\"line\">      break</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    tries++</span><br><span class=\"line\">    if tries &gt;= maxTriesPerEvent &#123;</span><br><span class=\"line\">      glog.Errorf(&quot;Unable to write event &apos;%#v&apos; (retry limit exceeded!)&quot;, event)</span><br><span class=\"line\">      break</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    //  apiserver </span><br><span class=\"line\">    if tries == 1 &#123;</span><br><span class=\"line\">      time.Sleep(time.Duration(float64(sleepDuration) * randGen.Float64()))</span><br><span class=\"line\">    &#125; else &#123;</span><br><span class=\"line\">      time.Sleep(sleepDuration)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>StartRecordingToSink()  randGen apiserver EventCorrelatorEventCorrelator  recordToSink() recordToSink()  events  apiserver StartEventWatcher() </p>\n<h5 id=\"6Events-\"><a href=\"#6Events-\" class=\"headerlink\" title=\"6Events \"></a>6Events </h5><p> events  demo events </p>\n<ul>\n<li>1</li>\n<li>2</li>\n<li>3</li>\n<li>4</li>\n<li>5</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">package main</span><br><span class=\"line\"></span><br><span class=\"line\">import (</span><br><span class=\"line\">  &quot;fmt&quot;</span><br><span class=\"line\">  &quot;sync&quot;</span><br><span class=\"line\">  &quot;time&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">// watcher queue</span><br><span class=\"line\">const queueLength = int64(1)</span><br><span class=\"line\"></span><br><span class=\"line\">// Events xxx</span><br><span class=\"line\">type Events struct &#123;</span><br><span class=\"line\">  Reason    string</span><br><span class=\"line\">  Message   string</span><br><span class=\"line\">  Source    string</span><br><span class=\"line\">  Type      string</span><br><span class=\"line\">  Count     int64</span><br><span class=\"line\">  Timestamp time.Time</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// EventBroadcaster xxx</span><br><span class=\"line\">type EventBroadcaster interface &#123;</span><br><span class=\"line\">  Event(etype, reason, message string)</span><br><span class=\"line\">  StartLogging() Interface</span><br><span class=\"line\">  Stop()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// eventBroadcaster xxx</span><br><span class=\"line\">type eventBroadcasterImpl struct &#123;</span><br><span class=\"line\">  *Broadcaster</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func NewEventBroadcaster() EventBroadcaster &#123;</span><br><span class=\"line\">  return &amp;eventBroadcasterImpl&#123;NewBroadcaster(queueLength)&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) Stop() &#123;</span><br><span class=\"line\">  eventBroadcaster.Shutdown()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// generate event</span><br><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) Event(etype, reason, message string) &#123;</span><br><span class=\"line\">  events := &amp;Events&#123;Type: etype, Reason: reason, Message: message&#125;</span><br><span class=\"line\">  // send event to broadcast</span><br><span class=\"line\">  eventBroadcaster.Action(events)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  StartLogging() </span><br><span class=\"line\">func (eventBroadcaster *eventBroadcasterImpl) StartLogging() Interface &#123;</span><br><span class=\"line\">  // register a watcher</span><br><span class=\"line\">  watcher := eventBroadcaster.Watch()</span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    for watchEvent := range watcher.ResultChan() &#123;</span><br><span class=\"line\">      fmt.Printf(&quot;%v\\n&quot;, watchEvent)</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    time.Sleep(time.Second * 4)</span><br><span class=\"line\">    watcher.Stop()</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">  return watcher</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// --------------------</span><br><span class=\"line\">// Broadcaster </span><br><span class=\"line\">//  events channel </span><br><span class=\"line\">const incomingQueuLength = 100</span><br><span class=\"line\"></span><br><span class=\"line\">type Broadcaster struct &#123;</span><br><span class=\"line\">  lock             sync.Mutex</span><br><span class=\"line\">  incoming         chan Events</span><br><span class=\"line\">  watchers         map[int64]*broadcasterWatcher</span><br><span class=\"line\">  watchersQueue    int64</span><br><span class=\"line\">  watchQueueLength int64</span><br><span class=\"line\">  distributing     sync.WaitGroup</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func NewBroadcaster(queueLength int64) *Broadcaster &#123;</span><br><span class=\"line\">  m := &amp;Broadcaster&#123;</span><br><span class=\"line\">    incoming:         make(chan Events, incomingQueuLength),</span><br><span class=\"line\">    watchers:         map[int64]*broadcasterWatcher&#123;&#125;,</span><br><span class=\"line\">    watchQueueLength: queueLength,</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.distributing.Add(1)</span><br><span class=\"line\">  //  goroutine  events</span><br><span class=\"line\">  go m.loop()</span><br><span class=\"line\">  return m</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// Broadcaster  events</span><br><span class=\"line\">func (m *Broadcaster) Action(event *Events) &#123;</span><br><span class=\"line\">  m.incoming &lt;- *event</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  events  watcher</span><br><span class=\"line\">func (m *Broadcaster) loop() &#123;</span><br><span class=\"line\">  //  incoming channel  events</span><br><span class=\"line\">  for event := range m.incoming &#123;</span><br><span class=\"line\">    //  events  watcher</span><br><span class=\"line\">    for _, w := range m.watchers &#123;</span><br><span class=\"line\">      select &#123;</span><br><span class=\"line\">      case w.result &lt;- event:</span><br><span class=\"line\">      case &lt;-w.stopped:</span><br><span class=\"line\">      default:</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.closeAll()</span><br><span class=\"line\">  m.distributing.Done()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (m *Broadcaster) Shutdown() &#123;</span><br><span class=\"line\">  close(m.incoming)</span><br><span class=\"line\">  m.distributing.Wait()</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (m *Broadcaster) closeAll() &#123;</span><br><span class=\"line\">  // TODO</span><br><span class=\"line\">  m.lock.Lock()</span><br><span class=\"line\">  defer m.lock.Unlock()</span><br><span class=\"line\">  for _, w := range m.watchers &#123;</span><br><span class=\"line\">    close(w.result)</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.watchers = map[int64]*broadcasterWatcher&#123;&#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (m *Broadcaster) stopWatching(id int64) &#123;</span><br><span class=\"line\">  m.lock.Lock()</span><br><span class=\"line\">  defer m.lock.Unlock()</span><br><span class=\"line\">  w, ok := m.watchers[id]</span><br><span class=\"line\">  if !ok &#123;</span><br><span class=\"line\">    return</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  delete(m.watchers, id)</span><br><span class=\"line\">  close(w.result)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  Watch( watcher</span><br><span class=\"line\">func (m *Broadcaster) Watch() Interface &#123;</span><br><span class=\"line\">  watcher := &amp;broadcasterWatcher&#123;</span><br><span class=\"line\">    result:  make(chan Events, incomingQueuLength),</span><br><span class=\"line\">    stopped: make(chan struct&#123;&#125;),</span><br><span class=\"line\">    id:      m.watchQueueLength,</span><br><span class=\"line\">    m:       m,</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">  m.watchers[m.watchersQueue] = watcher</span><br><span class=\"line\">  m.watchQueueLength++</span><br><span class=\"line\">  return watcher</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// watcher </span><br><span class=\"line\">type Interface interface &#123;</span><br><span class=\"line\">  Stop()</span><br><span class=\"line\">  ResultChan() &lt;-chan Events</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type broadcasterWatcher struct &#123;</span><br><span class=\"line\">  result  chan Events</span><br><span class=\"line\">  stopped chan struct&#123;&#125;</span><br><span class=\"line\">  stop    sync.Once</span><br><span class=\"line\">  id      int64</span><br><span class=\"line\">  m       *Broadcaster</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">//  watcher  channel  events</span><br><span class=\"line\">func (b *broadcasterWatcher) ResultChan() &lt;-chan Events &#123;</span><br><span class=\"line\">  return b.result</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func (b *broadcasterWatcher) Stop() &#123;</span><br><span class=\"line\">  b.stop.Do(func() &#123;</span><br><span class=\"line\">    close(b.stopped)</span><br><span class=\"line\">    b.m.stopWatching(b.id)</span><br><span class=\"line\">  &#125;)</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// --------------------</span><br><span class=\"line\"></span><br><span class=\"line\">func main() &#123;</span><br><span class=\"line\">  eventBroadcast := NewEventBroadcaster()</span><br><span class=\"line\"></span><br><span class=\"line\">  var wg sync.WaitGroup</span><br><span class=\"line\">  wg.Add(1)</span><br><span class=\"line\">  // producer event</span><br><span class=\"line\">  go func() &#123;</span><br><span class=\"line\">    defer wg.Done()</span><br><span class=\"line\">    time.Sleep(time.Second)</span><br><span class=\"line\">    eventBroadcast.Event(&quot;add&quot;, &quot;test&quot;, &quot;1&quot;)</span><br><span class=\"line\">    time.Sleep(time.Second * 2)</span><br><span class=\"line\">    eventBroadcast.Event(&quot;add&quot;, &quot;test&quot;, &quot;2&quot;)</span><br><span class=\"line\">    time.Sleep(time.Second * 3)</span><br><span class=\"line\">    eventBroadcast.Event(&quot;add&quot;, &quot;test&quot;, &quot;3&quot;)</span><br><span class=\"line\">    //eventBroadcast.Stop()</span><br><span class=\"line\">  &#125;()</span><br><span class=\"line\"></span><br><span class=\"line\">  eventBroadcast.StartLogging()</span><br><span class=\"line\">  wg.Wait()</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p> EventRecorder  events  EventBroadcaster  events  StartLogging()Broadcaster  k8s  EventCorrelator </p>\n<p><a href=\"https://github.com/gosoon/k8s-learning-notes/tree/master/k8s-package/events\" target=\"_blank\" rel=\"noopener\">https://github.com/gosoon/k8s-learning-notes/tree/master/k8s-package/events</a></p>\n<h5 id=\"7\"><a href=\"#7\" class=\"headerlink\" title=\"7\"></a>7</h5><p> k8s  events  demo kubelet  events  EventBroadcasterEventRecorderBroadcaster</p>\n<ul>\n<li>1kubelet  EventBroadcaster  Broadcaster </li>\n<li>2kubelet  EventBroadcaster  NewRecorder()  EventRecorder EventRecorder  events  Action()  events  Broadcaster  channel </li>\n<li>3Broadcaster  events Broadcaster  goroutine EventRecorder  events</li>\n<li>4EventBroadcaster  events StartEventWatcher()StartRecordingToSink()StartLogging()StartEventWatcher()  watcher  Broadcaster StartEventWatcher() </li>\n<li>5 Broadcaster  map  watcher events  watcher watcher  ResultChan()  channel  events</li>\n<li>6kubelet  StartRecordingToSink()  StartLogging()  events StartRecordingToSink()  events  apiserverapiserver  events  etcd  kubectl StartLogging()  events  kubelet </li>\n</ul>\n"},{"title":"kubelet  pod ","date":"2019-01-03T00:15:30.000Z","type":"kubelet","_content":" [kubelet ](http://blog.tianfeiyu.com/2018/12/23/kubelet_init/) kubelet  pod \n \n> kubernetes  v1.12 \n\n![kubelet ](https://upload-images.jianshu.io/upload_images/1262158-78c8272f4b617c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nkubelet  pod ( pod )SyncLoop\n\n\n pod  pod  node  pod  kubelet  handler HandlePods  pod  kubelet kubelet  pod Handler  ADD  kubelet  pod  podStatus pod  volume  update kubelet  pod \n\n## kubelet  pod \n\n![kubelet  pod ](https://upload-images.jianshu.io/upload_images/1262158-bb6b29bac1ca6c9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### 1kubelet syncLoop\n\nsyncLoop  syncTicker  housekeepingTicker pod kubelet  pod  for  syncLoopIterationkubelet  runtimeState  5 \n\n\n```\nfunc (kl *Kubelet) syncLoop(updates <-chan kubetypes.PodUpdate, handler SyncHandler) {\n\tglog.Info(\"Starting kubelet main sync loop.\")\n\n\t// syncTicker  pod workers\n\tsyncTicker := time.NewTicker(time.Second)\n\tdefer syncTicker.Stop()\n\t//  pod\n\thousekeepingTicker := time.NewTicker(housekeepingPeriod)\n\tdefer housekeepingTicker.Stop()\n\t// pod \n\tplegCh := kl.pleg.Watch()\n\tconst (\n\t\tbase   = 100 * time.Millisecond\n\t\tmax    = 5 * time.Second\n\t\tfactor = 2\n\t)\n\tduration := base\n\tfor {\n\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 {\n\t\t\ttime.Sleep(duration)\n\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))\n\t\t\tcontinue\n\t\t}\n        ...\n\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t\t//  SyncHandler SyncHandler  interface\n\t\t// \n\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) {\n\t\t\tbreak\n\t\t}\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t}\n}\n```\n\n \n\n### 2 pod syncLoopIteration \n\nsyncLoopIteration  handler \n\n- configCh kubeDeps  PodConfig  watch 3  pod filehttpapiserver pod // channel  pod \n- syncCh pod \n- houseKeepingChhousekeeping  pod \n- plegCh kubelet  pleg  container runtime  channel \n- livenessManager.Updates() pod kubelet  Pod restartPolicy \n\n\n```\nfunc (kl *Kubelet) syncLoopIteration(configCh <-chan kubetypes.PodUpdate, handler SyncHandler,\n\tsyncCh <-chan time.Time, housekeepingCh <-chan time.Time, plegCh <-chan *pleg.PodLifecycleEvent) bool {\n\tselect {\n\tcase u, open := <-configCh:\n\t\tif !open {\n\t\t\tglog.Errorf(\"Update channel is closed. Exiting the sync loop.\")\n\t\t\treturn false\n\t\t}\n\n\t\tswitch u.Op {\n\t\tcase kubetypes.ADD:\n\t\t\t...\n\t\tcase kubetypes.UPDATE:\n\t\t\t...\n\t\tcase kubetypes.REMOVE:\n\t\t\t...\n\t\tcase kubetypes.RECONCILE:\n\t\t\t...\n\t\tcase kubetypes.DELETE:\n\t\t\t...\n\t\tcase kubetypes.RESTORE:\n\t\t\t...\n\t\tcase kubetypes.SET:\n\t\t\t...\n\t\t}\n\t\t...\n\tcase e := <-plegCh:\n\t\t...\n\tcase <-syncCh:\n\t\t...\n\tcase update := <-kl.livenessManager.Updates():\n\t\t...\n\tcase <-housekeepingCh:\n\t\t...\n\t}\n\treturn true\n}\n```\n\n### 3 podHandlePodAddtions\n\n pod\n\n- 1 pod  pod \n- 2 podManager podManager  pod pod  mirrorPod  pod  podManager  pod pod \n- 3 mirror pod \n- 4 pod \n- 5 dispatchWork  pod  podWorkers \n- 6 probeManager  pod pod  readiness  liveness  goroutine \n\n```\nfunc (kl *Kubelet) HandlePodAdditions(pods []*v1.Pod) {\n\tstart := kl.clock.Now()\n\t//  pod  pod \n\tsort.Sort(sliceutils.PodsByCreationTime(pods))\n\tfor _, pod := range pods {\n\t\tif kl.dnsConfigurer != nil && kl.dnsConfigurer.ResolverConfig != \"\" {\n\t\t\tkl.dnsConfigurer.CheckLimitsForResolvConf()\n\t\t}\n\t\texistingPods := kl.podManager.GetPods()\n\t\t//  pod  podManager \n\t\tkl.podManager.AddPod(pod)\n\n\t\t//  mirror pod static pod\n\t\tif kubepod.IsMirrorPod(pod) {\n\t\t\tkl.handleMirrorPod(pod, start)\n\t\t\tcontinue\n\t\t}\n\n\t\tif !kl.podIsTerminated(pod) {\n\t\t\tactivePods := kl.filterOutTerminatedPods(existingPods)\n\t\t\t//  canAdmitPod Pod(:)\n\t\t\t// Check if we can admit the pod; if not, reject it.\n\t\t\tif ok, reason, message := kl.canAdmitPod(activePods, pod); !ok {\n\t\t\t\tkl.rejectPod(pod, reason, message)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t\n\t\tmirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod)\n\t\t//  dispatchWork  pod dispatchWork  UpdatePodOptions UpdatePod .\n\t\tkl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start)\n\t\t//  probeManager  pod pod  readiness  liveness  goroutine \n\t\tkl.probeManager.AddPod(pod)\n\t}\n}\n```\n\n> static pod  kubelet k8s apiserver  static pod  rs  kubelet Kubelet  apiserver  static pod  mirror pod kubectl  pod, kubectl logs static pod \n\n\n### 4dispatchWork\n\ndispatchWorker  Pod // podWorkers\n\n```\nfunc (kl *Kubelet) dispatchWork(pod *v1.Pod, syncType kubetypes.SyncPodType, mirrorPod *v1.Pod, start time.Time) {\n\tif kl.podIsTerminated(pod) {\n\t\tif pod.DeletionTimestamp != nil {\n\t\t\tkl.statusManager.TerminatePod(pod)\n\t\t}\n\t\treturn\n\t}\n\t//  podWorkers \n\tkl.podWorkers.UpdatePod(&UpdatePodOptions{\n\t\tPod:        pod,\n\t\tMirrorPod:  mirrorPod,\n\t\tUpdateType: syncType,\n\t\tOnCompleteFunc: func(err error) {\n\t\t\tif err != nil {\n\t\t\t\tmetrics.PodWorkerLatency.WithLabelValues(syncType.String()).Observe(metrics.SinceInMicroseconds(start))\n\t\t\t}\n\t\t},\n\t})\n\tif syncType == kubetypes.SyncPodCreate {\n\t\tmetrics.ContainersPerPodCount.Observe(float64(len(pod.Spec.Containers)))\n\t}\n}\n```\n\n\n### 5 channelUpdatePod\n\npodWorkers  Pod  Pod  podWorkers  Pod  goroutine  channelgoroutine  channel  podWorkers \n\n\n```\nfunc (p *podWorkers) UpdatePod(options *UpdatePodOptions) {\n\tpod := options.Pod\n\tuid := pod.UID\n\tvar podUpdates chan UpdatePodOptions\n\tvar exists bool\n\n\tp.podLock.Lock()\n\tdefer p.podLock.Unlock()\n\n\t//  pod  goroutine  goroutine channel\n\tif podUpdates, exists = p.podUpdates[uid]; !exists {\n\t\t//  channel\n\t\tpodUpdates = make(chan UpdatePodOptions, 1)\n\t\tp.podUpdates[uid] = podUpdates\n\n\t\t//  goroutine\n\t\tgo func() {\n\t\t\tdefer runtime.HandleCrash()\n\t\t\tp.managePodLoop(podUpdates)\n\t\t}()\n\t}\n\t// \n\tif !p.isWorking[pod.UID] {\n\t\tp.isWorking[pod.UID] = true\n\t\tpodUpdates <- *options\n\t} else {\n\t\tupdate, found := p.lastUndeliveredWorkUpdate[pod.UID]\n\t\tif !found || update.UpdateType != kubetypes.SyncPodKill {\n\t\t\tp.lastUndeliveredWorkUpdate[pod.UID] = *options\n\t\t}\n\t}\n}\n```\n\n### 6 syncPodFn  podmanagePodLoop\nmanagePodLoop  syncPodFn  podsyncPodFn kubelet.SyncPod sync  wrapUp :\n\n-  pod  kubelet  workQueue  pod  sync\n-  sync  update  goroutine  channel \n\n\n```\nfunc (p *podWorkers) managePodLoop(podUpdates <-chan UpdatePodOptions) {\n\tvar lastSyncTime time.Time\n\tfor update := range podUpdates {\n\t\terr := func() error {\n\t\t\tpodUID := update.Pod.UID\n\t\t\tstatus, err := p.podCache.GetNewerThan(podUID, lastSyncTime)\n\t\t\tif err != nil {\n\t\t\t\t...\n\t\t\t}\n\t\t\terr = p.syncPodFn(syncPodOptions{\n\t\t\t\tmirrorPod:      update.MirrorPod,\n\t\t\t\tpod:            update.Pod,\n\t\t\t\tpodStatus:      status,\n\t\t\t\tkillPodOptions: update.KillPodOptions,\n\t\t\t\tupdateType:     update.UpdateType,\n\t\t\t})\n\t\t\tlastSyncTime = time.Now()\n\t\t\treturn err\n\t\t}()\n\t\tif update.OnCompleteFunc != nil {\n\t\t\tupdate.OnCompleteFunc(err)\n\t\t}\n\t\tif err != nil {\n\t\t\t...\n\t\t}\n\t\tp.wrapUp(update.Pod.UID, err)\n\t}\n}\n```\n\n### 7SyncPod\n\n\n\n-  pod\n-  podStatus  kubelet.statusManager\n-  pod  privileged  pod \n-  containerManagar  pod level cgroup Qos level cgroup\n-  static Pod mirrorPod\n-  pod  volume  plugin , pv volume mount volumeManager , image secrets apiserver  secrets \n-  kubelet.volumeManager  pod  volume \n-  container runtime  SyncPod \n\n pod \n\n```\nfunc (kl *Kubelet) syncPod(o syncPodOptions) error {\n\t// pull out the required options\n\tpod := o.pod\n\tmirrorPod := o.mirrorPod\n\tpodStatus := o.podStatus\n\tupdateType := o.updateType\n\n\t//   pod\n\tif updateType == kubetypes.SyncPodKill {\n\t\t...\n\t}\n    ...\n\t//  pod \n\trunnable := kl.canRunPod(pod)\n\tif !runnable.Admit {\n\t\t...\n\t}\n\n\t//  pod \n\tkl.statusManager.SetPodStatus(pod, apiPodStatus)\n\n\t//  pod  running  kill \n\tif !runnable.Admit || pod.DeletionTimestamp != nil || apiPodStatus.Phase == v1.PodFailed {\n\t\t...\n\t}\n\n\t// \n\tif rs := kl.runtimeState.networkErrors(); len(rs) != 0 && !kubecontainer.IsHostNetworkPod(pod) {\n\t\t...\n\t}\n\n\tpcm := kl.containerManager.NewPodContainerManager()\n\tif !kl.podIsTerminated(pod) {\n\t\t...\n\t\t//  pod  cgroups\n\t\tif !(podKilled && pod.Spec.RestartPolicy == v1.RestartPolicyNever) {\n\t\t\tif !pcm.Exists(pod) {\n\t\t\t\t...\n\t\t\t}\n\t\t}\n\t}\n\n\t//  static pod  mirror pod\n\tif kubepod.IsStaticPod(pod) {\n\t\t...\n\t}\n\n\t// \n\tif err := kl.makePodDataDirs(pod); err != nil {\n\t\t...\n\t}\n\n\t//  volume\n\tif !kl.podIsTerminated(pod) {\n\t\tif err := kl.volumeManager.WaitForAttachAndMount(pod); err != nil {\n\t\t\t...\n\t\t}\n\t}\n\n\t//  secret \n\tpullSecrets := kl.getPullSecretsForPod(pod)\n\n\t//  containerRuntime  SyncPod \n\tresult := kl.containerRuntime.SyncPod(pod, apiPodStatus, podStatus, pullSecrets, kl.backOff)\n\tkl.reasonCache.Update(pod.UID, result)\n\tif err := result.Error(); err != nil {\n\t\t...\n\t}\n\n\treturn nil\n}\n```\n\n\n### 8\n\ncontainerRuntimepkg/kubelet/kuberuntime SyncPod  pod \nsyncPod \n- 1 sandbox  container \n- 2 sandbox \n- 3 init \n- 4\n\ninitContainers  container  container  container\n\n```\nfunc (m *kubeGenericRuntimeManager) SyncPod(pod *v1.Pod, _ v1.PodStatus, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, backOff *flowcontrol.Backoff) (result kubecontainer.PodSyncResult) {\n\t// 1 sandbox  container \n\tpodContainerChanges := m.computePodActions(pod, podStatus)\n\tif podContainerChanges.CreateSandbox {\n\t\tref, err := ref.GetReference(legacyscheme.Scheme, pod)\n\t\tif err != nil {\n\t\t\tglog.Errorf(\"Couldn't make a ref to pod %q: '%v'\", format.Pod(pod), err)\n\t\t}\n\t\t...\n\t}\n\n\t// 2kill  sandbox  pod\n\tif podContainerChanges.KillPod {\n\t\t...\n\t} else {\n\t\t// 3kill  running  containers\n\t\t...\n\t\tfor containerID, containerInfo := range podContainerChanges.ContainersToKill {\n\t\t\t...\n\t\t\tif err := m.killContainer(pod, containerID, containerInfo.name, containerInfo.message, nil); err != nil {\n\t\t\t\t...\n\t\t\t}\n\t\t}\n\t}\n\n\tm.pruneInitContainersBeforeStart(pod, podStatus)\n\tpodIP := \"\"\n\tif podStatus != nil {\n\t\tpodIP = podStatus.IP\n\t}\n\n\t// 4 sandbox \n\tpodSandboxID := podContainerChanges.SandboxID\n\tif podContainerChanges.CreateSandbox {\n\t\tpodSandboxID, msg, err = m.createPodSandbox(pod, podContainerChanges.Attempt)\n\t\tif err != nil {\n\t\t\t...\n\t\t}\n\t\t...\n\t\tpodSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID)\n\t\tif err != nil {\n\t\t\t...\n\t\t}\n\t\t//  pod  host  None  kubelet \n\t\tif !kubecontainer.IsHostNetworkPod(pod) {\n\t\t\tpodIP = m.determinePodSandboxIP(pod.Namespace, pod.Name, podSandboxStatus)\n\t\t\tglog.V(4).Infof(\"Determined the ip %q for pod %q after sandbox changed\", podIP, format.Pod(pod))\n\t\t}\n\t}\n\n\tconfigPodSandboxResult := kubecontainer.NewSyncResult(kubecontainer.ConfigPodSandbox, podSandboxID)\n\tresult.AddSyncResult(configPodSandboxResult)\n\t//  PodSandbox (:metadata,clusterDNS,)\n\tpodSandboxConfig, err := m.generatePodSandboxConfig(pod, podContainerChanges.Attempt)\n\t...\n\n\t// 5 init container\n\tif container := podContainerChanges.NextInitContainerToStart; container != nil {\n\t\t...\n\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeInit); err != nil {\n\t\t\t...\n\t\t}\n\t}\n\n\t// 6\n\tfor _, idx := range podContainerChanges.ContainersToStart {\n\t\t...\n\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeRegular); err != nil {\n\t\t\t...\n\t\t}\n\t}\n\t\n\treturn\n}\n```\n\n\n### 9\n\n startContainer \n\n- 1\n- 2\n- 3 docker api \n- 4\n- 5 post start hook\n\n\n```\nfunc (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, container *v1.Container, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, containerType kubecontainer.ContainerType) (string, error) {\n\t// 1 Docker Registry  Private Registry \n\timageRef, msg, err := m.imagePuller.EnsureImageExists(pod, container, pullSecrets)\n\tif err != nil {\n\t\t...\n\t}\n\n\tref, err := kubecontainer.GenerateContainerRef(pod, container)\n\tif err != nil {\n\t\t...\n\t}\n\n\t//  RestartCount \n\trestartCount := 0\n\tcontainerStatus := podStatus.FindContainerStatusByName(container.Name)\n\tif containerStatus != nil {\n\t\trestartCount = containerStatus.RestartCount + 1\n\t}\n\n\t// 2\n\tcontainerConfig, cleanupAction, err := m.generateContainerConfig(container, pod, restartCount, podIP, imageRef, containerType)\n\tif cleanupAction != nil {\n\t\tdefer cleanupAction()\n\t}\n\t...\n\n\t// 3 client.CreateContainer  docker api \n\tcontainerID, err := m.runtimeService.CreateContainer(podSandboxID, containerConfig, podSandboxConfig)\n\tif err != nil {\n\t\t...\n\t}\n\terr = m.internalLifecycle.PreStartContainer(pod, container, containerID)\n\tif err != nil {\n\t\t...\n\t}\n\t...\n\n\t// 3\n\terr = m.runtimeService.StartContainer(containerID)\n\tif err != nil {\n\t\t...\n\t}\n\n\tcontainerMeta := containerConfig.GetMetadata()\n\tsandboxMeta := podSandboxConfig.GetMetadata()\n\tlegacySymlink := legacyLogSymlink(containerID, containerMeta.Name, sandboxMeta.Name,\n\t\tsandboxMeta.Namespace)\n\tcontainerLog := filepath.Join(podSandboxConfig.LogDirectory, containerConfig.LogPath)\n\tif _, err := m.osInterface.Stat(containerLog); !os.IsNotExist(err) {\n\t\tif err := m.osInterface.Symlink(containerLog, legacySymlink); err != nil {\n\t\t\tglog.Errorf(\"Failed to create legacy symbolic link %q to container %q log %q: %v\",\n\t\t\t\tlegacySymlink, containerID, containerLog, err)\n\t\t}\n\t}\n\n\t// 4 post start hook\n\tif container.Lifecycle != nil && container.Lifecycle.PostStart != nil {\n\t\tkubeContainerID := kubecontainer.ContainerID{\n\t\t\tType: m.runtimeName,\n\t\t\tID:   containerID,\n\t\t}\n\t\t// runner.Run \n\t\t//  container hook(PostStart  PreStop),\n\t\t//  container hook \n\t\tmsg, handlerErr := m.runner.Run(kubeContainerID, pod, container, container.Lifecycle.PostStart)\n\t\tif handlerErr != nil {\n\t\t\t...\n\t\t}\n\t}\n\n\treturn \"\", nil\n}\n```\n\n\n## \n\n kubelet kubelet  docker api  kubelet  pod \n\n\n\n[k8s-kubelet](https://sycki.com/articles/kubernetes/k8s-code-kubelet)\n[Kubelet():](https://segmentfault.com/a/1190000008267351)\n[kubelet pod ](http://cizixs.com/2017/06/07/kubelet-source-code-analysis-part-2/)\n[kubeletPod](https://fatsheep9146.github.io/2018/07/22/kubelet%E5%88%9B%E5%BB%BAPod%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/)\n[Kubelet: Pod Lifecycle Event Generator (PLEG) Design-\tproposals](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md)\n\n","source":"_posts/kubelet_create_pod.md","raw":"---\ntitle: kubelet  pod \ndate: 2019-01-03 08:15:30\ntags: \"kubelet\"\ntype: \"kubelet\"\n\n---\n [kubelet ](http://blog.tianfeiyu.com/2018/12/23/kubelet_init/) kubelet  pod \n \n> kubernetes  v1.12 \n\n![kubelet ](https://upload-images.jianshu.io/upload_images/1262158-78c8272f4b617c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nkubelet  pod ( pod )SyncLoop\n\n\n pod  pod  node  pod  kubelet  handler HandlePods  pod  kubelet kubelet  pod Handler  ADD  kubelet  pod  podStatus pod  volume  update kubelet  pod \n\n## kubelet  pod \n\n![kubelet  pod ](https://upload-images.jianshu.io/upload_images/1262158-bb6b29bac1ca6c9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\n### 1kubelet syncLoop\n\nsyncLoop  syncTicker  housekeepingTicker pod kubelet  pod  for  syncLoopIterationkubelet  runtimeState  5 \n\n\n```\nfunc (kl *Kubelet) syncLoop(updates <-chan kubetypes.PodUpdate, handler SyncHandler) {\n\tglog.Info(\"Starting kubelet main sync loop.\")\n\n\t// syncTicker  pod workers\n\tsyncTicker := time.NewTicker(time.Second)\n\tdefer syncTicker.Stop()\n\t//  pod\n\thousekeepingTicker := time.NewTicker(housekeepingPeriod)\n\tdefer housekeepingTicker.Stop()\n\t// pod \n\tplegCh := kl.pleg.Watch()\n\tconst (\n\t\tbase   = 100 * time.Millisecond\n\t\tmax    = 5 * time.Second\n\t\tfactor = 2\n\t)\n\tduration := base\n\tfor {\n\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 {\n\t\t\ttime.Sleep(duration)\n\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))\n\t\t\tcontinue\n\t\t}\n        ...\n\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t\t//  SyncHandler SyncHandler  interface\n\t\t// \n\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) {\n\t\t\tbreak\n\t\t}\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t}\n}\n```\n\n \n\n### 2 pod syncLoopIteration \n\nsyncLoopIteration  handler \n\n- configCh kubeDeps  PodConfig  watch 3  pod filehttpapiserver pod // channel  pod \n- syncCh pod \n- houseKeepingChhousekeeping  pod \n- plegCh kubelet  pleg  container runtime  channel \n- livenessManager.Updates() pod kubelet  Pod restartPolicy \n\n\n```\nfunc (kl *Kubelet) syncLoopIteration(configCh <-chan kubetypes.PodUpdate, handler SyncHandler,\n\tsyncCh <-chan time.Time, housekeepingCh <-chan time.Time, plegCh <-chan *pleg.PodLifecycleEvent) bool {\n\tselect {\n\tcase u, open := <-configCh:\n\t\tif !open {\n\t\t\tglog.Errorf(\"Update channel is closed. Exiting the sync loop.\")\n\t\t\treturn false\n\t\t}\n\n\t\tswitch u.Op {\n\t\tcase kubetypes.ADD:\n\t\t\t...\n\t\tcase kubetypes.UPDATE:\n\t\t\t...\n\t\tcase kubetypes.REMOVE:\n\t\t\t...\n\t\tcase kubetypes.RECONCILE:\n\t\t\t...\n\t\tcase kubetypes.DELETE:\n\t\t\t...\n\t\tcase kubetypes.RESTORE:\n\t\t\t...\n\t\tcase kubetypes.SET:\n\t\t\t...\n\t\t}\n\t\t...\n\tcase e := <-plegCh:\n\t\t...\n\tcase <-syncCh:\n\t\t...\n\tcase update := <-kl.livenessManager.Updates():\n\t\t...\n\tcase <-housekeepingCh:\n\t\t...\n\t}\n\treturn true\n}\n```\n\n### 3 podHandlePodAddtions\n\n pod\n\n- 1 pod  pod \n- 2 podManager podManager  pod pod  mirrorPod  pod  podManager  pod pod \n- 3 mirror pod \n- 4 pod \n- 5 dispatchWork  pod  podWorkers \n- 6 probeManager  pod pod  readiness  liveness  goroutine \n\n```\nfunc (kl *Kubelet) HandlePodAdditions(pods []*v1.Pod) {\n\tstart := kl.clock.Now()\n\t//  pod  pod \n\tsort.Sort(sliceutils.PodsByCreationTime(pods))\n\tfor _, pod := range pods {\n\t\tif kl.dnsConfigurer != nil && kl.dnsConfigurer.ResolverConfig != \"\" {\n\t\t\tkl.dnsConfigurer.CheckLimitsForResolvConf()\n\t\t}\n\t\texistingPods := kl.podManager.GetPods()\n\t\t//  pod  podManager \n\t\tkl.podManager.AddPod(pod)\n\n\t\t//  mirror pod static pod\n\t\tif kubepod.IsMirrorPod(pod) {\n\t\t\tkl.handleMirrorPod(pod, start)\n\t\t\tcontinue\n\t\t}\n\n\t\tif !kl.podIsTerminated(pod) {\n\t\t\tactivePods := kl.filterOutTerminatedPods(existingPods)\n\t\t\t//  canAdmitPod Pod(:)\n\t\t\t// Check if we can admit the pod; if not, reject it.\n\t\t\tif ok, reason, message := kl.canAdmitPod(activePods, pod); !ok {\n\t\t\t\tkl.rejectPod(pod, reason, message)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t\n\t\tmirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod)\n\t\t//  dispatchWork  pod dispatchWork  UpdatePodOptions UpdatePod .\n\t\tkl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start)\n\t\t//  probeManager  pod pod  readiness  liveness  goroutine \n\t\tkl.probeManager.AddPod(pod)\n\t}\n}\n```\n\n> static pod  kubelet k8s apiserver  static pod  rs  kubelet Kubelet  apiserver  static pod  mirror pod kubectl  pod, kubectl logs static pod \n\n\n### 4dispatchWork\n\ndispatchWorker  Pod // podWorkers\n\n```\nfunc (kl *Kubelet) dispatchWork(pod *v1.Pod, syncType kubetypes.SyncPodType, mirrorPod *v1.Pod, start time.Time) {\n\tif kl.podIsTerminated(pod) {\n\t\tif pod.DeletionTimestamp != nil {\n\t\t\tkl.statusManager.TerminatePod(pod)\n\t\t}\n\t\treturn\n\t}\n\t//  podWorkers \n\tkl.podWorkers.UpdatePod(&UpdatePodOptions{\n\t\tPod:        pod,\n\t\tMirrorPod:  mirrorPod,\n\t\tUpdateType: syncType,\n\t\tOnCompleteFunc: func(err error) {\n\t\t\tif err != nil {\n\t\t\t\tmetrics.PodWorkerLatency.WithLabelValues(syncType.String()).Observe(metrics.SinceInMicroseconds(start))\n\t\t\t}\n\t\t},\n\t})\n\tif syncType == kubetypes.SyncPodCreate {\n\t\tmetrics.ContainersPerPodCount.Observe(float64(len(pod.Spec.Containers)))\n\t}\n}\n```\n\n\n### 5 channelUpdatePod\n\npodWorkers  Pod  Pod  podWorkers  Pod  goroutine  channelgoroutine  channel  podWorkers \n\n\n```\nfunc (p *podWorkers) UpdatePod(options *UpdatePodOptions) {\n\tpod := options.Pod\n\tuid := pod.UID\n\tvar podUpdates chan UpdatePodOptions\n\tvar exists bool\n\n\tp.podLock.Lock()\n\tdefer p.podLock.Unlock()\n\n\t//  pod  goroutine  goroutine channel\n\tif podUpdates, exists = p.podUpdates[uid]; !exists {\n\t\t//  channel\n\t\tpodUpdates = make(chan UpdatePodOptions, 1)\n\t\tp.podUpdates[uid] = podUpdates\n\n\t\t//  goroutine\n\t\tgo func() {\n\t\t\tdefer runtime.HandleCrash()\n\t\t\tp.managePodLoop(podUpdates)\n\t\t}()\n\t}\n\t// \n\tif !p.isWorking[pod.UID] {\n\t\tp.isWorking[pod.UID] = true\n\t\tpodUpdates <- *options\n\t} else {\n\t\tupdate, found := p.lastUndeliveredWorkUpdate[pod.UID]\n\t\tif !found || update.UpdateType != kubetypes.SyncPodKill {\n\t\t\tp.lastUndeliveredWorkUpdate[pod.UID] = *options\n\t\t}\n\t}\n}\n```\n\n### 6 syncPodFn  podmanagePodLoop\nmanagePodLoop  syncPodFn  podsyncPodFn kubelet.SyncPod sync  wrapUp :\n\n-  pod  kubelet  workQueue  pod  sync\n-  sync  update  goroutine  channel \n\n\n```\nfunc (p *podWorkers) managePodLoop(podUpdates <-chan UpdatePodOptions) {\n\tvar lastSyncTime time.Time\n\tfor update := range podUpdates {\n\t\terr := func() error {\n\t\t\tpodUID := update.Pod.UID\n\t\t\tstatus, err := p.podCache.GetNewerThan(podUID, lastSyncTime)\n\t\t\tif err != nil {\n\t\t\t\t...\n\t\t\t}\n\t\t\terr = p.syncPodFn(syncPodOptions{\n\t\t\t\tmirrorPod:      update.MirrorPod,\n\t\t\t\tpod:            update.Pod,\n\t\t\t\tpodStatus:      status,\n\t\t\t\tkillPodOptions: update.KillPodOptions,\n\t\t\t\tupdateType:     update.UpdateType,\n\t\t\t})\n\t\t\tlastSyncTime = time.Now()\n\t\t\treturn err\n\t\t}()\n\t\tif update.OnCompleteFunc != nil {\n\t\t\tupdate.OnCompleteFunc(err)\n\t\t}\n\t\tif err != nil {\n\t\t\t...\n\t\t}\n\t\tp.wrapUp(update.Pod.UID, err)\n\t}\n}\n```\n\n### 7SyncPod\n\n\n\n-  pod\n-  podStatus  kubelet.statusManager\n-  pod  privileged  pod \n-  containerManagar  pod level cgroup Qos level cgroup\n-  static Pod mirrorPod\n-  pod  volume  plugin , pv volume mount volumeManager , image secrets apiserver  secrets \n-  kubelet.volumeManager  pod  volume \n-  container runtime  SyncPod \n\n pod \n\n```\nfunc (kl *Kubelet) syncPod(o syncPodOptions) error {\n\t// pull out the required options\n\tpod := o.pod\n\tmirrorPod := o.mirrorPod\n\tpodStatus := o.podStatus\n\tupdateType := o.updateType\n\n\t//   pod\n\tif updateType == kubetypes.SyncPodKill {\n\t\t...\n\t}\n    ...\n\t//  pod \n\trunnable := kl.canRunPod(pod)\n\tif !runnable.Admit {\n\t\t...\n\t}\n\n\t//  pod \n\tkl.statusManager.SetPodStatus(pod, apiPodStatus)\n\n\t//  pod  running  kill \n\tif !runnable.Admit || pod.DeletionTimestamp != nil || apiPodStatus.Phase == v1.PodFailed {\n\t\t...\n\t}\n\n\t// \n\tif rs := kl.runtimeState.networkErrors(); len(rs) != 0 && !kubecontainer.IsHostNetworkPod(pod) {\n\t\t...\n\t}\n\n\tpcm := kl.containerManager.NewPodContainerManager()\n\tif !kl.podIsTerminated(pod) {\n\t\t...\n\t\t//  pod  cgroups\n\t\tif !(podKilled && pod.Spec.RestartPolicy == v1.RestartPolicyNever) {\n\t\t\tif !pcm.Exists(pod) {\n\t\t\t\t...\n\t\t\t}\n\t\t}\n\t}\n\n\t//  static pod  mirror pod\n\tif kubepod.IsStaticPod(pod) {\n\t\t...\n\t}\n\n\t// \n\tif err := kl.makePodDataDirs(pod); err != nil {\n\t\t...\n\t}\n\n\t//  volume\n\tif !kl.podIsTerminated(pod) {\n\t\tif err := kl.volumeManager.WaitForAttachAndMount(pod); err != nil {\n\t\t\t...\n\t\t}\n\t}\n\n\t//  secret \n\tpullSecrets := kl.getPullSecretsForPod(pod)\n\n\t//  containerRuntime  SyncPod \n\tresult := kl.containerRuntime.SyncPod(pod, apiPodStatus, podStatus, pullSecrets, kl.backOff)\n\tkl.reasonCache.Update(pod.UID, result)\n\tif err := result.Error(); err != nil {\n\t\t...\n\t}\n\n\treturn nil\n}\n```\n\n\n### 8\n\ncontainerRuntimepkg/kubelet/kuberuntime SyncPod  pod \nsyncPod \n- 1 sandbox  container \n- 2 sandbox \n- 3 init \n- 4\n\ninitContainers  container  container  container\n\n```\nfunc (m *kubeGenericRuntimeManager) SyncPod(pod *v1.Pod, _ v1.PodStatus, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, backOff *flowcontrol.Backoff) (result kubecontainer.PodSyncResult) {\n\t// 1 sandbox  container \n\tpodContainerChanges := m.computePodActions(pod, podStatus)\n\tif podContainerChanges.CreateSandbox {\n\t\tref, err := ref.GetReference(legacyscheme.Scheme, pod)\n\t\tif err != nil {\n\t\t\tglog.Errorf(\"Couldn't make a ref to pod %q: '%v'\", format.Pod(pod), err)\n\t\t}\n\t\t...\n\t}\n\n\t// 2kill  sandbox  pod\n\tif podContainerChanges.KillPod {\n\t\t...\n\t} else {\n\t\t// 3kill  running  containers\n\t\t...\n\t\tfor containerID, containerInfo := range podContainerChanges.ContainersToKill {\n\t\t\t...\n\t\t\tif err := m.killContainer(pod, containerID, containerInfo.name, containerInfo.message, nil); err != nil {\n\t\t\t\t...\n\t\t\t}\n\t\t}\n\t}\n\n\tm.pruneInitContainersBeforeStart(pod, podStatus)\n\tpodIP := \"\"\n\tif podStatus != nil {\n\t\tpodIP = podStatus.IP\n\t}\n\n\t// 4 sandbox \n\tpodSandboxID := podContainerChanges.SandboxID\n\tif podContainerChanges.CreateSandbox {\n\t\tpodSandboxID, msg, err = m.createPodSandbox(pod, podContainerChanges.Attempt)\n\t\tif err != nil {\n\t\t\t...\n\t\t}\n\t\t...\n\t\tpodSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID)\n\t\tif err != nil {\n\t\t\t...\n\t\t}\n\t\t//  pod  host  None  kubelet \n\t\tif !kubecontainer.IsHostNetworkPod(pod) {\n\t\t\tpodIP = m.determinePodSandboxIP(pod.Namespace, pod.Name, podSandboxStatus)\n\t\t\tglog.V(4).Infof(\"Determined the ip %q for pod %q after sandbox changed\", podIP, format.Pod(pod))\n\t\t}\n\t}\n\n\tconfigPodSandboxResult := kubecontainer.NewSyncResult(kubecontainer.ConfigPodSandbox, podSandboxID)\n\tresult.AddSyncResult(configPodSandboxResult)\n\t//  PodSandbox (:metadata,clusterDNS,)\n\tpodSandboxConfig, err := m.generatePodSandboxConfig(pod, podContainerChanges.Attempt)\n\t...\n\n\t// 5 init container\n\tif container := podContainerChanges.NextInitContainerToStart; container != nil {\n\t\t...\n\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeInit); err != nil {\n\t\t\t...\n\t\t}\n\t}\n\n\t// 6\n\tfor _, idx := range podContainerChanges.ContainersToStart {\n\t\t...\n\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeRegular); err != nil {\n\t\t\t...\n\t\t}\n\t}\n\t\n\treturn\n}\n```\n\n\n### 9\n\n startContainer \n\n- 1\n- 2\n- 3 docker api \n- 4\n- 5 post start hook\n\n\n```\nfunc (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, container *v1.Container, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, containerType kubecontainer.ContainerType) (string, error) {\n\t// 1 Docker Registry  Private Registry \n\timageRef, msg, err := m.imagePuller.EnsureImageExists(pod, container, pullSecrets)\n\tif err != nil {\n\t\t...\n\t}\n\n\tref, err := kubecontainer.GenerateContainerRef(pod, container)\n\tif err != nil {\n\t\t...\n\t}\n\n\t//  RestartCount \n\trestartCount := 0\n\tcontainerStatus := podStatus.FindContainerStatusByName(container.Name)\n\tif containerStatus != nil {\n\t\trestartCount = containerStatus.RestartCount + 1\n\t}\n\n\t// 2\n\tcontainerConfig, cleanupAction, err := m.generateContainerConfig(container, pod, restartCount, podIP, imageRef, containerType)\n\tif cleanupAction != nil {\n\t\tdefer cleanupAction()\n\t}\n\t...\n\n\t// 3 client.CreateContainer  docker api \n\tcontainerID, err := m.runtimeService.CreateContainer(podSandboxID, containerConfig, podSandboxConfig)\n\tif err != nil {\n\t\t...\n\t}\n\terr = m.internalLifecycle.PreStartContainer(pod, container, containerID)\n\tif err != nil {\n\t\t...\n\t}\n\t...\n\n\t// 3\n\terr = m.runtimeService.StartContainer(containerID)\n\tif err != nil {\n\t\t...\n\t}\n\n\tcontainerMeta := containerConfig.GetMetadata()\n\tsandboxMeta := podSandboxConfig.GetMetadata()\n\tlegacySymlink := legacyLogSymlink(containerID, containerMeta.Name, sandboxMeta.Name,\n\t\tsandboxMeta.Namespace)\n\tcontainerLog := filepath.Join(podSandboxConfig.LogDirectory, containerConfig.LogPath)\n\tif _, err := m.osInterface.Stat(containerLog); !os.IsNotExist(err) {\n\t\tif err := m.osInterface.Symlink(containerLog, legacySymlink); err != nil {\n\t\t\tglog.Errorf(\"Failed to create legacy symbolic link %q to container %q log %q: %v\",\n\t\t\t\tlegacySymlink, containerID, containerLog, err)\n\t\t}\n\t}\n\n\t// 4 post start hook\n\tif container.Lifecycle != nil && container.Lifecycle.PostStart != nil {\n\t\tkubeContainerID := kubecontainer.ContainerID{\n\t\t\tType: m.runtimeName,\n\t\t\tID:   containerID,\n\t\t}\n\t\t// runner.Run \n\t\t//  container hook(PostStart  PreStop),\n\t\t//  container hook \n\t\tmsg, handlerErr := m.runner.Run(kubeContainerID, pod, container, container.Lifecycle.PostStart)\n\t\tif handlerErr != nil {\n\t\t\t...\n\t\t}\n\t}\n\n\treturn \"\", nil\n}\n```\n\n\n## \n\n kubelet kubelet  docker api  kubelet  pod \n\n\n\n[k8s-kubelet](https://sycki.com/articles/kubernetes/k8s-code-kubelet)\n[Kubelet():](https://segmentfault.com/a/1190000008267351)\n[kubelet pod ](http://cizixs.com/2017/06/07/kubelet-source-code-analysis-part-2/)\n[kubeletPod](https://fatsheep9146.github.io/2018/07/22/kubelet%E5%88%9B%E5%BB%BAPod%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/)\n[Kubelet: Pod Lifecycle Event Generator (PLEG) Design-\tproposals](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md)\n\n","slug":"kubelet_create_pod","published":1,"updated":"2019-01-03T01:15:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyt050011tadv44ecob0h","content":"<p> <a href=\"http://blog.tianfeiyu.com/2018/12/23/kubelet_init/\" target=\"_blank\" rel=\"noopener\">kubelet </a> kubelet  pod </p>\n<blockquote>\n<p>kubernetes  v1.12 </p>\n</blockquote>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-78c8272f4b617c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet \"></p>\n<p>kubelet  pod ( pod )SyncLoop</p>\n<p> pod  pod  node  pod  kubelet  handler HandlePods  pod  kubelet kubelet  pod Handler  ADD  kubelet  pod  podStatus pod  volume  update kubelet  pod </p>\n<h2 id=\"kubelet--pod-\"><a href=\"#kubelet--pod-\" class=\"headerlink\" title=\"kubelet  pod \"></a>kubelet  pod </h2><p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-bb6b29bac1ca6c9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet  pod \"></p>\n<h3 id=\"1kubelet-syncLoop\"><a href=\"#1kubelet-syncLoop\" class=\"headerlink\" title=\"1kubelet syncLoop\"></a>1kubelet syncLoop</h3><p>syncLoop  syncTicker  housekeepingTicker pod kubelet  pod  for  syncLoopIterationkubelet  runtimeState  5 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) &#123;</span><br><span class=\"line\">\tglog.Info(&quot;Starting kubelet main sync loop.&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// syncTicker  pod workers</span><br><span class=\"line\">\tsyncTicker := time.NewTicker(time.Second)</span><br><span class=\"line\">\tdefer syncTicker.Stop()</span><br><span class=\"line\">\t//  pod</span><br><span class=\"line\">\thousekeepingTicker := time.NewTicker(housekeepingPeriod)</span><br><span class=\"line\">\tdefer housekeepingTicker.Stop()</span><br><span class=\"line\">\t// pod </span><br><span class=\"line\">\tplegCh := kl.pleg.Watch()</span><br><span class=\"line\">\tconst (</span><br><span class=\"line\">\t\tbase   = 100 * time.Millisecond</span><br><span class=\"line\">\t\tmax    = 5 * time.Second</span><br><span class=\"line\">\t\tfactor = 2</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\tduration := base</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 &#123;</span><br><span class=\"line\">\t\t\ttime.Sleep(duration)</span><br><span class=\"line\">\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))</span><br><span class=\"line\">\t\t\tcontinue</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t\t//  SyncHandler SyncHandler  interface</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-pod-syncLoopIteration\"><a href=\"#2-pod-syncLoopIteration\" class=\"headerlink\" title=\"2 pod syncLoopIteration\"></a>2 pod syncLoopIteration</h3><p>syncLoopIteration  handler </p>\n<ul>\n<li>configCh kubeDeps  PodConfig  watch 3  pod filehttpapiserver pod // channel  pod </li>\n<li>syncCh pod </li>\n<li>houseKeepingChhousekeeping  pod </li>\n<li>plegCh kubelet  pleg  container runtime  channel </li>\n<li>livenessManager.Updates() pod kubelet  Pod restartPolicy </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,</span><br><span class=\"line\">\tsyncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;</span><br><span class=\"line\">\tselect &#123;</span><br><span class=\"line\">\tcase u, open := &lt;-configCh:</span><br><span class=\"line\">\t\tif !open &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;Update channel is closed. Exiting the sync loop.&quot;)</span><br><span class=\"line\">\t\t\treturn false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tswitch u.Op &#123;</span><br><span class=\"line\">\t\tcase kubetypes.ADD:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.UPDATE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.REMOVE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.RECONCILE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.DELETE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.RESTORE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.SET:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase e := &lt;-plegCh:</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase &lt;-syncCh:</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase update := &lt;-kl.livenessManager.Updates():</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase &lt;-housekeepingCh:</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn true</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-podHandlePodAddtions\"><a href=\"#3-podHandlePodAddtions\" class=\"headerlink\" title=\"3 podHandlePodAddtions\"></a>3 podHandlePodAddtions</h3><p> pod</p>\n<ul>\n<li>1 pod  pod </li>\n<li>2 podManager podManager  pod pod  mirrorPod  pod  podManager  pod pod </li>\n<li>3 mirror pod </li>\n<li>4 pod </li>\n<li>5 dispatchWork  pod  podWorkers </li>\n<li>6 probeManager  pod pod  readiness  liveness  goroutine </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) HandlePodAdditions(pods []*v1.Pod) &#123;</span><br><span class=\"line\">\tstart := kl.clock.Now()</span><br><span class=\"line\">\t//  pod  pod </span><br><span class=\"line\">\tsort.Sort(sliceutils.PodsByCreationTime(pods))</span><br><span class=\"line\">\tfor _, pod := range pods &#123;</span><br><span class=\"line\">\t\tif kl.dnsConfigurer != nil &amp;&amp; kl.dnsConfigurer.ResolverConfig != &quot;&quot; &#123;</span><br><span class=\"line\">\t\t\tkl.dnsConfigurer.CheckLimitsForResolvConf()</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\texistingPods := kl.podManager.GetPods()</span><br><span class=\"line\">\t\t//  pod  podManager </span><br><span class=\"line\">\t\tkl.podManager.AddPod(pod)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t//  mirror pod static pod</span><br><span class=\"line\">\t\tif kubepod.IsMirrorPod(pod) &#123;</span><br><span class=\"line\">\t\t\tkl.handleMirrorPod(pod, start)</span><br><span class=\"line\">\t\t\tcontinue</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif !kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\t\tactivePods := kl.filterOutTerminatedPods(existingPods)</span><br><span class=\"line\">\t\t\t//  canAdmitPod Pod(:)</span><br><span class=\"line\">\t\t\t// Check if we can admit the pod; if not, reject it.</span><br><span class=\"line\">\t\t\tif ok, reason, message := kl.canAdmitPod(activePods, pod); !ok &#123;</span><br><span class=\"line\">\t\t\t\tkl.rejectPod(pod, reason, message)</span><br><span class=\"line\">\t\t\t\tcontinue</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tmirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod)</span><br><span class=\"line\">\t\t//  dispatchWork  pod dispatchWork  UpdatePodOptions UpdatePod .</span><br><span class=\"line\">\t\tkl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start)</span><br><span class=\"line\">\t\t//  probeManager  pod pod  readiness  liveness  goroutine </span><br><span class=\"line\">\t\tkl.probeManager.AddPod(pod)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>static pod  kubelet k8s apiserver  static pod  rs  kubelet Kubelet  apiserver  static pod  mirror pod kubectl  pod, kubectl logs static pod </p>\n</blockquote>\n<h3 id=\"4dispatchWork\"><a href=\"#4dispatchWork\" class=\"headerlink\" title=\"4dispatchWork\"></a>4dispatchWork</h3><p>dispatchWorker  Pod // podWorkers</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) dispatchWork(pod *v1.Pod, syncType kubetypes.SyncPodType, mirrorPod *v1.Pod, start time.Time) &#123;</span><br><span class=\"line\">\tif kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\tif pod.DeletionTimestamp != nil &#123;</span><br><span class=\"line\">\t\t\tkl.statusManager.TerminatePod(pod)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//  podWorkers </span><br><span class=\"line\">\tkl.podWorkers.UpdatePod(&amp;UpdatePodOptions&#123;</span><br><span class=\"line\">\t\tPod:        pod,</span><br><span class=\"line\">\t\tMirrorPod:  mirrorPod,</span><br><span class=\"line\">\t\tUpdateType: syncType,</span><br><span class=\"line\">\t\tOnCompleteFunc: func(err error) &#123;</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\tmetrics.PodWorkerLatency.WithLabelValues(syncType.String()).Observe(metrics.SinceInMicroseconds(start))</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">\tif syncType == kubetypes.SyncPodCreate &#123;</span><br><span class=\"line\">\t\tmetrics.ContainersPerPodCount.Observe(float64(len(pod.Spec.Containers)))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"5-channelUpdatePod\"><a href=\"#5-channelUpdatePod\" class=\"headerlink\" title=\"5 channelUpdatePod\"></a>5 channelUpdatePod</h3><p>podWorkers  Pod  Pod  podWorkers  Pod  goroutine  channelgoroutine  channel  podWorkers </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *podWorkers) UpdatePod(options *UpdatePodOptions) &#123;</span><br><span class=\"line\">\tpod := options.Pod</span><br><span class=\"line\">\tuid := pod.UID</span><br><span class=\"line\">\tvar podUpdates chan UpdatePodOptions</span><br><span class=\"line\">\tvar exists bool</span><br><span class=\"line\"></span><br><span class=\"line\">\tp.podLock.Lock()</span><br><span class=\"line\">\tdefer p.podLock.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod  goroutine  goroutine channel</span><br><span class=\"line\">\tif podUpdates, exists = p.podUpdates[uid]; !exists &#123;</span><br><span class=\"line\">\t\t//  channel</span><br><span class=\"line\">\t\tpodUpdates = make(chan UpdatePodOptions, 1)</span><br><span class=\"line\">\t\tp.podUpdates[uid] = podUpdates</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t//  goroutine</span><br><span class=\"line\">\t\tgo func() &#123;</span><br><span class=\"line\">\t\t\tdefer runtime.HandleCrash()</span><br><span class=\"line\">\t\t\tp.managePodLoop(podUpdates)</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif !p.isWorking[pod.UID] &#123;</span><br><span class=\"line\">\t\tp.isWorking[pod.UID] = true</span><br><span class=\"line\">\t\tpodUpdates &lt;- *options</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tupdate, found := p.lastUndeliveredWorkUpdate[pod.UID]</span><br><span class=\"line\">\t\tif !found || update.UpdateType != kubetypes.SyncPodKill &#123;</span><br><span class=\"line\">\t\t\tp.lastUndeliveredWorkUpdate[pod.UID] = *options</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"6-syncPodFn--podmanagePodLoop\"><a href=\"#6-syncPodFn--podmanagePodLoop\" class=\"headerlink\" title=\"6 syncPodFn  podmanagePodLoop\"></a>6 syncPodFn  podmanagePodLoop</h3><p>managePodLoop  syncPodFn  podsyncPodFn kubelet.SyncPod sync  wrapUp :</p>\n<ul>\n<li> pod  kubelet  workQueue  pod  sync</li>\n<li> sync  update  goroutine  channel </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *podWorkers) managePodLoop(podUpdates &lt;-chan UpdatePodOptions) &#123;</span><br><span class=\"line\">\tvar lastSyncTime time.Time</span><br><span class=\"line\">\tfor update := range podUpdates &#123;</span><br><span class=\"line\">\t\terr := func() error &#123;</span><br><span class=\"line\">\t\t\tpodUID := update.Pod.UID</span><br><span class=\"line\">\t\t\tstatus, err := p.podCache.GetNewerThan(podUID, lastSyncTime)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\terr = p.syncPodFn(syncPodOptions&#123;</span><br><span class=\"line\">\t\t\t\tmirrorPod:      update.MirrorPod,</span><br><span class=\"line\">\t\t\t\tpod:            update.Pod,</span><br><span class=\"line\">\t\t\t\tpodStatus:      status,</span><br><span class=\"line\">\t\t\t\tkillPodOptions: update.KillPodOptions,</span><br><span class=\"line\">\t\t\t\tupdateType:     update.UpdateType,</span><br><span class=\"line\">\t\t\t&#125;)</span><br><span class=\"line\">\t\t\tlastSyncTime = time.Now()</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t\tif update.OnCompleteFunc != nil &#123;</span><br><span class=\"line\">\t\t\tupdate.OnCompleteFunc(err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tp.wrapUp(update.Pod.UID, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"7SyncPod\"><a href=\"#7SyncPod\" class=\"headerlink\" title=\"7SyncPod\"></a>7SyncPod</h3><p></p>\n<ul>\n<li> pod</li>\n<li> podStatus  kubelet.statusManager</li>\n<li> pod  privileged  pod </li>\n<li> containerManagar  pod level cgroup Qos level cgroup</li>\n<li> static Pod mirrorPod</li>\n<li> pod  volume  plugin , pv volume mount volumeManager , image secrets apiserver  secrets </li>\n<li> kubelet.volumeManager  pod  volume </li>\n<li> container runtime  SyncPod </li>\n</ul>\n<p> pod </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncPod(o syncPodOptions) error &#123;</span><br><span class=\"line\">\t// pull out the required options</span><br><span class=\"line\">\tpod := o.pod</span><br><span class=\"line\">\tmirrorPod := o.mirrorPod</span><br><span class=\"line\">\tpodStatus := o.podStatus</span><br><span class=\"line\">\tupdateType := o.updateType</span><br><span class=\"line\"></span><br><span class=\"line\">\t//   pod</span><br><span class=\"line\">\tif updateType == kubetypes.SyncPodKill &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">\t//  pod </span><br><span class=\"line\">\trunnable := kl.canRunPod(pod)</span><br><span class=\"line\">\tif !runnable.Admit &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod </span><br><span class=\"line\">\tkl.statusManager.SetPodStatus(pod, apiPodStatus)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod  running  kill </span><br><span class=\"line\">\tif !runnable.Admit || pod.DeletionTimestamp != nil || apiPodStatus.Phase == v1.PodFailed &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif rs := kl.runtimeState.networkErrors(); len(rs) != 0 &amp;&amp; !kubecontainer.IsHostNetworkPod(pod) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tpcm := kl.containerManager.NewPodContainerManager()</span><br><span class=\"line\">\tif !kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t//  pod  cgroups</span><br><span class=\"line\">\t\tif !(podKilled &amp;&amp; pod.Spec.RestartPolicy == v1.RestartPolicyNever) &#123;</span><br><span class=\"line\">\t\t\tif !pcm.Exists(pod) &#123;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  static pod  mirror pod</span><br><span class=\"line\">\tif kubepod.IsStaticPod(pod) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif err := kl.makePodDataDirs(pod); err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  volume</span><br><span class=\"line\">\tif !kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\tif err := kl.volumeManager.WaitForAttachAndMount(pod); err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  secret </span><br><span class=\"line\">\tpullSecrets := kl.getPullSecretsForPod(pod)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  containerRuntime  SyncPod </span><br><span class=\"line\">\tresult := kl.containerRuntime.SyncPod(pod, apiPodStatus, podStatus, pullSecrets, kl.backOff)</span><br><span class=\"line\">\tkl.reasonCache.Update(pod.UID, result)</span><br><span class=\"line\">\tif err := result.Error(); err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"8\"><a href=\"#8\" class=\"headerlink\" title=\"8\"></a>8</h3><p>containerRuntimepkg/kubelet/kuberuntime SyncPod  pod <br>syncPod </p>\n<ul>\n<li>1 sandbox  container </li>\n<li>2 sandbox </li>\n<li>3 init </li>\n<li>4</li>\n</ul>\n<p>initContainers  container  container  container</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *kubeGenericRuntimeManager) SyncPod(pod *v1.Pod, _ v1.PodStatus, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, backOff *flowcontrol.Backoff) (result kubecontainer.PodSyncResult) &#123;</span><br><span class=\"line\">\t// 1 sandbox  container </span><br><span class=\"line\">\tpodContainerChanges := m.computePodActions(pod, podStatus)</span><br><span class=\"line\">\tif podContainerChanges.CreateSandbox &#123;</span><br><span class=\"line\">\t\tref, err := ref.GetReference(legacyscheme.Scheme, pod)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;Couldn&apos;t make a ref to pod %q: &apos;%v&apos;&quot;, format.Pod(pod), err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 2kill  sandbox  pod</span><br><span class=\"line\">\tif podContainerChanges.KillPod &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\t// 3kill  running  containers</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tfor containerID, containerInfo := range podContainerChanges.ContainersToKill &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t\tif err := m.killContainer(pod, containerID, containerInfo.name, containerInfo.message, nil); err != nil &#123;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tm.pruneInitContainersBeforeStart(pod, podStatus)</span><br><span class=\"line\">\tpodIP := &quot;&quot;</span><br><span class=\"line\">\tif podStatus != nil &#123;</span><br><span class=\"line\">\t\tpodIP = podStatus.IP</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 4 sandbox </span><br><span class=\"line\">\tpodSandboxID := podContainerChanges.SandboxID</span><br><span class=\"line\">\tif podContainerChanges.CreateSandbox &#123;</span><br><span class=\"line\">\t\tpodSandboxID, msg, err = m.createPodSandbox(pod, podContainerChanges.Attempt)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tpodSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//  pod  host  None  kubelet </span><br><span class=\"line\">\t\tif !kubecontainer.IsHostNetworkPod(pod) &#123;</span><br><span class=\"line\">\t\t\tpodIP = m.determinePodSandboxIP(pod.Namespace, pod.Name, podSandboxStatus)</span><br><span class=\"line\">\t\t\tglog.V(4).Infof(&quot;Determined the ip %q for pod %q after sandbox changed&quot;, podIP, format.Pod(pod))</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tconfigPodSandboxResult := kubecontainer.NewSyncResult(kubecontainer.ConfigPodSandbox, podSandboxID)</span><br><span class=\"line\">\tresult.AddSyncResult(configPodSandboxResult)</span><br><span class=\"line\">\t//  PodSandbox (:metadata,clusterDNS,)</span><br><span class=\"line\">\tpodSandboxConfig, err := m.generatePodSandboxConfig(pod, podContainerChanges.Attempt)</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 5 init container</span><br><span class=\"line\">\tif container := podContainerChanges.NextInitContainerToStart; container != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeInit); err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 6</span><br><span class=\"line\">\tfor _, idx := range podContainerChanges.ContainersToStart &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeRegular); err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\treturn</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"9\"><a href=\"#9\" class=\"headerlink\" title=\"9\"></a>9</h3><p> startContainer </p>\n<ul>\n<li>1</li>\n<li>2</li>\n<li>3 docker api </li>\n<li>4</li>\n<li>5 post start hook</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, container *v1.Container, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, containerType kubecontainer.ContainerType) (string, error) &#123;</span><br><span class=\"line\">\t// 1 Docker Registry  Private Registry </span><br><span class=\"line\">\timageRef, msg, err := m.imagePuller.EnsureImageExists(pod, container, pullSecrets)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tref, err := kubecontainer.GenerateContainerRef(pod, container)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  RestartCount </span><br><span class=\"line\">\trestartCount := 0</span><br><span class=\"line\">\tcontainerStatus := podStatus.FindContainerStatusByName(container.Name)</span><br><span class=\"line\">\tif containerStatus != nil &#123;</span><br><span class=\"line\">\t\trestartCount = containerStatus.RestartCount + 1</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 2</span><br><span class=\"line\">\tcontainerConfig, cleanupAction, err := m.generateContainerConfig(container, pod, restartCount, podIP, imageRef, containerType)</span><br><span class=\"line\">\tif cleanupAction != nil &#123;</span><br><span class=\"line\">\t\tdefer cleanupAction()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 3 client.CreateContainer  docker api </span><br><span class=\"line\">\tcontainerID, err := m.runtimeService.CreateContainer(podSandboxID, containerConfig, podSandboxConfig)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\terr = m.internalLifecycle.PreStartContainer(pod, container, containerID)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 3</span><br><span class=\"line\">\terr = m.runtimeService.StartContainer(containerID)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tcontainerMeta := containerConfig.GetMetadata()</span><br><span class=\"line\">\tsandboxMeta := podSandboxConfig.GetMetadata()</span><br><span class=\"line\">\tlegacySymlink := legacyLogSymlink(containerID, containerMeta.Name, sandboxMeta.Name,</span><br><span class=\"line\">\t\tsandboxMeta.Namespace)</span><br><span class=\"line\">\tcontainerLog := filepath.Join(podSandboxConfig.LogDirectory, containerConfig.LogPath)</span><br><span class=\"line\">\tif _, err := m.osInterface.Stat(containerLog); !os.IsNotExist(err) &#123;</span><br><span class=\"line\">\t\tif err := m.osInterface.Symlink(containerLog, legacySymlink); err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;Failed to create legacy symbolic link %q to container %q log %q: %v&quot;,</span><br><span class=\"line\">\t\t\t\tlegacySymlink, containerID, containerLog, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 4 post start hook</span><br><span class=\"line\">\tif container.Lifecycle != nil &amp;&amp; container.Lifecycle.PostStart != nil &#123;</span><br><span class=\"line\">\t\tkubeContainerID := kubecontainer.ContainerID&#123;</span><br><span class=\"line\">\t\t\tType: m.runtimeName,</span><br><span class=\"line\">\t\t\tID:   containerID,</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t// runner.Run </span><br><span class=\"line\">\t\t//  container hook(PostStart  PreStop),</span><br><span class=\"line\">\t\t//  container hook </span><br><span class=\"line\">\t\tmsg, handlerErr := m.runner.Run(kubeContainerID, pod, container, container.Lifecycle.PostStart)</span><br><span class=\"line\">\t\tif handlerErr != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn &quot;&quot;, nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> kubelet kubelet  docker api  kubelet  pod </p>\n<p><br><a href=\"https://sycki.com/articles/kubernetes/k8s-code-kubelet\" target=\"_blank\" rel=\"noopener\">k8s-kubelet</a><br><a href=\"https://segmentfault.com/a/1190000008267351\" target=\"_blank\" rel=\"noopener\">Kubelet():</a><br><a href=\"http://cizixs.com/2017/06/07/kubelet-source-code-analysis-part-2/\" target=\"_blank\" rel=\"noopener\">kubelet pod </a><br><a href=\"https://fatsheep9146.github.io/2018/07/22/kubelet%E5%88%9B%E5%BB%BAPod%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/\" target=\"_blank\" rel=\"noopener\">kubeletPod</a><br><a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md\" target=\"_blank\" rel=\"noopener\">Kubelet: Pod Lifecycle Event Generator (PLEG) Design-    proposals</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p> <a href=\"http://blog.tianfeiyu.com/2018/12/23/kubelet_init/\" target=\"_blank\" rel=\"noopener\">kubelet </a> kubelet  pod </p>\n<blockquote>\n<p>kubernetes  v1.12 </p>\n</blockquote>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-78c8272f4b617c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet \"></p>\n<p>kubelet  pod ( pod )SyncLoop</p>\n<p> pod  pod  node  pod  kubelet  handler HandlePods  pod  kubelet kubelet  pod Handler  ADD  kubelet  pod  podStatus pod  volume  update kubelet  pod </p>\n<h2 id=\"kubelet--pod-\"><a href=\"#kubelet--pod-\" class=\"headerlink\" title=\"kubelet  pod \"></a>kubelet  pod </h2><p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-bb6b29bac1ca6c9d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet  pod \"></p>\n<h3 id=\"1kubelet-syncLoop\"><a href=\"#1kubelet-syncLoop\" class=\"headerlink\" title=\"1kubelet syncLoop\"></a>1kubelet syncLoop</h3><p>syncLoop  syncTicker  housekeepingTicker pod kubelet  pod  for  syncLoopIterationkubelet  runtimeState  5 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) &#123;</span><br><span class=\"line\">\tglog.Info(&quot;Starting kubelet main sync loop.&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// syncTicker  pod workers</span><br><span class=\"line\">\tsyncTicker := time.NewTicker(time.Second)</span><br><span class=\"line\">\tdefer syncTicker.Stop()</span><br><span class=\"line\">\t//  pod</span><br><span class=\"line\">\thousekeepingTicker := time.NewTicker(housekeepingPeriod)</span><br><span class=\"line\">\tdefer housekeepingTicker.Stop()</span><br><span class=\"line\">\t// pod </span><br><span class=\"line\">\tplegCh := kl.pleg.Watch()</span><br><span class=\"line\">\tconst (</span><br><span class=\"line\">\t\tbase   = 100 * time.Millisecond</span><br><span class=\"line\">\t\tmax    = 5 * time.Second</span><br><span class=\"line\">\t\tfactor = 2</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\tduration := base</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 &#123;</span><br><span class=\"line\">\t\t\ttime.Sleep(duration)</span><br><span class=\"line\">\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))</span><br><span class=\"line\">\t\t\tcontinue</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">        ...</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t\t//  SyncHandler SyncHandler  interface</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-pod-syncLoopIteration\"><a href=\"#2-pod-syncLoopIteration\" class=\"headerlink\" title=\"2 pod syncLoopIteration\"></a>2 pod syncLoopIteration</h3><p>syncLoopIteration  handler </p>\n<ul>\n<li>configCh kubeDeps  PodConfig  watch 3  pod filehttpapiserver pod // channel  pod </li>\n<li>syncCh pod </li>\n<li>houseKeepingChhousekeeping  pod </li>\n<li>plegCh kubelet  pleg  container runtime  channel </li>\n<li>livenessManager.Updates() pod kubelet  Pod restartPolicy </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncLoopIteration(configCh &lt;-chan kubetypes.PodUpdate, handler SyncHandler,</span><br><span class=\"line\">\tsyncCh &lt;-chan time.Time, housekeepingCh &lt;-chan time.Time, plegCh &lt;-chan *pleg.PodLifecycleEvent) bool &#123;</span><br><span class=\"line\">\tselect &#123;</span><br><span class=\"line\">\tcase u, open := &lt;-configCh:</span><br><span class=\"line\">\t\tif !open &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;Update channel is closed. Exiting the sync loop.&quot;)</span><br><span class=\"line\">\t\t\treturn false</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tswitch u.Op &#123;</span><br><span class=\"line\">\t\tcase kubetypes.ADD:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.UPDATE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.REMOVE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.RECONCILE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.DELETE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.RESTORE:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\tcase kubetypes.SET:</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase e := &lt;-plegCh:</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase &lt;-syncCh:</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase update := &lt;-kl.livenessManager.Updates():</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\tcase &lt;-housekeepingCh:</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\treturn true</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-podHandlePodAddtions\"><a href=\"#3-podHandlePodAddtions\" class=\"headerlink\" title=\"3 podHandlePodAddtions\"></a>3 podHandlePodAddtions</h3><p> pod</p>\n<ul>\n<li>1 pod  pod </li>\n<li>2 podManager podManager  pod pod  mirrorPod  pod  podManager  pod pod </li>\n<li>3 mirror pod </li>\n<li>4 pod </li>\n<li>5 dispatchWork  pod  podWorkers </li>\n<li>6 probeManager  pod pod  readiness  liveness  goroutine </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) HandlePodAdditions(pods []*v1.Pod) &#123;</span><br><span class=\"line\">\tstart := kl.clock.Now()</span><br><span class=\"line\">\t//  pod  pod </span><br><span class=\"line\">\tsort.Sort(sliceutils.PodsByCreationTime(pods))</span><br><span class=\"line\">\tfor _, pod := range pods &#123;</span><br><span class=\"line\">\t\tif kl.dnsConfigurer != nil &amp;&amp; kl.dnsConfigurer.ResolverConfig != &quot;&quot; &#123;</span><br><span class=\"line\">\t\t\tkl.dnsConfigurer.CheckLimitsForResolvConf()</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\texistingPods := kl.podManager.GetPods()</span><br><span class=\"line\">\t\t//  pod  podManager </span><br><span class=\"line\">\t\tkl.podManager.AddPod(pod)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t//  mirror pod static pod</span><br><span class=\"line\">\t\tif kubepod.IsMirrorPod(pod) &#123;</span><br><span class=\"line\">\t\t\tkl.handleMirrorPod(pod, start)</span><br><span class=\"line\">\t\t\tcontinue</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif !kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\t\tactivePods := kl.filterOutTerminatedPods(existingPods)</span><br><span class=\"line\">\t\t\t//  canAdmitPod Pod(:)</span><br><span class=\"line\">\t\t\t// Check if we can admit the pod; if not, reject it.</span><br><span class=\"line\">\t\t\tif ok, reason, message := kl.canAdmitPod(activePods, pod); !ok &#123;</span><br><span class=\"line\">\t\t\t\tkl.rejectPod(pod, reason, message)</span><br><span class=\"line\">\t\t\t\tcontinue</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tmirrorPod, _ := kl.podManager.GetMirrorPodByPod(pod)</span><br><span class=\"line\">\t\t//  dispatchWork  pod dispatchWork  UpdatePodOptions UpdatePod .</span><br><span class=\"line\">\t\tkl.dispatchWork(pod, kubetypes.SyncPodCreate, mirrorPod, start)</span><br><span class=\"line\">\t\t//  probeManager  pod pod  readiness  liveness  goroutine </span><br><span class=\"line\">\t\tkl.probeManager.AddPod(pod)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>static pod  kubelet k8s apiserver  static pod  rs  kubelet Kubelet  apiserver  static pod  mirror pod kubectl  pod, kubectl logs static pod </p>\n</blockquote>\n<h3 id=\"4dispatchWork\"><a href=\"#4dispatchWork\" class=\"headerlink\" title=\"4dispatchWork\"></a>4dispatchWork</h3><p>dispatchWorker  Pod // podWorkers</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) dispatchWork(pod *v1.Pod, syncType kubetypes.SyncPodType, mirrorPod *v1.Pod, start time.Time) &#123;</span><br><span class=\"line\">\tif kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\tif pod.DeletionTimestamp != nil &#123;</span><br><span class=\"line\">\t\t\tkl.statusManager.TerminatePod(pod)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t//  podWorkers </span><br><span class=\"line\">\tkl.podWorkers.UpdatePod(&amp;UpdatePodOptions&#123;</span><br><span class=\"line\">\t\tPod:        pod,</span><br><span class=\"line\">\t\tMirrorPod:  mirrorPod,</span><br><span class=\"line\">\t\tUpdateType: syncType,</span><br><span class=\"line\">\t\tOnCompleteFunc: func(err error) &#123;</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\tmetrics.PodWorkerLatency.WithLabelValues(syncType.String()).Observe(metrics.SinceInMicroseconds(start))</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t&#125;)</span><br><span class=\"line\">\tif syncType == kubetypes.SyncPodCreate &#123;</span><br><span class=\"line\">\t\tmetrics.ContainersPerPodCount.Observe(float64(len(pod.Spec.Containers)))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"5-channelUpdatePod\"><a href=\"#5-channelUpdatePod\" class=\"headerlink\" title=\"5 channelUpdatePod\"></a>5 channelUpdatePod</h3><p>podWorkers  Pod  Pod  podWorkers  Pod  goroutine  channelgoroutine  channel  podWorkers </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *podWorkers) UpdatePod(options *UpdatePodOptions) &#123;</span><br><span class=\"line\">\tpod := options.Pod</span><br><span class=\"line\">\tuid := pod.UID</span><br><span class=\"line\">\tvar podUpdates chan UpdatePodOptions</span><br><span class=\"line\">\tvar exists bool</span><br><span class=\"line\"></span><br><span class=\"line\">\tp.podLock.Lock()</span><br><span class=\"line\">\tdefer p.podLock.Unlock()</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod  goroutine  goroutine channel</span><br><span class=\"line\">\tif podUpdates, exists = p.podUpdates[uid]; !exists &#123;</span><br><span class=\"line\">\t\t//  channel</span><br><span class=\"line\">\t\tpodUpdates = make(chan UpdatePodOptions, 1)</span><br><span class=\"line\">\t\tp.podUpdates[uid] = podUpdates</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t//  goroutine</span><br><span class=\"line\">\t\tgo func() &#123;</span><br><span class=\"line\">\t\t\tdefer runtime.HandleCrash()</span><br><span class=\"line\">\t\t\tp.managePodLoop(podUpdates)</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif !p.isWorking[pod.UID] &#123;</span><br><span class=\"line\">\t\tp.isWorking[pod.UID] = true</span><br><span class=\"line\">\t\tpodUpdates &lt;- *options</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\tupdate, found := p.lastUndeliveredWorkUpdate[pod.UID]</span><br><span class=\"line\">\t\tif !found || update.UpdateType != kubetypes.SyncPodKill &#123;</span><br><span class=\"line\">\t\t\tp.lastUndeliveredWorkUpdate[pod.UID] = *options</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"6-syncPodFn--podmanagePodLoop\"><a href=\"#6-syncPodFn--podmanagePodLoop\" class=\"headerlink\" title=\"6 syncPodFn  podmanagePodLoop\"></a>6 syncPodFn  podmanagePodLoop</h3><p>managePodLoop  syncPodFn  podsyncPodFn kubelet.SyncPod sync  wrapUp :</p>\n<ul>\n<li> pod  kubelet  workQueue  pod  sync</li>\n<li> sync  update  goroutine  channel </li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (p *podWorkers) managePodLoop(podUpdates &lt;-chan UpdatePodOptions) &#123;</span><br><span class=\"line\">\tvar lastSyncTime time.Time</span><br><span class=\"line\">\tfor update := range podUpdates &#123;</span><br><span class=\"line\">\t\terr := func() error &#123;</span><br><span class=\"line\">\t\t\tpodUID := update.Pod.UID</span><br><span class=\"line\">\t\t\tstatus, err := p.podCache.GetNewerThan(podUID, lastSyncTime)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\terr = p.syncPodFn(syncPodOptions&#123;</span><br><span class=\"line\">\t\t\t\tmirrorPod:      update.MirrorPod,</span><br><span class=\"line\">\t\t\t\tpod:            update.Pod,</span><br><span class=\"line\">\t\t\t\tpodStatus:      status,</span><br><span class=\"line\">\t\t\t\tkillPodOptions: update.KillPodOptions,</span><br><span class=\"line\">\t\t\t\tupdateType:     update.UpdateType,</span><br><span class=\"line\">\t\t\t&#125;)</span><br><span class=\"line\">\t\t\tlastSyncTime = time.Now()</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;()</span><br><span class=\"line\">\t\tif update.OnCompleteFunc != nil &#123;</span><br><span class=\"line\">\t\t\tupdate.OnCompleteFunc(err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tp.wrapUp(update.Pod.UID, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"7SyncPod\"><a href=\"#7SyncPod\" class=\"headerlink\" title=\"7SyncPod\"></a>7SyncPod</h3><p></p>\n<ul>\n<li> pod</li>\n<li> podStatus  kubelet.statusManager</li>\n<li> pod  privileged  pod </li>\n<li> containerManagar  pod level cgroup Qos level cgroup</li>\n<li> static Pod mirrorPod</li>\n<li> pod  volume  plugin , pv volume mount volumeManager , image secrets apiserver  secrets </li>\n<li> kubelet.volumeManager  pod  volume </li>\n<li> container runtime  SyncPod </li>\n</ul>\n<p> pod </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncPod(o syncPodOptions) error &#123;</span><br><span class=\"line\">\t// pull out the required options</span><br><span class=\"line\">\tpod := o.pod</span><br><span class=\"line\">\tmirrorPod := o.mirrorPod</span><br><span class=\"line\">\tpodStatus := o.podStatus</span><br><span class=\"line\">\tupdateType := o.updateType</span><br><span class=\"line\"></span><br><span class=\"line\">\t//   pod</span><br><span class=\"line\">\tif updateType == kubetypes.SyncPodKill &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">\t//  pod </span><br><span class=\"line\">\trunnable := kl.canRunPod(pod)</span><br><span class=\"line\">\tif !runnable.Admit &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod </span><br><span class=\"line\">\tkl.statusManager.SetPodStatus(pod, apiPodStatus)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod  running  kill </span><br><span class=\"line\">\tif !runnable.Admit || pod.DeletionTimestamp != nil || apiPodStatus.Phase == v1.PodFailed &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif rs := kl.runtimeState.networkErrors(); len(rs) != 0 &amp;&amp; !kubecontainer.IsHostNetworkPod(pod) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tpcm := kl.containerManager.NewPodContainerManager()</span><br><span class=\"line\">\tif !kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t//  pod  cgroups</span><br><span class=\"line\">\t\tif !(podKilled &amp;&amp; pod.Spec.RestartPolicy == v1.RestartPolicyNever) &#123;</span><br><span class=\"line\">\t\t\tif !pcm.Exists(pod) &#123;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  static pod  mirror pod</span><br><span class=\"line\">\tif kubepod.IsStaticPod(pod) &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif err := kl.makePodDataDirs(pod); err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  volume</span><br><span class=\"line\">\tif !kl.podIsTerminated(pod) &#123;</span><br><span class=\"line\">\t\tif err := kl.volumeManager.WaitForAttachAndMount(pod); err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  secret </span><br><span class=\"line\">\tpullSecrets := kl.getPullSecretsForPod(pod)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  containerRuntime  SyncPod </span><br><span class=\"line\">\tresult := kl.containerRuntime.SyncPod(pod, apiPodStatus, podStatus, pullSecrets, kl.backOff)</span><br><span class=\"line\">\tkl.reasonCache.Update(pod.UID, result)</span><br><span class=\"line\">\tif err := result.Error(); err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"8\"><a href=\"#8\" class=\"headerlink\" title=\"8\"></a>8</h3><p>containerRuntimepkg/kubelet/kuberuntime SyncPod  pod <br>syncPod </p>\n<ul>\n<li>1 sandbox  container </li>\n<li>2 sandbox </li>\n<li>3 init </li>\n<li>4</li>\n</ul>\n<p>initContainers  container  container  container</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *kubeGenericRuntimeManager) SyncPod(pod *v1.Pod, _ v1.PodStatus, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, backOff *flowcontrol.Backoff) (result kubecontainer.PodSyncResult) &#123;</span><br><span class=\"line\">\t// 1 sandbox  container </span><br><span class=\"line\">\tpodContainerChanges := m.computePodActions(pod, podStatus)</span><br><span class=\"line\">\tif podContainerChanges.CreateSandbox &#123;</span><br><span class=\"line\">\t\tref, err := ref.GetReference(legacyscheme.Scheme, pod)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;Couldn&apos;t make a ref to pod %q: &apos;%v&apos;&quot;, format.Pod(pod), err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 2kill  sandbox  pod</span><br><span class=\"line\">\tif podContainerChanges.KillPod &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">\t\t// 3kill  running  containers</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tfor containerID, containerInfo := range podContainerChanges.ContainersToKill &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t\tif err := m.killContainer(pod, containerID, containerInfo.name, containerInfo.message, nil); err != nil &#123;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tm.pruneInitContainersBeforeStart(pod, podStatus)</span><br><span class=\"line\">\tpodIP := &quot;&quot;</span><br><span class=\"line\">\tif podStatus != nil &#123;</span><br><span class=\"line\">\t\tpodIP = podStatus.IP</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 4 sandbox </span><br><span class=\"line\">\tpodSandboxID := podContainerChanges.SandboxID</span><br><span class=\"line\">\tif podContainerChanges.CreateSandbox &#123;</span><br><span class=\"line\">\t\tpodSandboxID, msg, err = m.createPodSandbox(pod, podContainerChanges.Attempt)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tpodSandboxStatus, err := m.runtimeService.PodSandboxStatus(podSandboxID)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//  pod  host  None  kubelet </span><br><span class=\"line\">\t\tif !kubecontainer.IsHostNetworkPod(pod) &#123;</span><br><span class=\"line\">\t\t\tpodIP = m.determinePodSandboxIP(pod.Namespace, pod.Name, podSandboxStatus)</span><br><span class=\"line\">\t\t\tglog.V(4).Infof(&quot;Determined the ip %q for pod %q after sandbox changed&quot;, podIP, format.Pod(pod))</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tconfigPodSandboxResult := kubecontainer.NewSyncResult(kubecontainer.ConfigPodSandbox, podSandboxID)</span><br><span class=\"line\">\tresult.AddSyncResult(configPodSandboxResult)</span><br><span class=\"line\">\t//  PodSandbox (:metadata,clusterDNS,)</span><br><span class=\"line\">\tpodSandboxConfig, err := m.generatePodSandboxConfig(pod, podContainerChanges.Attempt)</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 5 init container</span><br><span class=\"line\">\tif container := podContainerChanges.NextInitContainerToStart; container != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeInit); err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 6</span><br><span class=\"line\">\tfor _, idx := range podContainerChanges.ContainersToStart &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tif msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, kubecontainer.ContainerTypeRegular); err != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\treturn</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"9\"><a href=\"#9\" class=\"headerlink\" title=\"9\"></a>9</h3><p> startContainer </p>\n<ul>\n<li>1</li>\n<li>2</li>\n<li>3 docker api </li>\n<li>4</li>\n<li>5 post start hook</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, container *v1.Container, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, containerType kubecontainer.ContainerType) (string, error) &#123;</span><br><span class=\"line\">\t// 1 Docker Registry  Private Registry </span><br><span class=\"line\">\timageRef, msg, err := m.imagePuller.EnsureImageExists(pod, container, pullSecrets)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tref, err := kubecontainer.GenerateContainerRef(pod, container)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  RestartCount </span><br><span class=\"line\">\trestartCount := 0</span><br><span class=\"line\">\tcontainerStatus := podStatus.FindContainerStatusByName(container.Name)</span><br><span class=\"line\">\tif containerStatus != nil &#123;</span><br><span class=\"line\">\t\trestartCount = containerStatus.RestartCount + 1</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 2</span><br><span class=\"line\">\tcontainerConfig, cleanupAction, err := m.generateContainerConfig(container, pod, restartCount, podIP, imageRef, containerType)</span><br><span class=\"line\">\tif cleanupAction != nil &#123;</span><br><span class=\"line\">\t\tdefer cleanupAction()</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 3 client.CreateContainer  docker api </span><br><span class=\"line\">\tcontainerID, err := m.runtimeService.CreateContainer(podSandboxID, containerConfig, podSandboxConfig)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\terr = m.internalLifecycle.PreStartContainer(pod, container, containerID)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 3</span><br><span class=\"line\">\terr = m.runtimeService.StartContainer(containerID)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tcontainerMeta := containerConfig.GetMetadata()</span><br><span class=\"line\">\tsandboxMeta := podSandboxConfig.GetMetadata()</span><br><span class=\"line\">\tlegacySymlink := legacyLogSymlink(containerID, containerMeta.Name, sandboxMeta.Name,</span><br><span class=\"line\">\t\tsandboxMeta.Namespace)</span><br><span class=\"line\">\tcontainerLog := filepath.Join(podSandboxConfig.LogDirectory, containerConfig.LogPath)</span><br><span class=\"line\">\tif _, err := m.osInterface.Stat(containerLog); !os.IsNotExist(err) &#123;</span><br><span class=\"line\">\t\tif err := m.osInterface.Symlink(containerLog, legacySymlink); err != nil &#123;</span><br><span class=\"line\">\t\t\tglog.Errorf(&quot;Failed to create legacy symbolic link %q to container %q log %q: %v&quot;,</span><br><span class=\"line\">\t\t\t\tlegacySymlink, containerID, containerLog, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// 4 post start hook</span><br><span class=\"line\">\tif container.Lifecycle != nil &amp;&amp; container.Lifecycle.PostStart != nil &#123;</span><br><span class=\"line\">\t\tkubeContainerID := kubecontainer.ContainerID&#123;</span><br><span class=\"line\">\t\t\tType: m.runtimeName,</span><br><span class=\"line\">\t\t\tID:   containerID,</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t// runner.Run </span><br><span class=\"line\">\t\t//  container hook(PostStart  PreStop),</span><br><span class=\"line\">\t\t//  container hook </span><br><span class=\"line\">\t\tmsg, handlerErr := m.runner.Run(kubeContainerID, pod, container, container.Lifecycle.PostStart)</span><br><span class=\"line\">\t\tif handlerErr != nil &#123;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn &quot;&quot;, nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> kubelet kubelet  docker api  kubelet  pod </p>\n<p><br><a href=\"https://sycki.com/articles/kubernetes/k8s-code-kubelet\" target=\"_blank\" rel=\"noopener\">k8s-kubelet</a><br><a href=\"https://segmentfault.com/a/1190000008267351\" target=\"_blank\" rel=\"noopener\">Kubelet():</a><br><a href=\"http://cizixs.com/2017/06/07/kubelet-source-code-analysis-part-2/\" target=\"_blank\" rel=\"noopener\">kubelet pod </a><br><a href=\"https://fatsheep9146.github.io/2018/07/22/kubelet%E5%88%9B%E5%BB%BAPod%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/\" target=\"_blank\" rel=\"noopener\">kubeletPod</a><br><a href=\"https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/pod-lifecycle-event-generator.md\" target=\"_blank\" rel=\"noopener\">Kubelet: Pod Lifecycle Event Generator (PLEG) Design-    proposals</a></p>\n"},{"title":"kubelet ","date":"2018-12-23T13:22:30.000Z","type":"kubelet","_content":"\n[kubelet ](https://blog.tianfeiyu.com/2018/12/16/kubelet-modules/)  kubelet  kubelet \n\n > kubernetes  v1.12 \n\n\n## kubelet \n\nkubelet :\n\n```\n  kubernetes git:(release-1.12)  tree cmd/kubelet\ncmd/kubelet\n BUILD\n OWNERS\n app\n  BUILD\n  OWNERS\n  auth.go\n  init_others.go\n  init_windows.go\n  options\n   BUILD\n   container_runtime.go\n   globalflags.go\n   globalflags_linux.go\n   globalflags_other.go\n   options.go\n   options_test.go\n   osflags_others.go\n   osflags_windows.go\n  plugins.go\n  server.go\n  server_linux.go\n  server_test.go\n  server_unsupported.go\n kubelet.go\n\n2 directories, 22 files\n```\n\n![kubelet ](https://upload-images.jianshu.io/upload_images/1262158-bdeb34a5cdda93d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### 1kubelet  maincmd/kubelet/kubelet.go\n\n```\nfunc main() {\n\trand.Seed(time.Now().UTC().UnixNano())\n\n\tcommand := app.NewKubeletCommand(server.SetupSignalHandler())\n\tlogs.InitLogs()\n\tdefer logs.FlushLogs()\n\n\tif err := command.Execute(); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"%v\\n\", err)\n\t\tos.Exit(1)\n\t}\n}\n```\n\n#### 2 kubelet cmd/kubelet/app/server.go\n\nNewKubeletCommand()   \n\n```\n// NewKubeletCommand creates a *cobra.Command object with default parameters\nfunc NewKubeletCommand(stopCh <-chan struct{}) *cobra.Command {\n    cleanFlagSet := pflag.NewFlagSet(componentKubelet, pflag.ContinueOnError)\n    cleanFlagSet.SetNormalizeFunc(flag.WordSepNormalizeFunc)\n    // Kubelet:\n    // KubeletFlag:  kubelet  Nodes \n    // KubeletConfiguration: Nodes\n    kubeletFlags := options.NewKubeletFlags()\n\tkubeletConfig, err := options.NewKubeletConfiguration()\n\t...\n\tcmd := &cobra.Command{\n\t\t...\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\t//  kubelet \n\t\t\tif configFile := kubeletFlags.KubeletConfigFile; len(configFile) > 0 {\n\t\t\t\tkubeletConfig, err = loadConfigFile(configFile)\n\t\t\t\tif err != nil {\n\t\t\t\t\tglog.Fatal(err)\n\t\t\t\t}\n\t\t\t\t...\n\t\t\t}\n\t\t\t//  kubelet \n\t\t\tif err := kubeletconfigvalidation.ValidateKubeletConfiguration(kubeletConfig); err != nil {\n\t\t\t\tglog.Fatal(err)\n\t\t\t}\n\t\t\t...\n\t\t\t//  kubeletDeps\n\t\t\tkubeletDeps, err := UnsecuredDependencies(kubeletServer)\n\t\t\tif err != nil {\n\t\t\t\tglog.Fatal(err)\n\t\t\t}\n\t\t\t...\n\t\t\t// \n\t\t\tif err := Run(kubeletServer, kubeletDeps, stopCh); err != nil {\n\t\t\t\tglog.Fatal(err)\n\t\t\t}\n\t\t},\n\t}\n    ...\n\treturn cmd\n}\n```\nkubeletDeps  kubelet  dependency injection kubelet  kubelet cadvisorcgroup containerManager\n\nNewKubeletCommand()  Run() Run()  run() \n\n#### 3 apiserver cmd/kubelet/app/server.go\n\nrun() \n\n- 1 kubeClientevnetClient  apiserver  heartbeatClient  apiserver \n- 2 kubeDeps \n- 3 Healthz  http server 10248\n\n```\nfunc run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh <-chan struct{}) (err error) {\n\t...\n\t//  kubelet \n\tif standaloneMode {\n\t...\n\t} else if kubeDeps.KubeClient == nil || kubeDeps.EventClient == nil || kubeDeps.HeartbeatClient == nil || kubeDeps.DynamicKubeClient == nil {\n\t\t...\n\t\t//  kubeClient\n\t\tkubeClient, err = clientset.NewForConfig(clientConfig)\n\n\t\t...\n        //  evnetClient\n\t\teventClient, err = v1core.NewForConfig(&eventClientConfig)\n\t\t...\n\t\t// heartbeatClient \n\t\theartbeatClient, err = clientset.NewForConfig(&heartbeatClientConfig)\n\t\t...\n\t}\n\n\t//  kubeDeps \n\tif kubeDeps.Auth == nil {\n\t\t\tauth, err := BuildAuth(nodeName, kubeDeps.KubeClient, s.KubeletConfiguration)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tkubeDeps.Auth = auth\n\t\t}\n\n\t\tif kubeDeps.CAdvisorInterface == nil {\n\t\t\timageFsInfoProvider := cadvisor.NewImageFsInfoProvider(s.ContainerRuntime, s.RemoteRuntimeEndpoint)\n\t\t\tkubeDeps.CAdvisorInterface, err = cadvisor.New(imageFsInfoProvider, s.RootDirectory, cadvisor.UsingLegacyCadvisorStats(s.ContainerRuntime, s.RemoteRuntimeEndpoint))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// \n\tif err := RunKubelet(s, kubeDeps, s.RunOnce); err != nil {\n\t\t\treturn err\n\t}\n\t...\n\t//  Healthz  http server  \n\tif s.HealthzPort > 0 {\n\t\thealthz.DefaultHealthz()\n\t\tgo wait.Until(func() {\n\t\t\terr := http.ListenAndServe(net.JoinHostPort(s.HealthzBindAddress, strconv.Itoa(int(s.HealthzPort))), nil)\n\t\t\tif err != nil {\n\t\t\t\tglog.Errorf(\"Starting health server failed: %v\", err)\n\t\t\t}\n\t\t}, 5*time.Second, wait.NeverStop)\n\t}\n\t...\n}\n```\nkubelet  pod  /etc/kubernetes/manifests  URL  watch kube-apiserver  kubelet  standalone  standalone  kubelet \n\nrun()  RunKubelet() \n\n#### 4 kubelet cmd/kubelet/app/server.go\n\nRunKubelet()  \n\n- 1 kubelet  kubelet \n- 2\n\n```\nfunc RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error {\n    ...\n\n \t//  kubelet \n\tk, err := CreateAndInitKubelet(&kubeServer.KubeletConfiguration,\n\t\tkubeDeps,\n\t\t&kubeServer.ContainerRuntimeOptions,\n\t\tkubeServer.ContainerRuntime,\n\t\tkubeServer.RuntimeCgroups,\n\t\tkubeServer.HostnameOverride,\n\t\tkubeServer.NodeIP,\n\t\tkubeServer.ProviderID,\n\t\tkubeServer.CloudProvider,\n\t\tkubeServer.CertDirectory,\n\t\tkubeServer.RootDirectory,\n\t\tkubeServer.RegisterNode,\n\t\tkubeServer.RegisterWithTaints,\n\t\tkubeServer.AllowedUnsafeSysctls,\n\t\tkubeServer.RemoteRuntimeEndpoint,\n\t\tkubeServer.RemoteImageEndpoint,\n\t\tkubeServer.ExperimentalMounterPath,\n\t\tkubeServer.ExperimentalKernelMemcgNotification,\n\t\tkubeServer.ExperimentalCheckNodeCapabilitiesBeforeMount,\n\t\tkubeServer.ExperimentalNodeAllocatableIgnoreEvictionThreshold,\n\t\tkubeServer.MinimumGCAge,\n\t\tkubeServer.MaxPerPodContainerCount,\n\t\tkubeServer.MaxContainerCount,\n\t\tkubeServer.MasterServiceNamespace,\n\t\tkubeServer.RegisterSchedulable,\n\t\tkubeServer.NonMasqueradeCIDR,\n\t\tkubeServer.KeepTerminatedPodVolumes,\n\t\tkubeServer.NodeLabels,\n\t\tkubeServer.SeccompProfileRoot,\n\t\tkubeServer.BootstrapCheckpointPath,\n\t\tkubeServer.NodeStatusMaxImages)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create kubelet: %v\", err)\n\t}\n\n\t...\n\tif runOnce {\n\t\tif _, err := k.RunOnce(podCfg.Updates()); err != nil {\n\t\t\treturn fmt.Errorf(\"runonce failed: %v\", err)\n\t\t}\n\t\tglog.Infof(\"Started kubelet as runonce\")\n\t} else {\n        // \n\t\tstartKubelet(k, podCfg, &kubeServer.KubeletConfiguration, kubeDeps, kubeServer.EnableServer)\n\t\tglog.Infof(\"Started kubelet\")\n\t}\n\n}\n```\n\n\n```\nfunc CreateAndInitKubelet(...){\n\t// NewMainKubelet  kubelet  kubelet \n\tk, err = kubelet.NewMainKubelet(kubeCfg,\n\t\tkubeDeps,\n\t\tcrOptions,\n\t\tcontainerRuntime,\n\t\truntimeCgroups,\n\t\thostnameOverride,\n\t\tnodeIP,\n\t\tproviderID,\n\t\tcloudProvider,\n\t\tcertDirectory,\n\t\trootDirectory,\n\t\tregisterNode,\n\t\tregisterWithTaints,\n\t\tallowedUnsafeSysctls,\n\t\tremoteRuntimeEndpoint,\n\t\tremoteImageEndpoint,\n\t\texperimentalMounterPath,\n\t\texperimentalKernelMemcgNotification,\n\t\texperimentalCheckNodeCapabilitiesBeforeMount,\n\t\texperimentalNodeAllocatableIgnoreEvictionThreshold,\n\t\tminimumGCAge,\n\t\tmaxPerPodContainerCount,\n\t\tmaxContainerCount,\n\t\tmasterServiceNamespace,\n\t\tregisterSchedulable,\n\t\tnonMasqueradeCIDR,\n\t\tkeepTerminatedPodVolumes,\n\t\tnodeLabels,\n\t\tseccompProfileRoot,\n\t\tbootstrapCheckpointPath,\n\t\tnodeStatusMaxImages)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//  apiserver kubelet \n\tk.BirthCry()\n\t// \n\tk.StartGarbageCollection()\n\n\treturn k, nil\n\n}\n```\n\n```\nfunc NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration,...){\n    ...\n\tif kubeDeps.PodConfig == nil {\n\t\tvar err error\n\t\t//  makePodSourceConfig pod (FILE, URL, api-server) source  pod configuration \n\t\tkubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName, bootstrapCheckpointPath)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n    \n    // kubelet  10250\n\tdaemonEndpoints := &v1.NodeDaemonEndpoints{\n\t\tKubeletEndpoint: v1.DaemonEndpoint{Port: kubeCfg.Port},\n\t}\n\n\t//  reflector  ListWatch  serviceStore \n\tserviceIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc})\n\tif kubeDeps.KubeClient != nil {\n\t\tserviceLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), \"services\", metav1.NamespaceAll, fields.Everything())\n\t\tr := cache.NewReflector(serviceLW, &v1.Service{}, serviceIndexer, 0)\n\t\tgo r.Run(wait.NeverStop)\n\t}\n\tserviceLister := corelisters.NewServiceLister(serviceIndexer)\n\n\t//  reflector  ListWatch   nodeStore \n\tnodeIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{})\n\tif kubeDeps.KubeClient != nil {\n\t\tfieldSelector := fields.Set{api.ObjectNameField: string(nodeName)}.AsSelector()\n\t\tnodeLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), \"nodes\", metav1.NamespaceAll, fieldSelector)\n\t\tr := cache.NewReflector(nodeLW, &v1.Node{}, nodeIndexer, 0)\n\t\tgo r.Run(wait.NeverStop)\n\t}\n\tnodeInfo := &predicates.CachedNodeInfo{NodeLister: corelisters.NewNodeLister(nodeIndexer)}\n\n\t...\n\t// node \n\tthresholds, err := eviction.ParseThresholdConfig(enforceNodeAllocatable, kubeCfg.EvictionHard, kubeCfg.EvictionSoft, kubeCfg.EvictionSoftGracePeriod, kubeCfg.EvictionMinimumReclaim)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tevictionConfig := eviction.Config{\n\t\tPressureTransitionPeriod: kubeCfg.EvictionPressureTransitionPeriod.Duration,\n\t\tMaxPodGracePeriodSeconds: int64(kubeCfg.EvictionMaxPodGracePeriod),\n\t\tThresholds:               thresholds,\n\t\tKernelMemcgNotification:  experimentalKernelMemcgNotification,\n\t\tPodCgroupRoot:            kubeDeps.ContainerManager.GetPodCgroupRoot(),\n\t}\n    ...\n    // \n\tcontainerRefManager := kubecontainer.NewRefManager()\n    // oom \n\toomWatcher := NewOOMWatcher(kubeDeps.CAdvisorInterface, kubeDeps.Recorder)\n\n\t//  Kubelet \n\tklet := &Kubelet{\n\t\thostname:                       hostname,\n\t\thostnameOverridden:             len(hostnameOverride) > 0,\n\t\tnodeName:                       nodeName,\n\t\t...\n\t}\n\t\n\t//  cAdvisor \n\tmachineInfo, err := klet.cadvisor.MachineInfo()\n\n\t//  pod : \n\tklet.podManager = kubepod.NewBasicPodManager(kubepod.NewBasicMirrorClient(klet.kubeClient), secretManager, configMapManager, checkpointManager)\n\n\t// \n\truntime, err := kuberuntime.NewKubeGenericRuntimeManager(...)\n\n\t// pleg\n\tklet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{})\n\n\t//  containerGC \n\tcontainerGC, err := kubecontainer.NewContainerGC(klet.containerRuntime, containerGCPolicy, klet.sourcesReady)\n\n\t//  imageManager \n\timageManager, err := images.NewImageGCManager(klet.containerRuntime, klet.StatsProvider, kubeDeps.Recorder, nodeRef, imageGCPolicy, crOptions.PodSandboxImage)\n\t\n\t// statusManager  pod  apiserver  pod\n\tklet.statusManager = status.NewManager(klet.kubeClient, klet.podManager, klet)\n\n\t// \n\tklet.probeManager = prober.NewManager(...)\n\n    // token \n\ttokenManager := token.NewManager(kubeDeps.KubeClient)\n\n\t// \n\tklet.volumeManager = volumemanager.NewVolumeManager()\n\t\n\t//  syncPod()  podWorkers \n\tklet.podWorkers = newPodWorkers(klet.syncPod, kubeDeps.Recorder, klet.workQueue, klet.resyncInterval, backOffPeriod, klet.podCache)\n\n\t// \n\tevictionManager, evictionAdmitHandler := eviction.NewManager(klet.resourceAnalyzer, evictionConfig, killPodNow(klet.podWorkers, kubeDeps.Recorder), klet.imageManager, klet.containerGC, kubeDeps.Recorder, nodeRef, klet.clock)\n    ...\n}\n```\nRunKubelet  startKubelet() \n\n#### 5 kubelet cmd/kubelet/app/server.go\nstartKubelet()  \n\n- 1 goroutine  kubelet \n- 2 kubelet http server\n\n\n```\nfunc startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration, kubeDeps *kubelet.Dependencies, enableServer bool) {\n\tgo wait.Until(func() {\n\t\t//  goroutine  kubelet \n\t\tk.Run(podCfg.Updates())\n\t}, 0, wait.NeverStop)\n\n\t//  kubelet http server\t\n\tif enableServer {\n\t\tgo k.ListenAndServe(net.ParseIP(kubeCfg.Address), uint(kubeCfg.Port), kubeDeps.TLSOptions, kubeDeps.Auth, kubeCfg.EnableDebuggingHandlers, kubeCfg.EnableContentionProfiling)\n\n\t}\n\tif kubeCfg.ReadOnlyPort > 0 {\n\t\tgo k.ListenAndServeReadOnly(net.ParseIP(kubeCfg.Address), uint(kubeCfg.ReadOnlyPort))\n\t}\n}\n```\n\n```\n// Run starts the kubelet reacting to config updates\nfunc (kl *Kubelet) Run(updates <-chan kubetypes.PodUpdate) {\n\tif kl.logServer == nil {\n\t\tkl.logServer = http.StripPrefix(\"/logs/\", http.FileServer(http.Dir(\"/var/log/\")))\n\t}\n\tif kl.kubeClient == nil {\n\t\tglog.Warning(\"No api server defined - no node status update will be sent.\")\n\t}\n\n\t// Start the cloud provider sync manager\n\tif kl.cloudResourceSyncManager != nil {\n\t\tgo kl.cloudResourceSyncManager.Run(wait.NeverStop)\n\t}\n\n\tif err := kl.initializeModules(); err != nil {\n\t\tkl.recorder.Eventf(kl.nodeRef, v1.EventTypeWarning, events.KubeletSetupFailed, err.Error())\n\t\tglog.Fatal(err)\n\t}\n\n\t// Start volume manager\n\tgo kl.volumeManager.Run(kl.sourcesReady, wait.NeverStop)\n\n\tif kl.kubeClient != nil {\n\t\t// Start syncing node status immediately, this may set up things the runtime needs to run.\n\t\tgo wait.Until(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, wait.NeverStop)\n\t\tgo kl.fastStatusUpdateOnce()\n\n\t\t// start syncing lease\n\t\tif utilfeature.DefaultFeatureGate.Enabled(features.NodeLease) {\n\t\t\tgo kl.nodeLeaseController.Run(wait.NeverStop)\n\t\t}\n\t}\n\tgo wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)\n\n\t// Start loop to sync iptables util rules\n\tif kl.makeIPTablesUtilChains {\n\t\tgo wait.Until(kl.syncNetworkUtil, 1*time.Minute, wait.NeverStop)\n\t}\n\n\t// Start a goroutine responsible for killing pods (that are not properly\n\t// handled by pod workers).\n\tgo wait.Until(kl.podKiller, 1*time.Second, wait.NeverStop)\n\n\t// Start component sync loops.\n\tkl.statusManager.Start()\n\tkl.probeManager.Start()\n\n\t// Start syncing RuntimeClasses if enabled.\n\tif kl.runtimeClassManager != nil {\n\t\tgo kl.runtimeClassManager.Run(wait.NeverStop)\n\t}\n\n\t// Start the pod lifecycle event generator.\n\tkl.pleg.Start()\n\n\tkl.syncLoop(updates, kl)\n}\n```\nsyncLoop  kubelet (FILE,URL, API-SERVER) pod  Pod \n\n\n```\nfunc (kl *Kubelet) syncLoop(updates <-chan kubetypes.PodUpdate, handler SyncHandler) {\n\tglog.Info(\"Starting kubelet main sync loop.\")\n\n\t// syncTicker  pod workers\n\tsyncTicker := time.NewTicker(time.Second)\n\tdefer syncTicker.Stop()\n\thousekeepingTicker := time.NewTicker(housekeepingPeriod)\n\tdefer housekeepingTicker.Stop()\n\tplegCh := kl.pleg.Watch()\n\tconst (\n\t\tbase   = 100 * time.Millisecond\n\t\tmax    = 5 * time.Second\n\t\tfactor = 2\n\t)\n\tduration := base\n\tfor {\n\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 {\n\t\t\tglog.Infof(\"skipping pod synchronization - %v\", rs)\n\t\t\t// exponential backoff\n\t\t\ttime.Sleep(duration)\n\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))\n\t\t\tcontinue\n\t\t}\n\t\t// reset backoff if we have a success\n\t\tduration = base\n\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t\t// \n\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) {\n\t\t\tbreak\n\t\t}\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t}\n}\n```\n\nsyncLoopIteration()   pod  Handler Handler  dispatchWork \n\n\n## \n\n kubelet  kubelet \n\n\n[kubernetes node components  kubelet](http://www.sel.zju.edu.cn/?p=595)\n[Kubelet ():](https://segmentfault.com/a/1190000008267351)\n[kubelet ](https://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1/)\n[kubernetes  kubelet ](https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/05/02/Kubernetes-kubelet.html)\n[kubelet ](https://fatsheep9146.github.io/2018/07/08/kubelet%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/)\n","source":"_posts/kubelet_init.md","raw":"---\ntitle: kubelet \ndate: 2018-12-23 21:22:30\ntags: \"kubelet\"\ntype: \"kubelet\"\n\n---\n\n[kubelet ](https://blog.tianfeiyu.com/2018/12/16/kubelet-modules/)  kubelet  kubelet \n\n > kubernetes  v1.12 \n\n\n## kubelet \n\nkubelet :\n\n```\n  kubernetes git:(release-1.12)  tree cmd/kubelet\ncmd/kubelet\n BUILD\n OWNERS\n app\n  BUILD\n  OWNERS\n  auth.go\n  init_others.go\n  init_windows.go\n  options\n   BUILD\n   container_runtime.go\n   globalflags.go\n   globalflags_linux.go\n   globalflags_other.go\n   options.go\n   options_test.go\n   osflags_others.go\n   osflags_windows.go\n  plugins.go\n  server.go\n  server_linux.go\n  server_test.go\n  server_unsupported.go\n kubelet.go\n\n2 directories, 22 files\n```\n\n![kubelet ](https://upload-images.jianshu.io/upload_images/1262158-bdeb34a5cdda93d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n#### 1kubelet  maincmd/kubelet/kubelet.go\n\n```\nfunc main() {\n\trand.Seed(time.Now().UTC().UnixNano())\n\n\tcommand := app.NewKubeletCommand(server.SetupSignalHandler())\n\tlogs.InitLogs()\n\tdefer logs.FlushLogs()\n\n\tif err := command.Execute(); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"%v\\n\", err)\n\t\tos.Exit(1)\n\t}\n}\n```\n\n#### 2 kubelet cmd/kubelet/app/server.go\n\nNewKubeletCommand()   \n\n```\n// NewKubeletCommand creates a *cobra.Command object with default parameters\nfunc NewKubeletCommand(stopCh <-chan struct{}) *cobra.Command {\n    cleanFlagSet := pflag.NewFlagSet(componentKubelet, pflag.ContinueOnError)\n    cleanFlagSet.SetNormalizeFunc(flag.WordSepNormalizeFunc)\n    // Kubelet:\n    // KubeletFlag:  kubelet  Nodes \n    // KubeletConfiguration: Nodes\n    kubeletFlags := options.NewKubeletFlags()\n\tkubeletConfig, err := options.NewKubeletConfiguration()\n\t...\n\tcmd := &cobra.Command{\n\t\t...\n\t\tRun: func(cmd *cobra.Command, args []string) {\n\t\t\t//  kubelet \n\t\t\tif configFile := kubeletFlags.KubeletConfigFile; len(configFile) > 0 {\n\t\t\t\tkubeletConfig, err = loadConfigFile(configFile)\n\t\t\t\tif err != nil {\n\t\t\t\t\tglog.Fatal(err)\n\t\t\t\t}\n\t\t\t\t...\n\t\t\t}\n\t\t\t//  kubelet \n\t\t\tif err := kubeletconfigvalidation.ValidateKubeletConfiguration(kubeletConfig); err != nil {\n\t\t\t\tglog.Fatal(err)\n\t\t\t}\n\t\t\t...\n\t\t\t//  kubeletDeps\n\t\t\tkubeletDeps, err := UnsecuredDependencies(kubeletServer)\n\t\t\tif err != nil {\n\t\t\t\tglog.Fatal(err)\n\t\t\t}\n\t\t\t...\n\t\t\t// \n\t\t\tif err := Run(kubeletServer, kubeletDeps, stopCh); err != nil {\n\t\t\t\tglog.Fatal(err)\n\t\t\t}\n\t\t},\n\t}\n    ...\n\treturn cmd\n}\n```\nkubeletDeps  kubelet  dependency injection kubelet  kubelet cadvisorcgroup containerManager\n\nNewKubeletCommand()  Run() Run()  run() \n\n#### 3 apiserver cmd/kubelet/app/server.go\n\nrun() \n\n- 1 kubeClientevnetClient  apiserver  heartbeatClient  apiserver \n- 2 kubeDeps \n- 3 Healthz  http server 10248\n\n```\nfunc run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh <-chan struct{}) (err error) {\n\t...\n\t//  kubelet \n\tif standaloneMode {\n\t...\n\t} else if kubeDeps.KubeClient == nil || kubeDeps.EventClient == nil || kubeDeps.HeartbeatClient == nil || kubeDeps.DynamicKubeClient == nil {\n\t\t...\n\t\t//  kubeClient\n\t\tkubeClient, err = clientset.NewForConfig(clientConfig)\n\n\t\t...\n        //  evnetClient\n\t\teventClient, err = v1core.NewForConfig(&eventClientConfig)\n\t\t...\n\t\t// heartbeatClient \n\t\theartbeatClient, err = clientset.NewForConfig(&heartbeatClientConfig)\n\t\t...\n\t}\n\n\t//  kubeDeps \n\tif kubeDeps.Auth == nil {\n\t\t\tauth, err := BuildAuth(nodeName, kubeDeps.KubeClient, s.KubeletConfiguration)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tkubeDeps.Auth = auth\n\t\t}\n\n\t\tif kubeDeps.CAdvisorInterface == nil {\n\t\t\timageFsInfoProvider := cadvisor.NewImageFsInfoProvider(s.ContainerRuntime, s.RemoteRuntimeEndpoint)\n\t\t\tkubeDeps.CAdvisorInterface, err = cadvisor.New(imageFsInfoProvider, s.RootDirectory, cadvisor.UsingLegacyCadvisorStats(s.ContainerRuntime, s.RemoteRuntimeEndpoint))\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\t// \n\tif err := RunKubelet(s, kubeDeps, s.RunOnce); err != nil {\n\t\t\treturn err\n\t}\n\t...\n\t//  Healthz  http server  \n\tif s.HealthzPort > 0 {\n\t\thealthz.DefaultHealthz()\n\t\tgo wait.Until(func() {\n\t\t\terr := http.ListenAndServe(net.JoinHostPort(s.HealthzBindAddress, strconv.Itoa(int(s.HealthzPort))), nil)\n\t\t\tif err != nil {\n\t\t\t\tglog.Errorf(\"Starting health server failed: %v\", err)\n\t\t\t}\n\t\t}, 5*time.Second, wait.NeverStop)\n\t}\n\t...\n}\n```\nkubelet  pod  /etc/kubernetes/manifests  URL  watch kube-apiserver  kubelet  standalone  standalone  kubelet \n\nrun()  RunKubelet() \n\n#### 4 kubelet cmd/kubelet/app/server.go\n\nRunKubelet()  \n\n- 1 kubelet  kubelet \n- 2\n\n```\nfunc RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error {\n    ...\n\n \t//  kubelet \n\tk, err := CreateAndInitKubelet(&kubeServer.KubeletConfiguration,\n\t\tkubeDeps,\n\t\t&kubeServer.ContainerRuntimeOptions,\n\t\tkubeServer.ContainerRuntime,\n\t\tkubeServer.RuntimeCgroups,\n\t\tkubeServer.HostnameOverride,\n\t\tkubeServer.NodeIP,\n\t\tkubeServer.ProviderID,\n\t\tkubeServer.CloudProvider,\n\t\tkubeServer.CertDirectory,\n\t\tkubeServer.RootDirectory,\n\t\tkubeServer.RegisterNode,\n\t\tkubeServer.RegisterWithTaints,\n\t\tkubeServer.AllowedUnsafeSysctls,\n\t\tkubeServer.RemoteRuntimeEndpoint,\n\t\tkubeServer.RemoteImageEndpoint,\n\t\tkubeServer.ExperimentalMounterPath,\n\t\tkubeServer.ExperimentalKernelMemcgNotification,\n\t\tkubeServer.ExperimentalCheckNodeCapabilitiesBeforeMount,\n\t\tkubeServer.ExperimentalNodeAllocatableIgnoreEvictionThreshold,\n\t\tkubeServer.MinimumGCAge,\n\t\tkubeServer.MaxPerPodContainerCount,\n\t\tkubeServer.MaxContainerCount,\n\t\tkubeServer.MasterServiceNamespace,\n\t\tkubeServer.RegisterSchedulable,\n\t\tkubeServer.NonMasqueradeCIDR,\n\t\tkubeServer.KeepTerminatedPodVolumes,\n\t\tkubeServer.NodeLabels,\n\t\tkubeServer.SeccompProfileRoot,\n\t\tkubeServer.BootstrapCheckpointPath,\n\t\tkubeServer.NodeStatusMaxImages)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create kubelet: %v\", err)\n\t}\n\n\t...\n\tif runOnce {\n\t\tif _, err := k.RunOnce(podCfg.Updates()); err != nil {\n\t\t\treturn fmt.Errorf(\"runonce failed: %v\", err)\n\t\t}\n\t\tglog.Infof(\"Started kubelet as runonce\")\n\t} else {\n        // \n\t\tstartKubelet(k, podCfg, &kubeServer.KubeletConfiguration, kubeDeps, kubeServer.EnableServer)\n\t\tglog.Infof(\"Started kubelet\")\n\t}\n\n}\n```\n\n\n```\nfunc CreateAndInitKubelet(...){\n\t// NewMainKubelet  kubelet  kubelet \n\tk, err = kubelet.NewMainKubelet(kubeCfg,\n\t\tkubeDeps,\n\t\tcrOptions,\n\t\tcontainerRuntime,\n\t\truntimeCgroups,\n\t\thostnameOverride,\n\t\tnodeIP,\n\t\tproviderID,\n\t\tcloudProvider,\n\t\tcertDirectory,\n\t\trootDirectory,\n\t\tregisterNode,\n\t\tregisterWithTaints,\n\t\tallowedUnsafeSysctls,\n\t\tremoteRuntimeEndpoint,\n\t\tremoteImageEndpoint,\n\t\texperimentalMounterPath,\n\t\texperimentalKernelMemcgNotification,\n\t\texperimentalCheckNodeCapabilitiesBeforeMount,\n\t\texperimentalNodeAllocatableIgnoreEvictionThreshold,\n\t\tminimumGCAge,\n\t\tmaxPerPodContainerCount,\n\t\tmaxContainerCount,\n\t\tmasterServiceNamespace,\n\t\tregisterSchedulable,\n\t\tnonMasqueradeCIDR,\n\t\tkeepTerminatedPodVolumes,\n\t\tnodeLabels,\n\t\tseccompProfileRoot,\n\t\tbootstrapCheckpointPath,\n\t\tnodeStatusMaxImages)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t//  apiserver kubelet \n\tk.BirthCry()\n\t// \n\tk.StartGarbageCollection()\n\n\treturn k, nil\n\n}\n```\n\n```\nfunc NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration,...){\n    ...\n\tif kubeDeps.PodConfig == nil {\n\t\tvar err error\n\t\t//  makePodSourceConfig pod (FILE, URL, api-server) source  pod configuration \n\t\tkubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName, bootstrapCheckpointPath)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n    \n    // kubelet  10250\n\tdaemonEndpoints := &v1.NodeDaemonEndpoints{\n\t\tKubeletEndpoint: v1.DaemonEndpoint{Port: kubeCfg.Port},\n\t}\n\n\t//  reflector  ListWatch  serviceStore \n\tserviceIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{cache.NamespaceIndex: cache.MetaNamespaceIndexFunc})\n\tif kubeDeps.KubeClient != nil {\n\t\tserviceLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), \"services\", metav1.NamespaceAll, fields.Everything())\n\t\tr := cache.NewReflector(serviceLW, &v1.Service{}, serviceIndexer, 0)\n\t\tgo r.Run(wait.NeverStop)\n\t}\n\tserviceLister := corelisters.NewServiceLister(serviceIndexer)\n\n\t//  reflector  ListWatch   nodeStore \n\tnodeIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers{})\n\tif kubeDeps.KubeClient != nil {\n\t\tfieldSelector := fields.Set{api.ObjectNameField: string(nodeName)}.AsSelector()\n\t\tnodeLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), \"nodes\", metav1.NamespaceAll, fieldSelector)\n\t\tr := cache.NewReflector(nodeLW, &v1.Node{}, nodeIndexer, 0)\n\t\tgo r.Run(wait.NeverStop)\n\t}\n\tnodeInfo := &predicates.CachedNodeInfo{NodeLister: corelisters.NewNodeLister(nodeIndexer)}\n\n\t...\n\t// node \n\tthresholds, err := eviction.ParseThresholdConfig(enforceNodeAllocatable, kubeCfg.EvictionHard, kubeCfg.EvictionSoft, kubeCfg.EvictionSoftGracePeriod, kubeCfg.EvictionMinimumReclaim)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tevictionConfig := eviction.Config{\n\t\tPressureTransitionPeriod: kubeCfg.EvictionPressureTransitionPeriod.Duration,\n\t\tMaxPodGracePeriodSeconds: int64(kubeCfg.EvictionMaxPodGracePeriod),\n\t\tThresholds:               thresholds,\n\t\tKernelMemcgNotification:  experimentalKernelMemcgNotification,\n\t\tPodCgroupRoot:            kubeDeps.ContainerManager.GetPodCgroupRoot(),\n\t}\n    ...\n    // \n\tcontainerRefManager := kubecontainer.NewRefManager()\n    // oom \n\toomWatcher := NewOOMWatcher(kubeDeps.CAdvisorInterface, kubeDeps.Recorder)\n\n\t//  Kubelet \n\tklet := &Kubelet{\n\t\thostname:                       hostname,\n\t\thostnameOverridden:             len(hostnameOverride) > 0,\n\t\tnodeName:                       nodeName,\n\t\t...\n\t}\n\t\n\t//  cAdvisor \n\tmachineInfo, err := klet.cadvisor.MachineInfo()\n\n\t//  pod : \n\tklet.podManager = kubepod.NewBasicPodManager(kubepod.NewBasicMirrorClient(klet.kubeClient), secretManager, configMapManager, checkpointManager)\n\n\t// \n\truntime, err := kuberuntime.NewKubeGenericRuntimeManager(...)\n\n\t// pleg\n\tklet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock{})\n\n\t//  containerGC \n\tcontainerGC, err := kubecontainer.NewContainerGC(klet.containerRuntime, containerGCPolicy, klet.sourcesReady)\n\n\t//  imageManager \n\timageManager, err := images.NewImageGCManager(klet.containerRuntime, klet.StatsProvider, kubeDeps.Recorder, nodeRef, imageGCPolicy, crOptions.PodSandboxImage)\n\t\n\t// statusManager  pod  apiserver  pod\n\tklet.statusManager = status.NewManager(klet.kubeClient, klet.podManager, klet)\n\n\t// \n\tklet.probeManager = prober.NewManager(...)\n\n    // token \n\ttokenManager := token.NewManager(kubeDeps.KubeClient)\n\n\t// \n\tklet.volumeManager = volumemanager.NewVolumeManager()\n\t\n\t//  syncPod()  podWorkers \n\tklet.podWorkers = newPodWorkers(klet.syncPod, kubeDeps.Recorder, klet.workQueue, klet.resyncInterval, backOffPeriod, klet.podCache)\n\n\t// \n\tevictionManager, evictionAdmitHandler := eviction.NewManager(klet.resourceAnalyzer, evictionConfig, killPodNow(klet.podWorkers, kubeDeps.Recorder), klet.imageManager, klet.containerGC, kubeDeps.Recorder, nodeRef, klet.clock)\n    ...\n}\n```\nRunKubelet  startKubelet() \n\n#### 5 kubelet cmd/kubelet/app/server.go\nstartKubelet()  \n\n- 1 goroutine  kubelet \n- 2 kubelet http server\n\n\n```\nfunc startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration, kubeDeps *kubelet.Dependencies, enableServer bool) {\n\tgo wait.Until(func() {\n\t\t//  goroutine  kubelet \n\t\tk.Run(podCfg.Updates())\n\t}, 0, wait.NeverStop)\n\n\t//  kubelet http server\t\n\tif enableServer {\n\t\tgo k.ListenAndServe(net.ParseIP(kubeCfg.Address), uint(kubeCfg.Port), kubeDeps.TLSOptions, kubeDeps.Auth, kubeCfg.EnableDebuggingHandlers, kubeCfg.EnableContentionProfiling)\n\n\t}\n\tif kubeCfg.ReadOnlyPort > 0 {\n\t\tgo k.ListenAndServeReadOnly(net.ParseIP(kubeCfg.Address), uint(kubeCfg.ReadOnlyPort))\n\t}\n}\n```\n\n```\n// Run starts the kubelet reacting to config updates\nfunc (kl *Kubelet) Run(updates <-chan kubetypes.PodUpdate) {\n\tif kl.logServer == nil {\n\t\tkl.logServer = http.StripPrefix(\"/logs/\", http.FileServer(http.Dir(\"/var/log/\")))\n\t}\n\tif kl.kubeClient == nil {\n\t\tglog.Warning(\"No api server defined - no node status update will be sent.\")\n\t}\n\n\t// Start the cloud provider sync manager\n\tif kl.cloudResourceSyncManager != nil {\n\t\tgo kl.cloudResourceSyncManager.Run(wait.NeverStop)\n\t}\n\n\tif err := kl.initializeModules(); err != nil {\n\t\tkl.recorder.Eventf(kl.nodeRef, v1.EventTypeWarning, events.KubeletSetupFailed, err.Error())\n\t\tglog.Fatal(err)\n\t}\n\n\t// Start volume manager\n\tgo kl.volumeManager.Run(kl.sourcesReady, wait.NeverStop)\n\n\tif kl.kubeClient != nil {\n\t\t// Start syncing node status immediately, this may set up things the runtime needs to run.\n\t\tgo wait.Until(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, wait.NeverStop)\n\t\tgo kl.fastStatusUpdateOnce()\n\n\t\t// start syncing lease\n\t\tif utilfeature.DefaultFeatureGate.Enabled(features.NodeLease) {\n\t\t\tgo kl.nodeLeaseController.Run(wait.NeverStop)\n\t\t}\n\t}\n\tgo wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)\n\n\t// Start loop to sync iptables util rules\n\tif kl.makeIPTablesUtilChains {\n\t\tgo wait.Until(kl.syncNetworkUtil, 1*time.Minute, wait.NeverStop)\n\t}\n\n\t// Start a goroutine responsible for killing pods (that are not properly\n\t// handled by pod workers).\n\tgo wait.Until(kl.podKiller, 1*time.Second, wait.NeverStop)\n\n\t// Start component sync loops.\n\tkl.statusManager.Start()\n\tkl.probeManager.Start()\n\n\t// Start syncing RuntimeClasses if enabled.\n\tif kl.runtimeClassManager != nil {\n\t\tgo kl.runtimeClassManager.Run(wait.NeverStop)\n\t}\n\n\t// Start the pod lifecycle event generator.\n\tkl.pleg.Start()\n\n\tkl.syncLoop(updates, kl)\n}\n```\nsyncLoop  kubelet (FILE,URL, API-SERVER) pod  Pod \n\n\n```\nfunc (kl *Kubelet) syncLoop(updates <-chan kubetypes.PodUpdate, handler SyncHandler) {\n\tglog.Info(\"Starting kubelet main sync loop.\")\n\n\t// syncTicker  pod workers\n\tsyncTicker := time.NewTicker(time.Second)\n\tdefer syncTicker.Stop()\n\thousekeepingTicker := time.NewTicker(housekeepingPeriod)\n\tdefer housekeepingTicker.Stop()\n\tplegCh := kl.pleg.Watch()\n\tconst (\n\t\tbase   = 100 * time.Millisecond\n\t\tmax    = 5 * time.Second\n\t\tfactor = 2\n\t)\n\tduration := base\n\tfor {\n\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 {\n\t\t\tglog.Infof(\"skipping pod synchronization - %v\", rs)\n\t\t\t// exponential backoff\n\t\t\ttime.Sleep(duration)\n\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))\n\t\t\tcontinue\n\t\t}\n\t\t// reset backoff if we have a success\n\t\tduration = base\n\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t\t// \n\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) {\n\t\t\tbreak\n\t\t}\n\t\tkl.syncLoopMonitor.Store(kl.clock.Now())\n\t}\n}\n```\n\nsyncLoopIteration()   pod  Handler Handler  dispatchWork \n\n\n## \n\n kubelet  kubelet \n\n\n[kubernetes node components  kubelet](http://www.sel.zju.edu.cn/?p=595)\n[Kubelet ():](https://segmentfault.com/a/1190000008267351)\n[kubelet ](https://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1/)\n[kubernetes  kubelet ](https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/05/02/Kubernetes-kubelet.html)\n[kubelet ](https://fatsheep9146.github.io/2018/07/08/kubelet%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/)\n","slug":"kubelet_init","published":1,"updated":"2019-01-01T06:55:23.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyt060012tadvb4jdkh8m","content":"<p><a href=\"https://blog.tianfeiyu.com/2018/12/16/kubelet-modules/\" target=\"_blank\" rel=\"noopener\">kubelet </a>  kubelet  kubelet </p>\n<blockquote>\n<p>kubernetes  v1.12 </p>\n</blockquote>\n<h2 id=\"kubelet-\"><a href=\"#kubelet-\" class=\"headerlink\" title=\"kubelet \"></a>kubelet </h2><p>kubelet :</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  kubernetes git:(release-1.12)  tree cmd/kubelet</span><br><span class=\"line\">cmd/kubelet</span><br><span class=\"line\"> BUILD</span><br><span class=\"line\"> OWNERS</span><br><span class=\"line\"> app</span><br><span class=\"line\">  BUILD</span><br><span class=\"line\">  OWNERS</span><br><span class=\"line\">  auth.go</span><br><span class=\"line\">  init_others.go</span><br><span class=\"line\">  init_windows.go</span><br><span class=\"line\">  options</span><br><span class=\"line\">   BUILD</span><br><span class=\"line\">   container_runtime.go</span><br><span class=\"line\">   globalflags.go</span><br><span class=\"line\">   globalflags_linux.go</span><br><span class=\"line\">   globalflags_other.go</span><br><span class=\"line\">   options.go</span><br><span class=\"line\">   options_test.go</span><br><span class=\"line\">   osflags_others.go</span><br><span class=\"line\">   osflags_windows.go</span><br><span class=\"line\">  plugins.go</span><br><span class=\"line\">  server.go</span><br><span class=\"line\">  server_linux.go</span><br><span class=\"line\">  server_test.go</span><br><span class=\"line\">  server_unsupported.go</span><br><span class=\"line\"> kubelet.go</span><br><span class=\"line\"></span><br><span class=\"line\">2 directories, 22 files</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-bdeb34a5cdda93d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet \"></p>\n<h4 id=\"1kubelet--maincmd-kubelet-kubelet-go\"><a href=\"#1kubelet--maincmd-kubelet-kubelet-go\" class=\"headerlink\" title=\"1kubelet  maincmd/kubelet/kubelet.go\"></a>1kubelet  maincmd/kubelet/kubelet.go</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\trand.Seed(time.Now().UTC().UnixNano())</span><br><span class=\"line\"></span><br><span class=\"line\">\tcommand := app.NewKubeletCommand(server.SetupSignalHandler())</span><br><span class=\"line\">\tlogs.InitLogs()</span><br><span class=\"line\">\tdefer logs.FlushLogs()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif err := command.Execute(); err != nil &#123;</span><br><span class=\"line\">\t\tfmt.Fprintf(os.Stderr, &quot;%v\\n&quot;, err)</span><br><span class=\"line\">\t\tos.Exit(1)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-kubelet-cmd-kubelet-app-server-go\"><a href=\"#2-kubelet-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"2 kubelet cmd/kubelet/app/server.go\"></a>2 kubelet cmd/kubelet/app/server.go</h4><p>NewKubeletCommand()   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// NewKubeletCommand creates a *cobra.Command object with default parameters</span><br><span class=\"line\">func NewKubeletCommand(stopCh &lt;-chan struct&#123;&#125;) *cobra.Command &#123;</span><br><span class=\"line\">    cleanFlagSet := pflag.NewFlagSet(componentKubelet, pflag.ContinueOnError)</span><br><span class=\"line\">    cleanFlagSet.SetNormalizeFunc(flag.WordSepNormalizeFunc)</span><br><span class=\"line\">    // Kubelet:</span><br><span class=\"line\">    // KubeletFlag:  kubelet  Nodes </span><br><span class=\"line\">    // KubeletConfiguration: Nodes</span><br><span class=\"line\">    kubeletFlags := options.NewKubeletFlags()</span><br><span class=\"line\">\tkubeletConfig, err := options.NewKubeletConfiguration()</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tcmd := &amp;cobra.Command&#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tRun: func(cmd *cobra.Command, args []string) &#123;</span><br><span class=\"line\">\t\t\t//  kubelet </span><br><span class=\"line\">\t\t\tif configFile := kubeletFlags.KubeletConfigFile; len(configFile) &gt; 0 &#123;</span><br><span class=\"line\">\t\t\t\tkubeletConfig, err = loadConfigFile(configFile)</span><br><span class=\"line\">\t\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t//  kubelet </span><br><span class=\"line\">\t\t\tif err := kubeletconfigvalidation.ValidateKubeletConfiguration(kubeletConfig); err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t\t//  kubeletDeps</span><br><span class=\"line\">\t\t\tkubeletDeps, err := UnsecuredDependencies(kubeletServer)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t\t// </span><br><span class=\"line\">\t\t\tif err := Run(kubeletServer, kubeletDeps, stopCh); err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">\treturn cmd</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>kubeletDeps  kubelet  dependency injection kubelet  kubelet cadvisorcgroup containerManager</p>\n<p>NewKubeletCommand()  Run() Run()  run() </p>\n<h4 id=\"3-apiserver-cmd-kubelet-app-server-go\"><a href=\"#3-apiserver-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"3 apiserver cmd/kubelet/app/server.go\"></a>3 apiserver cmd/kubelet/app/server.go</h4><p>run() </p>\n<ul>\n<li>1 kubeClientevnetClient  apiserver  heartbeatClient  apiserver </li>\n<li>2 kubeDeps </li>\n<li>3 Healthz  http server 10248</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh &lt;-chan struct&#123;&#125;) (err error) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t//  kubelet </span><br><span class=\"line\">\tif standaloneMode &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t&#125; else if kubeDeps.KubeClient == nil || kubeDeps.EventClient == nil || kubeDeps.HeartbeatClient == nil || kubeDeps.DynamicKubeClient == nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t//  kubeClient</span><br><span class=\"line\">\t\tkubeClient, err = clientset.NewForConfig(clientConfig)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">        //  evnetClient</span><br><span class=\"line\">\t\teventClient, err = v1core.NewForConfig(&amp;eventClientConfig)</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t// heartbeatClient </span><br><span class=\"line\">\t\theartbeatClient, err = clientset.NewForConfig(&amp;heartbeatClientConfig)</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  kubeDeps </span><br><span class=\"line\">\tif kubeDeps.Auth == nil &#123;</span><br><span class=\"line\">\t\t\tauth, err := BuildAuth(nodeName, kubeDeps.KubeClient, s.KubeletConfiguration)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\treturn err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tkubeDeps.Auth = auth</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif kubeDeps.CAdvisorInterface == nil &#123;</span><br><span class=\"line\">\t\t\timageFsInfoProvider := cadvisor.NewImageFsInfoProvider(s.ContainerRuntime, s.RemoteRuntimeEndpoint)</span><br><span class=\"line\">\t\t\tkubeDeps.CAdvisorInterface, err = cadvisor.New(imageFsInfoProvider, s.RootDirectory, cadvisor.UsingLegacyCadvisorStats(s.ContainerRuntime, s.RemoteRuntimeEndpoint))</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\treturn err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif err := RunKubelet(s, kubeDeps, s.RunOnce); err != nil &#123;</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t//  Healthz  http server  </span><br><span class=\"line\">\tif s.HealthzPort &gt; 0 &#123;</span><br><span class=\"line\">\t\thealthz.DefaultHealthz()</span><br><span class=\"line\">\t\tgo wait.Until(func() &#123;</span><br><span class=\"line\">\t\t\terr := http.ListenAndServe(net.JoinHostPort(s.HealthzBindAddress, strconv.Itoa(int(s.HealthzPort))), nil)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Errorf(&quot;Starting health server failed: %v&quot;, err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;, 5*time.Second, wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>kubelet  pod  /etc/kubernetes/manifests  URL  watch kube-apiserver  kubelet  standalone  standalone  kubelet </p>\n<p>run()  RunKubelet() </p>\n<h4 id=\"4-kubelet-cmd-kubelet-app-server-go\"><a href=\"#4-kubelet-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"4 kubelet cmd/kubelet/app/server.go\"></a>4 kubelet cmd/kubelet/app/server.go</h4><p>RunKubelet()  </p>\n<ul>\n<li>1 kubelet  kubelet </li>\n<li>2</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\"> \t//  kubelet </span><br><span class=\"line\">\tk, err := CreateAndInitKubelet(&amp;kubeServer.KubeletConfiguration,</span><br><span class=\"line\">\t\tkubeDeps,</span><br><span class=\"line\">\t\t&amp;kubeServer.ContainerRuntimeOptions,</span><br><span class=\"line\">\t\tkubeServer.ContainerRuntime,</span><br><span class=\"line\">\t\tkubeServer.RuntimeCgroups,</span><br><span class=\"line\">\t\tkubeServer.HostnameOverride,</span><br><span class=\"line\">\t\tkubeServer.NodeIP,</span><br><span class=\"line\">\t\tkubeServer.ProviderID,</span><br><span class=\"line\">\t\tkubeServer.CloudProvider,</span><br><span class=\"line\">\t\tkubeServer.CertDirectory,</span><br><span class=\"line\">\t\tkubeServer.RootDirectory,</span><br><span class=\"line\">\t\tkubeServer.RegisterNode,</span><br><span class=\"line\">\t\tkubeServer.RegisterWithTaints,</span><br><span class=\"line\">\t\tkubeServer.AllowedUnsafeSysctls,</span><br><span class=\"line\">\t\tkubeServer.RemoteRuntimeEndpoint,</span><br><span class=\"line\">\t\tkubeServer.RemoteImageEndpoint,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalMounterPath,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalKernelMemcgNotification,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalCheckNodeCapabilitiesBeforeMount,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalNodeAllocatableIgnoreEvictionThreshold,</span><br><span class=\"line\">\t\tkubeServer.MinimumGCAge,</span><br><span class=\"line\">\t\tkubeServer.MaxPerPodContainerCount,</span><br><span class=\"line\">\t\tkubeServer.MaxContainerCount,</span><br><span class=\"line\">\t\tkubeServer.MasterServiceNamespace,</span><br><span class=\"line\">\t\tkubeServer.RegisterSchedulable,</span><br><span class=\"line\">\t\tkubeServer.NonMasqueradeCIDR,</span><br><span class=\"line\">\t\tkubeServer.KeepTerminatedPodVolumes,</span><br><span class=\"line\">\t\tkubeServer.NodeLabels,</span><br><span class=\"line\">\t\tkubeServer.SeccompProfileRoot,</span><br><span class=\"line\">\t\tkubeServer.BootstrapCheckpointPath,</span><br><span class=\"line\">\t\tkubeServer.NodeStatusMaxImages)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn fmt.Errorf(&quot;failed to create kubelet: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tif runOnce &#123;</span><br><span class=\"line\">\t\tif _, err := k.RunOnce(podCfg.Updates()); err != nil &#123;</span><br><span class=\"line\">\t\t\treturn fmt.Errorf(&quot;runonce failed: %v&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tglog.Infof(&quot;Started kubelet as runonce&quot;)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">        // </span><br><span class=\"line\">\t\tstartKubelet(k, podCfg, &amp;kubeServer.KubeletConfiguration, kubeDeps, kubeServer.EnableServer)</span><br><span class=\"line\">\t\tglog.Infof(&quot;Started kubelet&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func CreateAndInitKubelet(...)&#123;</span><br><span class=\"line\">\t// NewMainKubelet  kubelet  kubelet </span><br><span class=\"line\">\tk, err = kubelet.NewMainKubelet(kubeCfg,</span><br><span class=\"line\">\t\tkubeDeps,</span><br><span class=\"line\">\t\tcrOptions,</span><br><span class=\"line\">\t\tcontainerRuntime,</span><br><span class=\"line\">\t\truntimeCgroups,</span><br><span class=\"line\">\t\thostnameOverride,</span><br><span class=\"line\">\t\tnodeIP,</span><br><span class=\"line\">\t\tproviderID,</span><br><span class=\"line\">\t\tcloudProvider,</span><br><span class=\"line\">\t\tcertDirectory,</span><br><span class=\"line\">\t\trootDirectory,</span><br><span class=\"line\">\t\tregisterNode,</span><br><span class=\"line\">\t\tregisterWithTaints,</span><br><span class=\"line\">\t\tallowedUnsafeSysctls,</span><br><span class=\"line\">\t\tremoteRuntimeEndpoint,</span><br><span class=\"line\">\t\tremoteImageEndpoint,</span><br><span class=\"line\">\t\texperimentalMounterPath,</span><br><span class=\"line\">\t\texperimentalKernelMemcgNotification,</span><br><span class=\"line\">\t\texperimentalCheckNodeCapabilitiesBeforeMount,</span><br><span class=\"line\">\t\texperimentalNodeAllocatableIgnoreEvictionThreshold,</span><br><span class=\"line\">\t\tminimumGCAge,</span><br><span class=\"line\">\t\tmaxPerPodContainerCount,</span><br><span class=\"line\">\t\tmaxContainerCount,</span><br><span class=\"line\">\t\tmasterServiceNamespace,</span><br><span class=\"line\">\t\tregisterSchedulable,</span><br><span class=\"line\">\t\tnonMasqueradeCIDR,</span><br><span class=\"line\">\t\tkeepTerminatedPodVolumes,</span><br><span class=\"line\">\t\tnodeLabels,</span><br><span class=\"line\">\t\tseccompProfileRoot,</span><br><span class=\"line\">\t\tbootstrapCheckpointPath,</span><br><span class=\"line\">\t\tnodeStatusMaxImages)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  apiserver kubelet </span><br><span class=\"line\">\tk.BirthCry()</span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tk.StartGarbageCollection()</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn k, nil</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration,...)&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">\tif kubeDeps.PodConfig == nil &#123;</span><br><span class=\"line\">\t\tvar err error</span><br><span class=\"line\">\t\t//  makePodSourceConfig pod (FILE, URL, api-server) source  pod configuration </span><br><span class=\"line\">\t\tkubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName, bootstrapCheckpointPath)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\treturn nil, err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // kubelet  10250</span><br><span class=\"line\">\tdaemonEndpoints := &amp;v1.NodeDaemonEndpoints&#123;</span><br><span class=\"line\">\t\tKubeletEndpoint: v1.DaemonEndpoint&#123;Port: kubeCfg.Port&#125;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  reflector  ListWatch  serviceStore </span><br><span class=\"line\">\tserviceIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers&#123;cache.NamespaceIndex: cache.MetaNamespaceIndexFunc&#125;)</span><br><span class=\"line\">\tif kubeDeps.KubeClient != nil &#123;</span><br><span class=\"line\">\t\tserviceLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), &quot;services&quot;, metav1.NamespaceAll, fields.Everything())</span><br><span class=\"line\">\t\tr := cache.NewReflector(serviceLW, &amp;v1.Service&#123;&#125;, serviceIndexer, 0)</span><br><span class=\"line\">\t\tgo r.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tserviceLister := corelisters.NewServiceLister(serviceIndexer)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  reflector  ListWatch   nodeStore </span><br><span class=\"line\">\tnodeIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers&#123;&#125;)</span><br><span class=\"line\">\tif kubeDeps.KubeClient != nil &#123;</span><br><span class=\"line\">\t\tfieldSelector := fields.Set&#123;api.ObjectNameField: string(nodeName)&#125;.AsSelector()</span><br><span class=\"line\">\t\tnodeLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), &quot;nodes&quot;, metav1.NamespaceAll, fieldSelector)</span><br><span class=\"line\">\t\tr := cache.NewReflector(nodeLW, &amp;v1.Node&#123;&#125;, nodeIndexer, 0)</span><br><span class=\"line\">\t\tgo r.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tnodeInfo := &amp;predicates.CachedNodeInfo&#123;NodeLister: corelisters.NewNodeLister(nodeIndexer)&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t// node </span><br><span class=\"line\">\tthresholds, err := eviction.ParseThresholdConfig(enforceNodeAllocatable, kubeCfg.EvictionHard, kubeCfg.EvictionSoft, kubeCfg.EvictionSoftGracePeriod, kubeCfg.EvictionMinimumReclaim)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tevictionConfig := eviction.Config&#123;</span><br><span class=\"line\">\t\tPressureTransitionPeriod: kubeCfg.EvictionPressureTransitionPeriod.Duration,</span><br><span class=\"line\">\t\tMaxPodGracePeriodSeconds: int64(kubeCfg.EvictionMaxPodGracePeriod),</span><br><span class=\"line\">\t\tThresholds:               thresholds,</span><br><span class=\"line\">\t\tKernelMemcgNotification:  experimentalKernelMemcgNotification,</span><br><span class=\"line\">\t\tPodCgroupRoot:            kubeDeps.ContainerManager.GetPodCgroupRoot(),</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    // </span><br><span class=\"line\">\tcontainerRefManager := kubecontainer.NewRefManager()</span><br><span class=\"line\">    // oom </span><br><span class=\"line\">\toomWatcher := NewOOMWatcher(kubeDeps.CAdvisorInterface, kubeDeps.Recorder)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  Kubelet </span><br><span class=\"line\">\tklet := &amp;Kubelet&#123;</span><br><span class=\"line\">\t\thostname:                       hostname,</span><br><span class=\"line\">\t\thostnameOverridden:             len(hostnameOverride) &gt; 0,</span><br><span class=\"line\">\t\tnodeName:                       nodeName,</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t//  cAdvisor </span><br><span class=\"line\">\tmachineInfo, err := klet.cadvisor.MachineInfo()</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod : </span><br><span class=\"line\">\tklet.podManager = kubepod.NewBasicPodManager(kubepod.NewBasicMirrorClient(klet.kubeClient), secretManager, configMapManager, checkpointManager)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\truntime, err := kuberuntime.NewKubeGenericRuntimeManager(...)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// pleg</span><br><span class=\"line\">\tklet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  containerGC </span><br><span class=\"line\">\tcontainerGC, err := kubecontainer.NewContainerGC(klet.containerRuntime, containerGCPolicy, klet.sourcesReady)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  imageManager </span><br><span class=\"line\">\timageManager, err := images.NewImageGCManager(klet.containerRuntime, klet.StatsProvider, kubeDeps.Recorder, nodeRef, imageGCPolicy, crOptions.PodSandboxImage)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t// statusManager  pod  apiserver  pod</span><br><span class=\"line\">\tklet.statusManager = status.NewManager(klet.kubeClient, klet.podManager, klet)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tklet.probeManager = prober.NewManager(...)</span><br><span class=\"line\"></span><br><span class=\"line\">    // token </span><br><span class=\"line\">\ttokenManager := token.NewManager(kubeDeps.KubeClient)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tklet.volumeManager = volumemanager.NewVolumeManager()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t//  syncPod()  podWorkers </span><br><span class=\"line\">\tklet.podWorkers = newPodWorkers(klet.syncPod, kubeDeps.Recorder, klet.workQueue, klet.resyncInterval, backOffPeriod, klet.podCache)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tevictionManager, evictionAdmitHandler := eviction.NewManager(klet.resourceAnalyzer, evictionConfig, killPodNow(klet.podWorkers, kubeDeps.Recorder), klet.imageManager, klet.containerGC, kubeDeps.Recorder, nodeRef, klet.clock)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>RunKubelet  startKubelet() </p>\n<h4 id=\"5-kubelet-cmd-kubelet-app-server-go\"><a href=\"#5-kubelet-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"5 kubelet cmd/kubelet/app/server.go\"></a>5 kubelet cmd/kubelet/app/server.go</h4><p>startKubelet()  </p>\n<ul>\n<li>1 goroutine  kubelet </li>\n<li>2 kubelet http server</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration, kubeDeps *kubelet.Dependencies, enableServer bool) &#123;</span><br><span class=\"line\">\tgo wait.Until(func() &#123;</span><br><span class=\"line\">\t\t//  goroutine  kubelet </span><br><span class=\"line\">\t\tk.Run(podCfg.Updates())</span><br><span class=\"line\">\t&#125;, 0, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  kubelet http server\t</span><br><span class=\"line\">\tif enableServer &#123;</span><br><span class=\"line\">\t\tgo k.ListenAndServe(net.ParseIP(kubeCfg.Address), uint(kubeCfg.Port), kubeDeps.TLSOptions, kubeDeps.Auth, kubeCfg.EnableDebuggingHandlers, kubeCfg.EnableContentionProfiling)</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif kubeCfg.ReadOnlyPort &gt; 0 &#123;</span><br><span class=\"line\">\t\tgo k.ListenAndServeReadOnly(net.ParseIP(kubeCfg.Address), uint(kubeCfg.ReadOnlyPort))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Run starts the kubelet reacting to config updates</span><br><span class=\"line\">func (kl *Kubelet) Run(updates &lt;-chan kubetypes.PodUpdate) &#123;</span><br><span class=\"line\">\tif kl.logServer == nil &#123;</span><br><span class=\"line\">\t\tkl.logServer = http.StripPrefix(&quot;/logs/&quot;, http.FileServer(http.Dir(&quot;/var/log/&quot;)))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif kl.kubeClient == nil &#123;</span><br><span class=\"line\">\t\tglog.Warning(&quot;No api server defined - no node status update will be sent.&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start the cloud provider sync manager</span><br><span class=\"line\">\tif kl.cloudResourceSyncManager != nil &#123;</span><br><span class=\"line\">\t\tgo kl.cloudResourceSyncManager.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif err := kl.initializeModules(); err != nil &#123;</span><br><span class=\"line\">\t\tkl.recorder.Eventf(kl.nodeRef, v1.EventTypeWarning, events.KubeletSetupFailed, err.Error())</span><br><span class=\"line\">\t\tglog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start volume manager</span><br><span class=\"line\">\tgo kl.volumeManager.Run(kl.sourcesReady, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\tif kl.kubeClient != nil &#123;</span><br><span class=\"line\">\t\t// Start syncing node status immediately, this may set up things the runtime needs to run.</span><br><span class=\"line\">\t\tgo wait.Until(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, wait.NeverStop)</span><br><span class=\"line\">\t\tgo kl.fastStatusUpdateOnce()</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t// start syncing lease</span><br><span class=\"line\">\t\tif utilfeature.DefaultFeatureGate.Enabled(features.NodeLease) &#123;</span><br><span class=\"line\">\t\t\tgo kl.nodeLeaseController.Run(wait.NeverStop)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tgo wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start loop to sync iptables util rules</span><br><span class=\"line\">\tif kl.makeIPTablesUtilChains &#123;</span><br><span class=\"line\">\t\tgo wait.Until(kl.syncNetworkUtil, 1*time.Minute, wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start a goroutine responsible for killing pods (that are not properly</span><br><span class=\"line\">\t// handled by pod workers).</span><br><span class=\"line\">\tgo wait.Until(kl.podKiller, 1*time.Second, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start component sync loops.</span><br><span class=\"line\">\tkl.statusManager.Start()</span><br><span class=\"line\">\tkl.probeManager.Start()</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start syncing RuntimeClasses if enabled.</span><br><span class=\"line\">\tif kl.runtimeClassManager != nil &#123;</span><br><span class=\"line\">\t\tgo kl.runtimeClassManager.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start the pod lifecycle event generator.</span><br><span class=\"line\">\tkl.pleg.Start()</span><br><span class=\"line\"></span><br><span class=\"line\">\tkl.syncLoop(updates, kl)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>syncLoop  kubelet (FILE,URL, API-SERVER) pod  Pod </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) &#123;</span><br><span class=\"line\">\tglog.Info(&quot;Starting kubelet main sync loop.&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// syncTicker  pod workers</span><br><span class=\"line\">\tsyncTicker := time.NewTicker(time.Second)</span><br><span class=\"line\">\tdefer syncTicker.Stop()</span><br><span class=\"line\">\thousekeepingTicker := time.NewTicker(housekeepingPeriod)</span><br><span class=\"line\">\tdefer housekeepingTicker.Stop()</span><br><span class=\"line\">\tplegCh := kl.pleg.Watch()</span><br><span class=\"line\">\tconst (</span><br><span class=\"line\">\t\tbase   = 100 * time.Millisecond</span><br><span class=\"line\">\t\tmax    = 5 * time.Second</span><br><span class=\"line\">\t\tfactor = 2</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\tduration := base</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 &#123;</span><br><span class=\"line\">\t\t\tglog.Infof(&quot;skipping pod synchronization - %v&quot;, rs)</span><br><span class=\"line\">\t\t\t// exponential backoff</span><br><span class=\"line\">\t\t\ttime.Sleep(duration)</span><br><span class=\"line\">\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))</span><br><span class=\"line\">\t\t\tcontinue</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t// reset backoff if we have a success</span><br><span class=\"line\">\t\tduration = base</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>syncLoopIteration()   pod  Handler Handler  dispatchWork </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> kubelet  kubelet </p>\n<p><br><a href=\"http://www.sel.zju.edu.cn/?p=595\" target=\"_blank\" rel=\"noopener\">kubernetes node components  kubelet</a><br><a href=\"https://segmentfault.com/a/1190000008267351\" target=\"_blank\" rel=\"noopener\">Kubelet ():</a><br><a href=\"https://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1/\" target=\"_blank\" rel=\"noopener\">kubelet </a><br><a href=\"https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/05/02/Kubernetes-kubelet.html\" target=\"_blank\" rel=\"noopener\">kubernetes  kubelet </a><br><a href=\"https://fatsheep9146.github.io/2018/07/08/kubelet%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/\" target=\"_blank\" rel=\"noopener\">kubelet </a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://blog.tianfeiyu.com/2018/12/16/kubelet-modules/\" target=\"_blank\" rel=\"noopener\">kubelet </a>  kubelet  kubelet </p>\n<blockquote>\n<p>kubernetes  v1.12 </p>\n</blockquote>\n<h2 id=\"kubelet-\"><a href=\"#kubelet-\" class=\"headerlink\" title=\"kubelet \"></a>kubelet </h2><p>kubelet :</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">  kubernetes git:(release-1.12)  tree cmd/kubelet</span><br><span class=\"line\">cmd/kubelet</span><br><span class=\"line\"> BUILD</span><br><span class=\"line\"> OWNERS</span><br><span class=\"line\"> app</span><br><span class=\"line\">  BUILD</span><br><span class=\"line\">  OWNERS</span><br><span class=\"line\">  auth.go</span><br><span class=\"line\">  init_others.go</span><br><span class=\"line\">  init_windows.go</span><br><span class=\"line\">  options</span><br><span class=\"line\">   BUILD</span><br><span class=\"line\">   container_runtime.go</span><br><span class=\"line\">   globalflags.go</span><br><span class=\"line\">   globalflags_linux.go</span><br><span class=\"line\">   globalflags_other.go</span><br><span class=\"line\">   options.go</span><br><span class=\"line\">   options_test.go</span><br><span class=\"line\">   osflags_others.go</span><br><span class=\"line\">   osflags_windows.go</span><br><span class=\"line\">  plugins.go</span><br><span class=\"line\">  server.go</span><br><span class=\"line\">  server_linux.go</span><br><span class=\"line\">  server_test.go</span><br><span class=\"line\">  server_unsupported.go</span><br><span class=\"line\"> kubelet.go</span><br><span class=\"line\"></span><br><span class=\"line\">2 directories, 22 files</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-bdeb34a5cdda93d2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubelet \"></p>\n<h4 id=\"1kubelet--maincmd-kubelet-kubelet-go\"><a href=\"#1kubelet--maincmd-kubelet-kubelet-go\" class=\"headerlink\" title=\"1kubelet  maincmd/kubelet/kubelet.go\"></a>1kubelet  maincmd/kubelet/kubelet.go</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func main() &#123;</span><br><span class=\"line\">\trand.Seed(time.Now().UTC().UnixNano())</span><br><span class=\"line\"></span><br><span class=\"line\">\tcommand := app.NewKubeletCommand(server.SetupSignalHandler())</span><br><span class=\"line\">\tlogs.InitLogs()</span><br><span class=\"line\">\tdefer logs.FlushLogs()</span><br><span class=\"line\"></span><br><span class=\"line\">\tif err := command.Execute(); err != nil &#123;</span><br><span class=\"line\">\t\tfmt.Fprintf(os.Stderr, &quot;%v\\n&quot;, err)</span><br><span class=\"line\">\t\tos.Exit(1)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-kubelet-cmd-kubelet-app-server-go\"><a href=\"#2-kubelet-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"2 kubelet cmd/kubelet/app/server.go\"></a>2 kubelet cmd/kubelet/app/server.go</h4><p>NewKubeletCommand()   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// NewKubeletCommand creates a *cobra.Command object with default parameters</span><br><span class=\"line\">func NewKubeletCommand(stopCh &lt;-chan struct&#123;&#125;) *cobra.Command &#123;</span><br><span class=\"line\">    cleanFlagSet := pflag.NewFlagSet(componentKubelet, pflag.ContinueOnError)</span><br><span class=\"line\">    cleanFlagSet.SetNormalizeFunc(flag.WordSepNormalizeFunc)</span><br><span class=\"line\">    // Kubelet:</span><br><span class=\"line\">    // KubeletFlag:  kubelet  Nodes </span><br><span class=\"line\">    // KubeletConfiguration: Nodes</span><br><span class=\"line\">    kubeletFlags := options.NewKubeletFlags()</span><br><span class=\"line\">\tkubeletConfig, err := options.NewKubeletConfiguration()</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tcmd := &amp;cobra.Command&#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\tRun: func(cmd *cobra.Command, args []string) &#123;</span><br><span class=\"line\">\t\t\t//  kubelet </span><br><span class=\"line\">\t\t\tif configFile := kubeletFlags.KubeletConfigFile; len(configFile) &gt; 0 &#123;</span><br><span class=\"line\">\t\t\t\tkubeletConfig, err = loadConfigFile(configFile)</span><br><span class=\"line\">\t\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t\t...</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t//  kubelet </span><br><span class=\"line\">\t\t\tif err := kubeletconfigvalidation.ValidateKubeletConfiguration(kubeletConfig); err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t\t//  kubeletDeps</span><br><span class=\"line\">\t\t\tkubeletDeps, err := UnsecuredDependencies(kubeletServer)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\t...</span><br><span class=\"line\">\t\t\t// </span><br><span class=\"line\">\t\t\tif err := Run(kubeletServer, kubeletDeps, stopCh); err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Fatal(err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">\treturn cmd</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>kubeletDeps  kubelet  dependency injection kubelet  kubelet cadvisorcgroup containerManager</p>\n<p>NewKubeletCommand()  Run() Run()  run() </p>\n<h4 id=\"3-apiserver-cmd-kubelet-app-server-go\"><a href=\"#3-apiserver-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"3 apiserver cmd/kubelet/app/server.go\"></a>3 apiserver cmd/kubelet/app/server.go</h4><p>run() </p>\n<ul>\n<li>1 kubeClientevnetClient  apiserver  heartbeatClient  apiserver </li>\n<li>2 kubeDeps </li>\n<li>3 Healthz  http server 10248</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func run(s *options.KubeletServer, kubeDeps *kubelet.Dependencies, stopCh &lt;-chan struct&#123;&#125;) (err error) &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t//  kubelet </span><br><span class=\"line\">\tif standaloneMode &#123;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t&#125; else if kubeDeps.KubeClient == nil || kubeDeps.EventClient == nil || kubeDeps.HeartbeatClient == nil || kubeDeps.DynamicKubeClient == nil &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t//  kubeClient</span><br><span class=\"line\">\t\tkubeClient, err = clientset.NewForConfig(clientConfig)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">        //  evnetClient</span><br><span class=\"line\">\t\teventClient, err = v1core.NewForConfig(&amp;eventClientConfig)</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t\t// heartbeatClient </span><br><span class=\"line\">\t\theartbeatClient, err = clientset.NewForConfig(&amp;heartbeatClientConfig)</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  kubeDeps </span><br><span class=\"line\">\tif kubeDeps.Auth == nil &#123;</span><br><span class=\"line\">\t\t\tauth, err := BuildAuth(nodeName, kubeDeps.KubeClient, s.KubeletConfiguration)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\treturn err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tkubeDeps.Auth = auth</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tif kubeDeps.CAdvisorInterface == nil &#123;</span><br><span class=\"line\">\t\t\timageFsInfoProvider := cadvisor.NewImageFsInfoProvider(s.ContainerRuntime, s.RemoteRuntimeEndpoint)</span><br><span class=\"line\">\t\t\tkubeDeps.CAdvisorInterface, err = cadvisor.New(imageFsInfoProvider, s.RootDirectory, cadvisor.UsingLegacyCadvisorStats(s.ContainerRuntime, s.RemoteRuntimeEndpoint))</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\treturn err</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tif err := RunKubelet(s, kubeDeps, s.RunOnce); err != nil &#123;</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t//  Healthz  http server  </span><br><span class=\"line\">\tif s.HealthzPort &gt; 0 &#123;</span><br><span class=\"line\">\t\thealthz.DefaultHealthz()</span><br><span class=\"line\">\t\tgo wait.Until(func() &#123;</span><br><span class=\"line\">\t\t\terr := http.ListenAndServe(net.JoinHostPort(s.HealthzBindAddress, strconv.Itoa(int(s.HealthzPort))), nil)</span><br><span class=\"line\">\t\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\t\tglog.Errorf(&quot;Starting health server failed: %v&quot;, err)</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t&#125;, 5*time.Second, wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>kubelet  pod  /etc/kubernetes/manifests  URL  watch kube-apiserver  kubelet  standalone  standalone  kubelet </p>\n<p>run()  RunKubelet() </p>\n<h4 id=\"4-kubelet-cmd-kubelet-app-server-go\"><a href=\"#4-kubelet-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"4 kubelet cmd/kubelet/app/server.go\"></a>4 kubelet cmd/kubelet/app/server.go</h4><p>RunKubelet()  </p>\n<ul>\n<li>1 kubelet  kubelet </li>\n<li>2</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\"></span><br><span class=\"line\"> \t//  kubelet </span><br><span class=\"line\">\tk, err := CreateAndInitKubelet(&amp;kubeServer.KubeletConfiguration,</span><br><span class=\"line\">\t\tkubeDeps,</span><br><span class=\"line\">\t\t&amp;kubeServer.ContainerRuntimeOptions,</span><br><span class=\"line\">\t\tkubeServer.ContainerRuntime,</span><br><span class=\"line\">\t\tkubeServer.RuntimeCgroups,</span><br><span class=\"line\">\t\tkubeServer.HostnameOverride,</span><br><span class=\"line\">\t\tkubeServer.NodeIP,</span><br><span class=\"line\">\t\tkubeServer.ProviderID,</span><br><span class=\"line\">\t\tkubeServer.CloudProvider,</span><br><span class=\"line\">\t\tkubeServer.CertDirectory,</span><br><span class=\"line\">\t\tkubeServer.RootDirectory,</span><br><span class=\"line\">\t\tkubeServer.RegisterNode,</span><br><span class=\"line\">\t\tkubeServer.RegisterWithTaints,</span><br><span class=\"line\">\t\tkubeServer.AllowedUnsafeSysctls,</span><br><span class=\"line\">\t\tkubeServer.RemoteRuntimeEndpoint,</span><br><span class=\"line\">\t\tkubeServer.RemoteImageEndpoint,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalMounterPath,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalKernelMemcgNotification,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalCheckNodeCapabilitiesBeforeMount,</span><br><span class=\"line\">\t\tkubeServer.ExperimentalNodeAllocatableIgnoreEvictionThreshold,</span><br><span class=\"line\">\t\tkubeServer.MinimumGCAge,</span><br><span class=\"line\">\t\tkubeServer.MaxPerPodContainerCount,</span><br><span class=\"line\">\t\tkubeServer.MaxContainerCount,</span><br><span class=\"line\">\t\tkubeServer.MasterServiceNamespace,</span><br><span class=\"line\">\t\tkubeServer.RegisterSchedulable,</span><br><span class=\"line\">\t\tkubeServer.NonMasqueradeCIDR,</span><br><span class=\"line\">\t\tkubeServer.KeepTerminatedPodVolumes,</span><br><span class=\"line\">\t\tkubeServer.NodeLabels,</span><br><span class=\"line\">\t\tkubeServer.SeccompProfileRoot,</span><br><span class=\"line\">\t\tkubeServer.BootstrapCheckpointPath,</span><br><span class=\"line\">\t\tkubeServer.NodeStatusMaxImages)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn fmt.Errorf(&quot;failed to create kubelet: %v&quot;, err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\tif runOnce &#123;</span><br><span class=\"line\">\t\tif _, err := k.RunOnce(podCfg.Updates()); err != nil &#123;</span><br><span class=\"line\">\t\t\treturn fmt.Errorf(&quot;runonce failed: %v&quot;, err)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tglog.Infof(&quot;Started kubelet as runonce&quot;)</span><br><span class=\"line\">\t&#125; else &#123;</span><br><span class=\"line\">        // </span><br><span class=\"line\">\t\tstartKubelet(k, podCfg, &amp;kubeServer.KubeletConfiguration, kubeDeps, kubeServer.EnableServer)</span><br><span class=\"line\">\t\tglog.Infof(&quot;Started kubelet&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func CreateAndInitKubelet(...)&#123;</span><br><span class=\"line\">\t// NewMainKubelet  kubelet  kubelet </span><br><span class=\"line\">\tk, err = kubelet.NewMainKubelet(kubeCfg,</span><br><span class=\"line\">\t\tkubeDeps,</span><br><span class=\"line\">\t\tcrOptions,</span><br><span class=\"line\">\t\tcontainerRuntime,</span><br><span class=\"line\">\t\truntimeCgroups,</span><br><span class=\"line\">\t\thostnameOverride,</span><br><span class=\"line\">\t\tnodeIP,</span><br><span class=\"line\">\t\tproviderID,</span><br><span class=\"line\">\t\tcloudProvider,</span><br><span class=\"line\">\t\tcertDirectory,</span><br><span class=\"line\">\t\trootDirectory,</span><br><span class=\"line\">\t\tregisterNode,</span><br><span class=\"line\">\t\tregisterWithTaints,</span><br><span class=\"line\">\t\tallowedUnsafeSysctls,</span><br><span class=\"line\">\t\tremoteRuntimeEndpoint,</span><br><span class=\"line\">\t\tremoteImageEndpoint,</span><br><span class=\"line\">\t\texperimentalMounterPath,</span><br><span class=\"line\">\t\texperimentalKernelMemcgNotification,</span><br><span class=\"line\">\t\texperimentalCheckNodeCapabilitiesBeforeMount,</span><br><span class=\"line\">\t\texperimentalNodeAllocatableIgnoreEvictionThreshold,</span><br><span class=\"line\">\t\tminimumGCAge,</span><br><span class=\"line\">\t\tmaxPerPodContainerCount,</span><br><span class=\"line\">\t\tmaxContainerCount,</span><br><span class=\"line\">\t\tmasterServiceNamespace,</span><br><span class=\"line\">\t\tregisterSchedulable,</span><br><span class=\"line\">\t\tnonMasqueradeCIDR,</span><br><span class=\"line\">\t\tkeepTerminatedPodVolumes,</span><br><span class=\"line\">\t\tnodeLabels,</span><br><span class=\"line\">\t\tseccompProfileRoot,</span><br><span class=\"line\">\t\tbootstrapCheckpointPath,</span><br><span class=\"line\">\t\tnodeStatusMaxImages)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  apiserver kubelet </span><br><span class=\"line\">\tk.BirthCry()</span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tk.StartGarbageCollection()</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn k, nil</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func NewMainKubelet(kubeCfg *kubeletconfiginternal.KubeletConfiguration,...)&#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">\tif kubeDeps.PodConfig == nil &#123;</span><br><span class=\"line\">\t\tvar err error</span><br><span class=\"line\">\t\t//  makePodSourceConfig pod (FILE, URL, api-server) source  pod configuration </span><br><span class=\"line\">\t\tkubeDeps.PodConfig, err = makePodSourceConfig(kubeCfg, kubeDeps, nodeName, bootstrapCheckpointPath)</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\treturn nil, err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    // kubelet  10250</span><br><span class=\"line\">\tdaemonEndpoints := &amp;v1.NodeDaemonEndpoints&#123;</span><br><span class=\"line\">\t\tKubeletEndpoint: v1.DaemonEndpoint&#123;Port: kubeCfg.Port&#125;,</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  reflector  ListWatch  serviceStore </span><br><span class=\"line\">\tserviceIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers&#123;cache.NamespaceIndex: cache.MetaNamespaceIndexFunc&#125;)</span><br><span class=\"line\">\tif kubeDeps.KubeClient != nil &#123;</span><br><span class=\"line\">\t\tserviceLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), &quot;services&quot;, metav1.NamespaceAll, fields.Everything())</span><br><span class=\"line\">\t\tr := cache.NewReflector(serviceLW, &amp;v1.Service&#123;&#125;, serviceIndexer, 0)</span><br><span class=\"line\">\t\tgo r.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tserviceLister := corelisters.NewServiceLister(serviceIndexer)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  reflector  ListWatch   nodeStore </span><br><span class=\"line\">\tnodeIndexer := cache.NewIndexer(cache.MetaNamespaceKeyFunc, cache.Indexers&#123;&#125;)</span><br><span class=\"line\">\tif kubeDeps.KubeClient != nil &#123;</span><br><span class=\"line\">\t\tfieldSelector := fields.Set&#123;api.ObjectNameField: string(nodeName)&#125;.AsSelector()</span><br><span class=\"line\">\t\tnodeLW := cache.NewListWatchFromClient(kubeDeps.KubeClient.CoreV1().RESTClient(), &quot;nodes&quot;, metav1.NamespaceAll, fieldSelector)</span><br><span class=\"line\">\t\tr := cache.NewReflector(nodeLW, &amp;v1.Node&#123;&#125;, nodeIndexer, 0)</span><br><span class=\"line\">\t\tgo r.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tnodeInfo := &amp;predicates.CachedNodeInfo&#123;NodeLister: corelisters.NewNodeLister(nodeIndexer)&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t...</span><br><span class=\"line\">\t// node </span><br><span class=\"line\">\tthresholds, err := eviction.ParseThresholdConfig(enforceNodeAllocatable, kubeCfg.EvictionHard, kubeCfg.EvictionSoft, kubeCfg.EvictionSoftGracePeriod, kubeCfg.EvictionMinimumReclaim)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn nil, err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tevictionConfig := eviction.Config&#123;</span><br><span class=\"line\">\t\tPressureTransitionPeriod: kubeCfg.EvictionPressureTransitionPeriod.Duration,</span><br><span class=\"line\">\t\tMaxPodGracePeriodSeconds: int64(kubeCfg.EvictionMaxPodGracePeriod),</span><br><span class=\"line\">\t\tThresholds:               thresholds,</span><br><span class=\"line\">\t\tKernelMemcgNotification:  experimentalKernelMemcgNotification,</span><br><span class=\"line\">\t\tPodCgroupRoot:            kubeDeps.ContainerManager.GetPodCgroupRoot(),</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    // </span><br><span class=\"line\">\tcontainerRefManager := kubecontainer.NewRefManager()</span><br><span class=\"line\">    // oom </span><br><span class=\"line\">\toomWatcher := NewOOMWatcher(kubeDeps.CAdvisorInterface, kubeDeps.Recorder)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  Kubelet </span><br><span class=\"line\">\tklet := &amp;Kubelet&#123;</span><br><span class=\"line\">\t\thostname:                       hostname,</span><br><span class=\"line\">\t\thostnameOverridden:             len(hostnameOverride) &gt; 0,</span><br><span class=\"line\">\t\tnodeName:                       nodeName,</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t//  cAdvisor </span><br><span class=\"line\">\tmachineInfo, err := klet.cadvisor.MachineInfo()</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  pod : </span><br><span class=\"line\">\tklet.podManager = kubepod.NewBasicPodManager(kubepod.NewBasicMirrorClient(klet.kubeClient), secretManager, configMapManager, checkpointManager)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\truntime, err := kuberuntime.NewKubeGenericRuntimeManager(...)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// pleg</span><br><span class=\"line\">\tklet.pleg = pleg.NewGenericPLEG(klet.containerRuntime, plegChannelCapacity, plegRelistPeriod, klet.podCache, clock.RealClock&#123;&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  containerGC </span><br><span class=\"line\">\tcontainerGC, err := kubecontainer.NewContainerGC(klet.containerRuntime, containerGCPolicy, klet.sourcesReady)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  imageManager </span><br><span class=\"line\">\timageManager, err := images.NewImageGCManager(klet.containerRuntime, klet.StatsProvider, kubeDeps.Recorder, nodeRef, imageGCPolicy, crOptions.PodSandboxImage)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t// statusManager  pod  apiserver  pod</span><br><span class=\"line\">\tklet.statusManager = status.NewManager(klet.kubeClient, klet.podManager, klet)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tklet.probeManager = prober.NewManager(...)</span><br><span class=\"line\"></span><br><span class=\"line\">    // token </span><br><span class=\"line\">\ttokenManager := token.NewManager(kubeDeps.KubeClient)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tklet.volumeManager = volumemanager.NewVolumeManager()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t//  syncPod()  podWorkers </span><br><span class=\"line\">\tklet.podWorkers = newPodWorkers(klet.syncPod, kubeDeps.Recorder, klet.workQueue, klet.resyncInterval, backOffPeriod, klet.podCache)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// </span><br><span class=\"line\">\tevictionManager, evictionAdmitHandler := eviction.NewManager(klet.resourceAnalyzer, evictionConfig, killPodNow(klet.podWorkers, kubeDeps.Recorder), klet.imageManager, klet.containerGC, kubeDeps.Recorder, nodeRef, klet.clock)</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>RunKubelet  startKubelet() </p>\n<h4 id=\"5-kubelet-cmd-kubelet-app-server-go\"><a href=\"#5-kubelet-cmd-kubelet-app-server-go\" class=\"headerlink\" title=\"5 kubelet cmd/kubelet/app/server.go\"></a>5 kubelet cmd/kubelet/app/server.go</h4><p>startKubelet()  </p>\n<ul>\n<li>1 goroutine  kubelet </li>\n<li>2 kubelet http server</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func startKubelet(k kubelet.Bootstrap, podCfg *config.PodConfig, kubeCfg *kubeletconfiginternal.KubeletConfiguration, kubeDeps *kubelet.Dependencies, enableServer bool) &#123;</span><br><span class=\"line\">\tgo wait.Until(func() &#123;</span><br><span class=\"line\">\t\t//  goroutine  kubelet </span><br><span class=\"line\">\t\tk.Run(podCfg.Updates())</span><br><span class=\"line\">\t&#125;, 0, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\t//  kubelet http server\t</span><br><span class=\"line\">\tif enableServer &#123;</span><br><span class=\"line\">\t\tgo k.ListenAndServe(net.ParseIP(kubeCfg.Address), uint(kubeCfg.Port), kubeDeps.TLSOptions, kubeDeps.Auth, kubeCfg.EnableDebuggingHandlers, kubeCfg.EnableContentionProfiling)</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif kubeCfg.ReadOnlyPort &gt; 0 &#123;</span><br><span class=\"line\">\t\tgo k.ListenAndServeReadOnly(net.ParseIP(kubeCfg.Address), uint(kubeCfg.ReadOnlyPort))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// Run starts the kubelet reacting to config updates</span><br><span class=\"line\">func (kl *Kubelet) Run(updates &lt;-chan kubetypes.PodUpdate) &#123;</span><br><span class=\"line\">\tif kl.logServer == nil &#123;</span><br><span class=\"line\">\t\tkl.logServer = http.StripPrefix(&quot;/logs/&quot;, http.FileServer(http.Dir(&quot;/var/log/&quot;)))</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tif kl.kubeClient == nil &#123;</span><br><span class=\"line\">\t\tglog.Warning(&quot;No api server defined - no node status update will be sent.&quot;)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start the cloud provider sync manager</span><br><span class=\"line\">\tif kl.cloudResourceSyncManager != nil &#123;</span><br><span class=\"line\">\t\tgo kl.cloudResourceSyncManager.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tif err := kl.initializeModules(); err != nil &#123;</span><br><span class=\"line\">\t\tkl.recorder.Eventf(kl.nodeRef, v1.EventTypeWarning, events.KubeletSetupFailed, err.Error())</span><br><span class=\"line\">\t\tglog.Fatal(err)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start volume manager</span><br><span class=\"line\">\tgo kl.volumeManager.Run(kl.sourcesReady, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\tif kl.kubeClient != nil &#123;</span><br><span class=\"line\">\t\t// Start syncing node status immediately, this may set up things the runtime needs to run.</span><br><span class=\"line\">\t\tgo wait.Until(kl.syncNodeStatus, kl.nodeStatusUpdateFrequency, wait.NeverStop)</span><br><span class=\"line\">\t\tgo kl.fastStatusUpdateOnce()</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t// start syncing lease</span><br><span class=\"line\">\t\tif utilfeature.DefaultFeatureGate.Enabled(features.NodeLease) &#123;</span><br><span class=\"line\">\t\t\tgo kl.nodeLeaseController.Run(wait.NeverStop)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tgo wait.Until(kl.updateRuntimeUp, 5*time.Second, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start loop to sync iptables util rules</span><br><span class=\"line\">\tif kl.makeIPTablesUtilChains &#123;</span><br><span class=\"line\">\t\tgo wait.Until(kl.syncNetworkUtil, 1*time.Minute, wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start a goroutine responsible for killing pods (that are not properly</span><br><span class=\"line\">\t// handled by pod workers).</span><br><span class=\"line\">\tgo wait.Until(kl.podKiller, 1*time.Second, wait.NeverStop)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start component sync loops.</span><br><span class=\"line\">\tkl.statusManager.Start()</span><br><span class=\"line\">\tkl.probeManager.Start()</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start syncing RuntimeClasses if enabled.</span><br><span class=\"line\">\tif kl.runtimeClassManager != nil &#123;</span><br><span class=\"line\">\t\tgo kl.runtimeClassManager.Run(wait.NeverStop)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t// Start the pod lifecycle event generator.</span><br><span class=\"line\">\tkl.pleg.Start()</span><br><span class=\"line\"></span><br><span class=\"line\">\tkl.syncLoop(updates, kl)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>syncLoop  kubelet (FILE,URL, API-SERVER) pod  Pod </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) &#123;</span><br><span class=\"line\">\tglog.Info(&quot;Starting kubelet main sync loop.&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">\t// syncTicker  pod workers</span><br><span class=\"line\">\tsyncTicker := time.NewTicker(time.Second)</span><br><span class=\"line\">\tdefer syncTicker.Stop()</span><br><span class=\"line\">\thousekeepingTicker := time.NewTicker(housekeepingPeriod)</span><br><span class=\"line\">\tdefer housekeepingTicker.Stop()</span><br><span class=\"line\">\tplegCh := kl.pleg.Watch()</span><br><span class=\"line\">\tconst (</span><br><span class=\"line\">\t\tbase   = 100 * time.Millisecond</span><br><span class=\"line\">\t\tmax    = 5 * time.Second</span><br><span class=\"line\">\t\tfactor = 2</span><br><span class=\"line\">\t)</span><br><span class=\"line\">\tduration := base</span><br><span class=\"line\">\tfor &#123;</span><br><span class=\"line\">\t\tif rs := kl.runtimeState.runtimeErrors(); len(rs) != 0 &#123;</span><br><span class=\"line\">\t\t\tglog.Infof(&quot;skipping pod synchronization - %v&quot;, rs)</span><br><span class=\"line\">\t\t\t// exponential backoff</span><br><span class=\"line\">\t\t\ttime.Sleep(duration)</span><br><span class=\"line\">\t\t\tduration = time.Duration(math.Min(float64(max), factor*float64(duration)))</span><br><span class=\"line\">\t\t\tcontinue</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t// reset backoff if we have a success</span><br><span class=\"line\">\t\tduration = base</span><br><span class=\"line\"></span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t\t// </span><br><span class=\"line\">\t\tif !kl.syncLoopIteration(updates, handler, syncTicker.C, housekeepingTicker.C, plegCh) &#123;</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tkl.syncLoopMonitor.Store(kl.clock.Now())</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>syncLoopIteration()   pod  Handler Handler  dispatchWork </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> kubelet  kubelet </p>\n<p><br><a href=\"http://www.sel.zju.edu.cn/?p=595\" target=\"_blank\" rel=\"noopener\">kubernetes node components  kubelet</a><br><a href=\"https://segmentfault.com/a/1190000008267351\" target=\"_blank\" rel=\"noopener\">Kubelet ():</a><br><a href=\"https://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1/\" target=\"_blank\" rel=\"noopener\">kubelet </a><br><a href=\"https://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/05/02/Kubernetes-kubelet.html\" target=\"_blank\" rel=\"noopener\">kubernetes  kubelet </a><br><a href=\"https://fatsheep9146.github.io/2018/07/08/kubelet%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/\" target=\"_blank\" rel=\"noopener\">kubelet </a></p>\n"},{"title":"kubernetes ","date":"2017-02-12T14:58:00.000Z","type":"kubernetes","_content":"\n1  **kubernetes + docker**  kubernetes  kubernetes kubernetes  `API` \n\n\n## 1kubernetes \n\n[kubernetes](https://github.com/kubernetes/kubernetes)  google  **MesosCoreos** **kubernetes **\n\n\n![kubernetes ](http://upload-images.jianshu.io/upload_images/1262158-e050e035d6fa64ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\nkubernetes etcdmaster  minionetcd  3 etcd  **gitbook**   [etcd3](https://skyao.gitbooks.io/leaning-etcd3/content/documentation/leaning/)master  kube-apiserverkube-controller-managerkube-scheduler minion  kubeletkube-proxydocker \n\n>  > 3.10  kubernetescentos 7  \n\netcd \n\t\n\t# yum install -y etcd \n\t# systemctl start etcd  \n\nmaster \n\n\t# yum install -y kubernetes-master\n\t# systemctl start kube-apiserver \n\t# systemctl start kube-controller-manager \n\t# systemctl start kube-scheduler \n\nminion \n\n\t# yum install -y kubernetes  docker\n\t# systemctl start kubelet \n\t# systemctl start kube-proxy \n\t# systemctl start docker \n\t\n\n## 2kubernetes \n\n minion \n\n minion master  [kubernetes-server-linux-amd64.tar.gz](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md#downloads-for-v160-alpha1)  \n\n****\n\n- 1 docker docker  pod \n- 2kubectl,kube-proxy\n- 3\n- 4\n\n\t\n\t# systemctl stop docker\n\t# which kubectl kube-proxy \n\t/usr/bin/kubectl\n\t/usr/bin/kube-proxy\n\n\t# cp /usr/bin/{kubectl,kube-proxy} /tmp/\n\t# yes | cp bin/{kubectl,kube-proxy} /usr/bin/\n\t\n\t# systemctl status {kubectl,kube-proxy}\n\n\t# systemctl start docker \n\n\n## 3kubeconfig \n\n kubelet  1.4 `systemctl status kubelet`  \n\n\t--api-servers option is deprecated for kubelet, so I am now trying to deploy with simply using --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml\n\n kuconfig  1.5 kubeconfig  yaml  [](http://kubernetes.io/docs/user-guide/kubeconfig-file/)  \n\n**kubeconfig** \n\n\t\tapiVersion: v1\n\t\tclusters:\n\t\t- cluster:\n\t\t    server: http://localhost:8080\n\t\t  name: local-server\n\t\tcontexts:\n\t\t- context:\n\t\t    cluster: local-server\n\t\t    namespace: the-right-prefix\n\t\t    user: myself\n\t\t  name: default-context\n\t\tcurrent-context: default-context\n\t\tkind: Config\n\t\tpreferences: {}\n\t\tusers:\n\t\t- name: myself\n\t\t  user:\n\t\t    password: secret\n\t\t    username: admin\n\n---\n\n\t   # kubelet --kubeconfig=/etc/kubernetes/config --require-kubeconfig=true\n\n\nkubeconfig  kubelet  kubelet  api-server \n\nrequire-kubeconfig true  false true kubeconfig  kubeconfig  api-server  false kubelet  api-servers  api-server \n\n kubeconfig  **issue**[Kubelet won't read apiserver from kubeconfig](https://github.com/kubernetes/kubernetes/issues/36745)\n\n**** kubelet  1.5\n\n* 1 kubeletkube-proxy \n* 2 `/etc/kubernetes/kubelet` :\n\n    `KUBELET_API_SERVER=\"--api-servers=http://127.0.0.1:8080\"`\n\n **KUBELET_ARGS**  \n\n\t--kubeconfig=/etc/kubernetes/kubeconfig --require-kubeconfig=true\n\n yaml  \n\n- 3\n\n---\n## 4 [kubeconfig ](https://kubernetes.io/docs/user-guide/kubeconfig-file/)\n\n### kubernetes .\n\n*  kubelet \n*  token\n* \n*  -  \n\n kubeconfig \n\n nicknames  nickname \n\n kubeconfig \n\n### \n\n\thttp://issue.k8s.io/1755\n\n### kubeconfig  \n\nkubeconfig \n\n\tcurrent-context: federal-context\n\tapiVersion: v1\n\tclusters:\n\t- cluster:\n\t    api-version: v1\n\t    server: http://cow.org:8080\n\t  name: cow-cluster\n\t- cluster:\n\t    certificate-authority: path/to/my/cafile\n\t    server: https://horse.org:4443\n\t  name: horse-cluster\n\t- cluster:\n\t    insecure-skip-tls-verify: true\n\t    server: https://pig.org:443\n\t  name: pig-cluster\n\tcontexts:\n\t- context:\n\t    cluster: horse-cluster\n\t    namespace: chisel-ns\n\t    user: green-user\n\t  name: federal-context\n\t- context:\n\t    cluster: pig-cluster\n\t    namespace: saw-ns\n\t    user: black-user\n\t  name: queen-anne-context\n\tkind: Config\n\tpreferences:\n\t  colors: true\n\tusers:\n\t- name: blue-user\n\t  user:\n\t    token: blue-token\n\t- name: green-user\n\t  user:\n\t    client-certificate: path/to/my/client/cert\n\t    client-key: path/to/my/client/key\n\n### \n\n#### cluster\n\n\tclusters:\n\t- cluster:\n\t    certificate-authority: path/to/my/cafile\n\t    server: https://horse.org:4443\n\t  name: horse-cluster\n\t- cluster:\n\t    insecure-skip-tls-verify: true\n\t    server: https://pig.org:443\n\t  name: pig-cluster\n\n\ncluster  kubernetes  endpoint  kubernetes apiserver  URL insecure-skip-tls-verifytruenickname kubeconfig  kubectl config set-cluster \n\n#### user\n\n\tusers:\n\t- name: blue-user\n\t  user:\n\t    token: blue-token\n\t- name: green-user\n\t  user:\n\t    client-certificate: path/to/my/client/cert\n\t    client-key: path/to/my/client/key\n\n Kubernetes  kubeconfig /nickname// kubectl config set-credentials \n\n### context\n\n\tcontexts:\n\t- context:\n\t    cluster: horse-cluster\n\t    namespace: chisel-ns\n\t    user: green-user\n\t  name: federal-context\n\ncontext  cluster,user,namespace \n clusterusernamespace  none kubeconfig context  kubeconfig  pink-user // kubectl config set-context \n\n#### current-context\n\n\tcurrent-context: federal-context\n\ncurrent-context  cluster,user,namespace  nickname  keykubectl  kubelett  --context=CONTEXT, --cluster=CLUSTER, --user=USER, and/or --namespace=NAMESPACE  kubectl config use-context \n\n#### \n\n\tapiVersion: v1\n\tkind: Config\n\tpreferences:\n\t  colors: true\n\napiVersion  kind \npreferences () kubectl preferences.\n\n###  kubeconfig \n\nkubectl config view  kubeconfig  kubeconfig   --minify  current-context  kubectl config view \n\n###  kubeconfig \n\n kube-up.sh  k8s kubeconfig \n\n kubeconfig \n\n...\n\n--token-auth-file = tokens.csv  api  tokens.csv\n\t\n\tblue-user,blue-user,1\n\tmister-red,mister-red,2\n\napi-server  kubeconfig \n\n*  current-context  green-user kubeconfig  api-server green-user \n*  current-context  blue-user\n* \ngreen-user  blue-user  token\n\n\n### \n\n kubeconfig \n\n1 kubeconfig\n CommandLineLocationkubeconfig \n\n EnvVarLocation$KUBECONFIG CurrentContext  context red-user, red-user  red-user \n\n HomeDirectoryLocation~/.kube/config\n\n2 context \n\n* 1 -  context \n* 2 current-context\n* 3\n\n3 context\n\n* 1 - user cluster \n* 2 context \n* 3\n\n4\n\n* 1 - serverapi-versioncertificate-authority  insecure-skip-tls-verify\n* 2\n* 3 server \n\n5\n\n* 1 12 kubeconfig \n* 2 token\n* 3\n\n6\n\n7kubeconfig  kubeconfig  ~/.kube/config \n\nkubeconfig  kubeconfig \n\n\n###  kubectl config <subcommand>  kubeconfig\n\n kubeconfig  kubectl config  kubectl/kubectl_config.md \n\n\n\n\t$ kubectl config set-credentials myself --username=admin --password=secret\n\t$ kubectl config set-cluster local-server --server=http://localhost:8080\n\t$ kubectl config set-context default-context --cluster=local-server --user=myself\n\t$ kubectl config use-context default-context\n\t$ kubectl config set contexts.default-context.namespace the-right-prefix\n\t$ kubectl config view\n\n\n\n\tapiVersion: v1\n\tclusters:\n\t- cluster:\n\t    server: http://localhost:8080\n\t  name: local-server\n\tcontexts:\n\t- context:\n\t    cluster: local-server\n\t    namespace: the-right-prefix\n\t    user: myself\n\t  name: default-context\n\tcurrent-context: default-context\n\tkind: Config\n\tpreferences: {}\n\tusers:\n\t- name: myself\n\t  user:\n\t    password: secret\n\t    username: admin\n\n kubeconfig \n\n\tapiVersion: v1\n\tclusters:\n\t- cluster:\n\t    server: http://localhost:8080\n\t  name: local-server\n\tcontexts:\n\t- context:\n\t    cluster: local-server\n\t    namespace: the-right-prefix\n\t    user: myself\n\t  name: default-context\n\tcurrent-context: default-context\n\tkind: Config\n\tpreferences: {}\n\tusers:\n\t- name: myself\n\t  user:\n\t    password: secret\n\t    username: admin\n\n\n\n\t$ kubectl config set preferences.colors true\n\t$ kubectl config set-cluster cow-cluster --server=http://cow.org:8080 --api-version=v1\n\t$ kubectl config set-cluster horse-cluster --server=https://horse.org:4443 --certificate-authority=path/to/my/cafile\n\t$ kubectl config set-cluster pig-cluster --server=https://pig.org:443 --insecure-skip-tls-verify=true\n\t$ kubectl config set-credentials blue-user --token=blue-token\n\t$ kubectl config set-credentials green-user --client-certificate=path/to/my/client/cert --client-key=path/to/my/client/key\n\t$ kubectl config set-context queen-anne-context --cluster=pig-cluster --user=black-user --namespace=saw-ns\n\t$ kubectl config set-context federal-context --cluster=horse-cluster --user=green-user --namespace=chisel-ns\n\t$ kubectl config use-context federal-context\n\n\n\n kubeconfig \n\n*  api-server  kubeconfig \n*  api-server endpoint \n*  api-server green-user api-server \n","source":"_posts/kubernetes-learn.md","raw":"---\ntitle: kubernetes \ndate: 2017-02-12 22:58:00\ntype: \"kubernetes\"\n\n---\n\n1  **kubernetes + docker**  kubernetes  kubernetes kubernetes  `API` \n\n\n## 1kubernetes \n\n[kubernetes](https://github.com/kubernetes/kubernetes)  google  **MesosCoreos** **kubernetes **\n\n\n![kubernetes ](http://upload-images.jianshu.io/upload_images/1262158-e050e035d6fa64ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n\nkubernetes etcdmaster  minionetcd  3 etcd  **gitbook**   [etcd3](https://skyao.gitbooks.io/leaning-etcd3/content/documentation/leaning/)master  kube-apiserverkube-controller-managerkube-scheduler minion  kubeletkube-proxydocker \n\n>  > 3.10  kubernetescentos 7  \n\netcd \n\t\n\t# yum install -y etcd \n\t# systemctl start etcd  \n\nmaster \n\n\t# yum install -y kubernetes-master\n\t# systemctl start kube-apiserver \n\t# systemctl start kube-controller-manager \n\t# systemctl start kube-scheduler \n\nminion \n\n\t# yum install -y kubernetes  docker\n\t# systemctl start kubelet \n\t# systemctl start kube-proxy \n\t# systemctl start docker \n\t\n\n## 2kubernetes \n\n minion \n\n minion master  [kubernetes-server-linux-amd64.tar.gz](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md#downloads-for-v160-alpha1)  \n\n****\n\n- 1 docker docker  pod \n- 2kubectl,kube-proxy\n- 3\n- 4\n\n\t\n\t# systemctl stop docker\n\t# which kubectl kube-proxy \n\t/usr/bin/kubectl\n\t/usr/bin/kube-proxy\n\n\t# cp /usr/bin/{kubectl,kube-proxy} /tmp/\n\t# yes | cp bin/{kubectl,kube-proxy} /usr/bin/\n\t\n\t# systemctl status {kubectl,kube-proxy}\n\n\t# systemctl start docker \n\n\n## 3kubeconfig \n\n kubelet  1.4 `systemctl status kubelet`  \n\n\t--api-servers option is deprecated for kubelet, so I am now trying to deploy with simply using --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml\n\n kuconfig  1.5 kubeconfig  yaml  [](http://kubernetes.io/docs/user-guide/kubeconfig-file/)  \n\n**kubeconfig** \n\n\t\tapiVersion: v1\n\t\tclusters:\n\t\t- cluster:\n\t\t    server: http://localhost:8080\n\t\t  name: local-server\n\t\tcontexts:\n\t\t- context:\n\t\t    cluster: local-server\n\t\t    namespace: the-right-prefix\n\t\t    user: myself\n\t\t  name: default-context\n\t\tcurrent-context: default-context\n\t\tkind: Config\n\t\tpreferences: {}\n\t\tusers:\n\t\t- name: myself\n\t\t  user:\n\t\t    password: secret\n\t\t    username: admin\n\n---\n\n\t   # kubelet --kubeconfig=/etc/kubernetes/config --require-kubeconfig=true\n\n\nkubeconfig  kubelet  kubelet  api-server \n\nrequire-kubeconfig true  false true kubeconfig  kubeconfig  api-server  false kubelet  api-servers  api-server \n\n kubeconfig  **issue**[Kubelet won't read apiserver from kubeconfig](https://github.com/kubernetes/kubernetes/issues/36745)\n\n**** kubelet  1.5\n\n* 1 kubeletkube-proxy \n* 2 `/etc/kubernetes/kubelet` :\n\n    `KUBELET_API_SERVER=\"--api-servers=http://127.0.0.1:8080\"`\n\n **KUBELET_ARGS**  \n\n\t--kubeconfig=/etc/kubernetes/kubeconfig --require-kubeconfig=true\n\n yaml  \n\n- 3\n\n---\n## 4 [kubeconfig ](https://kubernetes.io/docs/user-guide/kubeconfig-file/)\n\n### kubernetes .\n\n*  kubelet \n*  token\n* \n*  -  \n\n kubeconfig \n\n nicknames  nickname \n\n kubeconfig \n\n### \n\n\thttp://issue.k8s.io/1755\n\n### kubeconfig  \n\nkubeconfig \n\n\tcurrent-context: federal-context\n\tapiVersion: v1\n\tclusters:\n\t- cluster:\n\t    api-version: v1\n\t    server: http://cow.org:8080\n\t  name: cow-cluster\n\t- cluster:\n\t    certificate-authority: path/to/my/cafile\n\t    server: https://horse.org:4443\n\t  name: horse-cluster\n\t- cluster:\n\t    insecure-skip-tls-verify: true\n\t    server: https://pig.org:443\n\t  name: pig-cluster\n\tcontexts:\n\t- context:\n\t    cluster: horse-cluster\n\t    namespace: chisel-ns\n\t    user: green-user\n\t  name: federal-context\n\t- context:\n\t    cluster: pig-cluster\n\t    namespace: saw-ns\n\t    user: black-user\n\t  name: queen-anne-context\n\tkind: Config\n\tpreferences:\n\t  colors: true\n\tusers:\n\t- name: blue-user\n\t  user:\n\t    token: blue-token\n\t- name: green-user\n\t  user:\n\t    client-certificate: path/to/my/client/cert\n\t    client-key: path/to/my/client/key\n\n### \n\n#### cluster\n\n\tclusters:\n\t- cluster:\n\t    certificate-authority: path/to/my/cafile\n\t    server: https://horse.org:4443\n\t  name: horse-cluster\n\t- cluster:\n\t    insecure-skip-tls-verify: true\n\t    server: https://pig.org:443\n\t  name: pig-cluster\n\n\ncluster  kubernetes  endpoint  kubernetes apiserver  URL insecure-skip-tls-verifytruenickname kubeconfig  kubectl config set-cluster \n\n#### user\n\n\tusers:\n\t- name: blue-user\n\t  user:\n\t    token: blue-token\n\t- name: green-user\n\t  user:\n\t    client-certificate: path/to/my/client/cert\n\t    client-key: path/to/my/client/key\n\n Kubernetes  kubeconfig /nickname// kubectl config set-credentials \n\n### context\n\n\tcontexts:\n\t- context:\n\t    cluster: horse-cluster\n\t    namespace: chisel-ns\n\t    user: green-user\n\t  name: federal-context\n\ncontext  cluster,user,namespace \n clusterusernamespace  none kubeconfig context  kubeconfig  pink-user // kubectl config set-context \n\n#### current-context\n\n\tcurrent-context: federal-context\n\ncurrent-context  cluster,user,namespace  nickname  keykubectl  kubelett  --context=CONTEXT, --cluster=CLUSTER, --user=USER, and/or --namespace=NAMESPACE  kubectl config use-context \n\n#### \n\n\tapiVersion: v1\n\tkind: Config\n\tpreferences:\n\t  colors: true\n\napiVersion  kind \npreferences () kubectl preferences.\n\n###  kubeconfig \n\nkubectl config view  kubeconfig  kubeconfig   --minify  current-context  kubectl config view \n\n###  kubeconfig \n\n kube-up.sh  k8s kubeconfig \n\n kubeconfig \n\n...\n\n--token-auth-file = tokens.csv  api  tokens.csv\n\t\n\tblue-user,blue-user,1\n\tmister-red,mister-red,2\n\napi-server  kubeconfig \n\n*  current-context  green-user kubeconfig  api-server green-user \n*  current-context  blue-user\n* \ngreen-user  blue-user  token\n\n\n### \n\n kubeconfig \n\n1 kubeconfig\n CommandLineLocationkubeconfig \n\n EnvVarLocation$KUBECONFIG CurrentContext  context red-user, red-user  red-user \n\n HomeDirectoryLocation~/.kube/config\n\n2 context \n\n* 1 -  context \n* 2 current-context\n* 3\n\n3 context\n\n* 1 - user cluster \n* 2 context \n* 3\n\n4\n\n* 1 - serverapi-versioncertificate-authority  insecure-skip-tls-verify\n* 2\n* 3 server \n\n5\n\n* 1 12 kubeconfig \n* 2 token\n* 3\n\n6\n\n7kubeconfig  kubeconfig  ~/.kube/config \n\nkubeconfig  kubeconfig \n\n\n###  kubectl config <subcommand>  kubeconfig\n\n kubeconfig  kubectl config  kubectl/kubectl_config.md \n\n\n\n\t$ kubectl config set-credentials myself --username=admin --password=secret\n\t$ kubectl config set-cluster local-server --server=http://localhost:8080\n\t$ kubectl config set-context default-context --cluster=local-server --user=myself\n\t$ kubectl config use-context default-context\n\t$ kubectl config set contexts.default-context.namespace the-right-prefix\n\t$ kubectl config view\n\n\n\n\tapiVersion: v1\n\tclusters:\n\t- cluster:\n\t    server: http://localhost:8080\n\t  name: local-server\n\tcontexts:\n\t- context:\n\t    cluster: local-server\n\t    namespace: the-right-prefix\n\t    user: myself\n\t  name: default-context\n\tcurrent-context: default-context\n\tkind: Config\n\tpreferences: {}\n\tusers:\n\t- name: myself\n\t  user:\n\t    password: secret\n\t    username: admin\n\n kubeconfig \n\n\tapiVersion: v1\n\tclusters:\n\t- cluster:\n\t    server: http://localhost:8080\n\t  name: local-server\n\tcontexts:\n\t- context:\n\t    cluster: local-server\n\t    namespace: the-right-prefix\n\t    user: myself\n\t  name: default-context\n\tcurrent-context: default-context\n\tkind: Config\n\tpreferences: {}\n\tusers:\n\t- name: myself\n\t  user:\n\t    password: secret\n\t    username: admin\n\n\n\n\t$ kubectl config set preferences.colors true\n\t$ kubectl config set-cluster cow-cluster --server=http://cow.org:8080 --api-version=v1\n\t$ kubectl config set-cluster horse-cluster --server=https://horse.org:4443 --certificate-authority=path/to/my/cafile\n\t$ kubectl config set-cluster pig-cluster --server=https://pig.org:443 --insecure-skip-tls-verify=true\n\t$ kubectl config set-credentials blue-user --token=blue-token\n\t$ kubectl config set-credentials green-user --client-certificate=path/to/my/client/cert --client-key=path/to/my/client/key\n\t$ kubectl config set-context queen-anne-context --cluster=pig-cluster --user=black-user --namespace=saw-ns\n\t$ kubectl config set-context federal-context --cluster=horse-cluster --user=green-user --namespace=chisel-ns\n\t$ kubectl config use-context federal-context\n\n\n\n kubeconfig \n\n*  api-server  kubeconfig \n*  api-server endpoint \n*  api-server green-user api-server \n","slug":"kubernetes-learn","published":1,"updated":"2018-12-08T10:29:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjugyyt070014tadvu0j5u3pn","content":"<p>1  <strong>kubernetes + docker</strong>  kubernetes  kubernetes kubernetes  <code>API</code> </p>\n<h2 id=\"1kubernetes-\"><a href=\"#1kubernetes-\" class=\"headerlink\" title=\"1kubernetes \"></a>1kubernetes </h2><p><a href=\"https://github.com/kubernetes/kubernetes\" target=\"_blank\" rel=\"noopener\">kubernetes</a>  google  <strong>MesosCoreos</strong> <strong>kubernetes </strong></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1262158-e050e035d6fa64ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubernetes \"></p>\n<p>kubernetes etcdmaster  minionetcd  3 etcd  <strong>gitbook</strong>   <a href=\"https://skyao.gitbooks.io/leaning-etcd3/content/documentation/leaning/\" target=\"_blank\" rel=\"noopener\">etcd3</a>master  kube-apiserverkube-controller-managerkube-scheduler minion  kubeletkube-proxydocker </p>\n<blockquote>\n<p> &gt; 3.10  kubernetescentos 7  </p>\n</blockquote>\n<p>etcd </p>\n<pre><code># yum install -y etcd \n# systemctl start etcd  \n</code></pre><p>master </p>\n<pre><code># yum install -y kubernetes-master\n# systemctl start kube-apiserver \n# systemctl start kube-controller-manager \n# systemctl start kube-scheduler \n</code></pre><p>minion </p>\n<pre><code># yum install -y kubernetes  docker\n# systemctl start kubelet \n# systemctl start kube-proxy \n# systemctl start docker \n</code></pre><h2 id=\"2kubernetes-\"><a href=\"#2kubernetes-\" class=\"headerlink\" title=\"2kubernetes \"></a>2kubernetes </h2><p> minion </p>\n<p> minion master  <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md#downloads-for-v160-alpha1\" target=\"_blank\" rel=\"noopener\">kubernetes-server-linux-amd64.tar.gz</a>  </p>\n<p><strong></strong></p>\n<ul>\n<li>1 docker docker  pod </li>\n<li>2kubectl,kube-proxy</li>\n<li>3</li>\n<li>4</li>\n</ul>\n<pre><code># systemctl stop docker\n# which kubectl kube-proxy \n/usr/bin/kubectl\n/usr/bin/kube-proxy\n\n# cp /usr/bin/{kubectl,kube-proxy} /tmp/\n# yes | cp bin/{kubectl,kube-proxy} /usr/bin/\n\n# systemctl status {kubectl,kube-proxy}\n\n# systemctl start docker \n</code></pre><h2 id=\"3kubeconfig-\"><a href=\"#3kubeconfig-\" class=\"headerlink\" title=\"3kubeconfig \"></a>3kubeconfig </h2><p> kubelet  1.4 <code>systemctl status kubelet</code>  </p>\n<pre><code>--api-servers option is deprecated for kubelet, so I am now trying to deploy with simply using --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml\n</code></pre><p> kuconfig  1.5 kubeconfig  yaml  <a href=\"http://kubernetes.io/docs/user-guide/kubeconfig-file/\" target=\"_blank\" rel=\"noopener\"></a>  </p>\n<p><strong>kubeconfig</strong> </p>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    server: http://localhost:8080\n  name: local-server\ncontexts:\n- context:\n    cluster: local-server\n    namespace: the-right-prefix\n    user: myself\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers:\n- name: myself\n  user:\n    password: secret\n    username: admin\n</code></pre><hr>\n<pre><code># kubelet --kubeconfig=/etc/kubernetes/config --require-kubeconfig=true\n</code></pre><p>kubeconfig  kubelet  kubelet  api-server </p>\n<p>require-kubeconfig true  false true kubeconfig  kubeconfig  api-server  false kubelet  api-servers  api-server </p>\n<p> kubeconfig  <strong>issue</strong><a href=\"https://github.com/kubernetes/kubernetes/issues/36745\" target=\"_blank\" rel=\"noopener\">Kubelet wont read apiserver from kubeconfig</a></p>\n<p><strong></strong> kubelet  1.5</p>\n<ul>\n<li>1 kubeletkube-proxy </li>\n<li><p>2 <code>/etc/kubernetes/kubelet</code> :</p>\n<p>  <code>KUBELET_API_SERVER=&quot;--api-servers=http://127.0.0.1:8080&quot;</code></p>\n</li>\n</ul>\n<p> <strong>KUBELET_ARGS</strong>  </p>\n<pre><code>--kubeconfig=/etc/kubernetes/kubeconfig --require-kubeconfig=true\n</code></pre><p> yaml  </p>\n<ul>\n<li>3</li>\n</ul>\n<hr>\n<h2 id=\"4-kubeconfig-\"><a href=\"#4-kubeconfig-\" class=\"headerlink\" title=\"4 kubeconfig \"></a>4 <a href=\"https://kubernetes.io/docs/user-guide/kubeconfig-file/\" target=\"_blank\" rel=\"noopener\">kubeconfig </a></h2><h3 id=\"kubernetes-\"><a href=\"#kubernetes-\" class=\"headerlink\" title=\"kubernetes .\"></a>kubernetes .</h3><ul>\n<li> kubelet </li>\n<li> token</li>\n<li></li>\n<li> -  </li>\n</ul>\n<p> kubeconfig </p>\n<p> nicknames  nickname </p>\n<p> kubeconfig </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><pre><code>http://issue.k8s.io/1755\n</code></pre><h3 id=\"kubeconfig-\"><a href=\"#kubeconfig-\" class=\"headerlink\" title=\"kubeconfig \"></a>kubeconfig </h3><p>kubeconfig </p>\n<pre><code>current-context: federal-context\napiVersion: v1\nclusters:\n- cluster:\n    api-version: v1\n    server: http://cow.org:8080\n  name: cow-cluster\n- cluster:\n    certificate-authority: path/to/my/cafile\n    server: https://horse.org:4443\n  name: horse-cluster\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://pig.org:443\n  name: pig-cluster\ncontexts:\n- context:\n    cluster: horse-cluster\n    namespace: chisel-ns\n    user: green-user\n  name: federal-context\n- context:\n    cluster: pig-cluster\n    namespace: saw-ns\n    user: black-user\n  name: queen-anne-context\nkind: Config\npreferences:\n  colors: true\nusers:\n- name: blue-user\n  user:\n    token: blue-token\n- name: green-user\n  user:\n    client-certificate: path/to/my/client/cert\n    client-key: path/to/my/client/key\n</code></pre><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"cluster\"><a href=\"#cluster\" class=\"headerlink\" title=\"cluster\"></a>cluster</h4><pre><code>clusters:\n- cluster:\n    certificate-authority: path/to/my/cafile\n    server: https://horse.org:4443\n  name: horse-cluster\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://pig.org:443\n  name: pig-cluster\n</code></pre><p>cluster  kubernetes  endpoint  kubernetes apiserver  URL insecure-skip-tls-verifytruenickname kubeconfig  kubectl config set-cluster </p>\n<h4 id=\"user\"><a href=\"#user\" class=\"headerlink\" title=\"user\"></a>user</h4><pre><code>users:\n- name: blue-user\n  user:\n    token: blue-token\n- name: green-user\n  user:\n    client-certificate: path/to/my/client/cert\n    client-key: path/to/my/client/key\n</code></pre><p> Kubernetes  kubeconfig /nickname// kubectl config set-credentials </p>\n<h3 id=\"context\"><a href=\"#context\" class=\"headerlink\" title=\"context\"></a>context</h3><pre><code>contexts:\n- context:\n    cluster: horse-cluster\n    namespace: chisel-ns\n    user: green-user\n  name: federal-context\n</code></pre><p>context  cluster,user,namespace <br> clusterusernamespace  none kubeconfig context  kubeconfig  pink-user // kubectl config set-context </p>\n<h4 id=\"current-context\"><a href=\"#current-context\" class=\"headerlink\" title=\"current-context\"></a>current-context</h4><pre><code>current-context: federal-context\n</code></pre><p>current-context  cluster,user,namespace  nickname  keykubectl  kubelett  context=CONTEXT, cluster=CLUSTER, user=USER, and/or namespace=NAMESPACE  kubectl config use-context </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><pre><code>apiVersion: v1\nkind: Config\npreferences:\n  colors: true\n</code></pre><p>apiVersion  kind <br>preferences () kubectl preferences.</p>\n<h3 id=\"-kubeconfig-\"><a href=\"#-kubeconfig-\" class=\"headerlink\" title=\" kubeconfig \"></a> kubeconfig </h3><p>kubectl config view  kubeconfig  kubeconfig   minify  current-context  kubectl config view </p>\n<h3 id=\"-kubeconfig-\"><a href=\"#-kubeconfig-\" class=\"headerlink\" title=\" kubeconfig \"></a> kubeconfig </h3><p> kube-up.sh  k8s kubeconfig </p>\n<p> kubeconfig </p>\n<p></p>\n<p>token-auth-file = tokens.csv  api  tokens.csv</p>\n<pre><code>blue-user,blue-user,1\nmister-red,mister-red,2\n</code></pre><p>api-server  kubeconfig </p>\n<ul>\n<li> current-context  green-user kubeconfig  api-server green-user </li>\n<li> current-context  blue-user</li>\n<li>green-user  blue-user  token</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> kubeconfig </p>\n<p>1 kubeconfig<br> CommandLineLocationkubeconfig </p>\n<p> EnvVarLocation$KUBECONFIG CurrentContext  context red-user, red-user  red-user </p>\n<p> HomeDirectoryLocation~/.kube/config</p>\n<p>2 context </p>\n<ul>\n<li>1 -  context </li>\n<li>2 current-context</li>\n<li>3</li>\n</ul>\n<p>3 context</p>\n<ul>\n<li>1 - user cluster </li>\n<li>2 context </li>\n<li>3</li>\n</ul>\n<p>4</p>\n<ul>\n<li>1 - serverapi-versioncertificate-authority  insecure-skip-tls-verify</li>\n<li>2</li>\n<li>3 server </li>\n</ul>\n<p>5</p>\n<ul>\n<li>1 12 kubeconfig </li>\n<li>2 token</li>\n<li>3</li>\n</ul>\n<p>6</p>\n<p>7kubeconfig  kubeconfig  ~/.kube/config </p>\n<p>kubeconfig  kubeconfig </p>\n<h3 id=\"-kubectl-config--kubeconfig\"><a href=\"#-kubectl-config--kubeconfig\" class=\"headerlink\" title=\" kubectl config   kubeconfig\"></a> kubectl config <subcommand>  kubeconfig</subcommand></h3><p> kubeconfig  kubectl config  kubectl/kubectl_config.md </p>\n<p></p>\n<pre><code>$ kubectl config set-credentials myself --username=admin --password=secret\n$ kubectl config set-cluster local-server --server=http://localhost:8080\n$ kubectl config set-context default-context --cluster=local-server --user=myself\n$ kubectl config use-context default-context\n$ kubectl config set contexts.default-context.namespace the-right-prefix\n$ kubectl config view\n</code></pre><p></p>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    server: http://localhost:8080\n  name: local-server\ncontexts:\n- context:\n    cluster: local-server\n    namespace: the-right-prefix\n    user: myself\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers:\n- name: myself\n  user:\n    password: secret\n    username: admin\n</code></pre><p> kubeconfig </p>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    server: http://localhost:8080\n  name: local-server\ncontexts:\n- context:\n    cluster: local-server\n    namespace: the-right-prefix\n    user: myself\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers:\n- name: myself\n  user:\n    password: secret\n    username: admin\n</code></pre><p></p>\n<pre><code>$ kubectl config set preferences.colors true\n$ kubectl config set-cluster cow-cluster --server=http://cow.org:8080 --api-version=v1\n$ kubectl config set-cluster horse-cluster --server=https://horse.org:4443 --certificate-authority=path/to/my/cafile\n$ kubectl config set-cluster pig-cluster --server=https://pig.org:443 --insecure-skip-tls-verify=true\n$ kubectl config set-credentials blue-user --token=blue-token\n$ kubectl config set-credentials green-user --client-certificate=path/to/my/client/cert --client-key=path/to/my/client/key\n$ kubectl config set-context queen-anne-context --cluster=pig-cluster --user=black-user --namespace=saw-ns\n$ kubectl config set-context federal-context --cluster=horse-cluster --user=green-user --namespace=chisel-ns\n$ kubectl config use-context federal-context\n</code></pre><p></p>\n<p> kubeconfig </p>\n<ul>\n<li> api-server  kubeconfig </li>\n<li> api-server endpoint </li>\n<li> api-server green-user api-server </li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>1  <strong>kubernetes + docker</strong>  kubernetes  kubernetes kubernetes  <code>API</code> </p>\n<h2 id=\"1kubernetes-\"><a href=\"#1kubernetes-\" class=\"headerlink\" title=\"1kubernetes \"></a>1kubernetes </h2><p><a href=\"https://github.com/kubernetes/kubernetes\" target=\"_blank\" rel=\"noopener\">kubernetes</a>  google  <strong>MesosCoreos</strong> <strong>kubernetes </strong></p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1262158-e050e035d6fa64ed.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"kubernetes \"></p>\n<p>kubernetes etcdmaster  minionetcd  3 etcd  <strong>gitbook</strong>   <a href=\"https://skyao.gitbooks.io/leaning-etcd3/content/documentation/leaning/\" target=\"_blank\" rel=\"noopener\">etcd3</a>master  kube-apiserverkube-controller-managerkube-scheduler minion  kubeletkube-proxydocker </p>\n<blockquote>\n<p> &gt; 3.10  kubernetescentos 7  </p>\n</blockquote>\n<p>etcd </p>\n<pre><code># yum install -y etcd \n# systemctl start etcd  \n</code></pre><p>master </p>\n<pre><code># yum install -y kubernetes-master\n# systemctl start kube-apiserver \n# systemctl start kube-controller-manager \n# systemctl start kube-scheduler \n</code></pre><p>minion </p>\n<pre><code># yum install -y kubernetes  docker\n# systemctl start kubelet \n# systemctl start kube-proxy \n# systemctl start docker \n</code></pre><h2 id=\"2kubernetes-\"><a href=\"#2kubernetes-\" class=\"headerlink\" title=\"2kubernetes \"></a>2kubernetes </h2><p> minion </p>\n<p> minion master  <a href=\"https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md#downloads-for-v160-alpha1\" target=\"_blank\" rel=\"noopener\">kubernetes-server-linux-amd64.tar.gz</a>  </p>\n<p><strong></strong></p>\n<ul>\n<li>1 docker docker  pod </li>\n<li>2kubectl,kube-proxy</li>\n<li>3</li>\n<li>4</li>\n</ul>\n<pre><code># systemctl stop docker\n# which kubectl kube-proxy \n/usr/bin/kubectl\n/usr/bin/kube-proxy\n\n# cp /usr/bin/{kubectl,kube-proxy} /tmp/\n# yes | cp bin/{kubectl,kube-proxy} /usr/bin/\n\n# systemctl status {kubectl,kube-proxy}\n\n# systemctl start docker \n</code></pre><h2 id=\"3kubeconfig-\"><a href=\"#3kubeconfig-\" class=\"headerlink\" title=\"3kubeconfig \"></a>3kubeconfig </h2><p> kubelet  1.4 <code>systemctl status kubelet</code>  </p>\n<pre><code>--api-servers option is deprecated for kubelet, so I am now trying to deploy with simply using --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml\n</code></pre><p> kuconfig  1.5 kubeconfig  yaml  <a href=\"http://kubernetes.io/docs/user-guide/kubeconfig-file/\" target=\"_blank\" rel=\"noopener\"></a>  </p>\n<p><strong>kubeconfig</strong> </p>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    server: http://localhost:8080\n  name: local-server\ncontexts:\n- context:\n    cluster: local-server\n    namespace: the-right-prefix\n    user: myself\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers:\n- name: myself\n  user:\n    password: secret\n    username: admin\n</code></pre><hr>\n<pre><code># kubelet --kubeconfig=/etc/kubernetes/config --require-kubeconfig=true\n</code></pre><p>kubeconfig  kubelet  kubelet  api-server </p>\n<p>require-kubeconfig true  false true kubeconfig  kubeconfig  api-server  false kubelet  api-servers  api-server </p>\n<p> kubeconfig  <strong>issue</strong><a href=\"https://github.com/kubernetes/kubernetes/issues/36745\" target=\"_blank\" rel=\"noopener\">Kubelet wont read apiserver from kubeconfig</a></p>\n<p><strong></strong> kubelet  1.5</p>\n<ul>\n<li>1 kubeletkube-proxy </li>\n<li><p>2 <code>/etc/kubernetes/kubelet</code> :</p>\n<p>  <code>KUBELET_API_SERVER=&quot;--api-servers=http://127.0.0.1:8080&quot;</code></p>\n</li>\n</ul>\n<p> <strong>KUBELET_ARGS</strong>  </p>\n<pre><code>--kubeconfig=/etc/kubernetes/kubeconfig --require-kubeconfig=true\n</code></pre><p> yaml  </p>\n<ul>\n<li>3</li>\n</ul>\n<hr>\n<h2 id=\"4-kubeconfig-\"><a href=\"#4-kubeconfig-\" class=\"headerlink\" title=\"4 kubeconfig \"></a>4 <a href=\"https://kubernetes.io/docs/user-guide/kubeconfig-file/\" target=\"_blank\" rel=\"noopener\">kubeconfig </a></h2><h3 id=\"kubernetes-\"><a href=\"#kubernetes-\" class=\"headerlink\" title=\"kubernetes .\"></a>kubernetes .</h3><ul>\n<li> kubelet </li>\n<li> token</li>\n<li></li>\n<li> -  </li>\n</ul>\n<p> kubeconfig </p>\n<p> nicknames  nickname </p>\n<p> kubeconfig </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><pre><code>http://issue.k8s.io/1755\n</code></pre><h3 id=\"kubeconfig-\"><a href=\"#kubeconfig-\" class=\"headerlink\" title=\"kubeconfig \"></a>kubeconfig </h3><p>kubeconfig </p>\n<pre><code>current-context: federal-context\napiVersion: v1\nclusters:\n- cluster:\n    api-version: v1\n    server: http://cow.org:8080\n  name: cow-cluster\n- cluster:\n    certificate-authority: path/to/my/cafile\n    server: https://horse.org:4443\n  name: horse-cluster\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://pig.org:443\n  name: pig-cluster\ncontexts:\n- context:\n    cluster: horse-cluster\n    namespace: chisel-ns\n    user: green-user\n  name: federal-context\n- context:\n    cluster: pig-cluster\n    namespace: saw-ns\n    user: black-user\n  name: queen-anne-context\nkind: Config\npreferences:\n  colors: true\nusers:\n- name: blue-user\n  user:\n    token: blue-token\n- name: green-user\n  user:\n    client-certificate: path/to/my/client/cert\n    client-key: path/to/my/client/key\n</code></pre><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h4 id=\"cluster\"><a href=\"#cluster\" class=\"headerlink\" title=\"cluster\"></a>cluster</h4><pre><code>clusters:\n- cluster:\n    certificate-authority: path/to/my/cafile\n    server: https://horse.org:4443\n  name: horse-cluster\n- cluster:\n    insecure-skip-tls-verify: true\n    server: https://pig.org:443\n  name: pig-cluster\n</code></pre><p>cluster  kubernetes  endpoint  kubernetes apiserver  URL insecure-skip-tls-verifytruenickname kubeconfig  kubectl config set-cluster </p>\n<h4 id=\"user\"><a href=\"#user\" class=\"headerlink\" title=\"user\"></a>user</h4><pre><code>users:\n- name: blue-user\n  user:\n    token: blue-token\n- name: green-user\n  user:\n    client-certificate: path/to/my/client/cert\n    client-key: path/to/my/client/key\n</code></pre><p> Kubernetes  kubeconfig /nickname// kubectl config set-credentials </p>\n<h3 id=\"context\"><a href=\"#context\" class=\"headerlink\" title=\"context\"></a>context</h3><pre><code>contexts:\n- context:\n    cluster: horse-cluster\n    namespace: chisel-ns\n    user: green-user\n  name: federal-context\n</code></pre><p>context  cluster,user,namespace <br> clusterusernamespace  none kubeconfig context  kubeconfig  pink-user // kubectl config set-context </p>\n<h4 id=\"current-context\"><a href=\"#current-context\" class=\"headerlink\" title=\"current-context\"></a>current-context</h4><pre><code>current-context: federal-context\n</code></pre><p>current-context  cluster,user,namespace  nickname  keykubectl  kubelett  context=CONTEXT, cluster=CLUSTER, user=USER, and/or namespace=NAMESPACE  kubectl config use-context </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><pre><code>apiVersion: v1\nkind: Config\npreferences:\n  colors: true\n</code></pre><p>apiVersion  kind <br>preferences () kubectl preferences.</p>\n<h3 id=\"-kubeconfig-\"><a href=\"#-kubeconfig-\" class=\"headerlink\" title=\" kubeconfig \"></a> kubeconfig </h3><p>kubectl config view  kubeconfig  kubeconfig   minify  current-context  kubectl config view </p>\n<h3 id=\"-kubeconfig-\"><a href=\"#-kubeconfig-\" class=\"headerlink\" title=\" kubeconfig \"></a> kubeconfig </h3><p> kube-up.sh  k8s kubeconfig </p>\n<p> kubeconfig </p>\n<p></p>\n<p>token-auth-file = tokens.csv  api  tokens.csv</p>\n<pre><code>blue-user,blue-user,1\nmister-red,mister-red,2\n</code></pre><p>api-server  kubeconfig </p>\n<ul>\n<li> current-context  green-user kubeconfig  api-server green-user </li>\n<li> current-context  blue-user</li>\n<li>green-user  blue-user  token</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> kubeconfig </p>\n<p>1 kubeconfig<br> CommandLineLocationkubeconfig </p>\n<p> EnvVarLocation$KUBECONFIG CurrentContext  context red-user, red-user  red-user </p>\n<p> HomeDirectoryLocation~/.kube/config</p>\n<p>2 context </p>\n<ul>\n<li>1 -  context </li>\n<li>2 current-context</li>\n<li>3</li>\n</ul>\n<p>3 context</p>\n<ul>\n<li>1 - user cluster </li>\n<li>2 context </li>\n<li>3</li>\n</ul>\n<p>4</p>\n<ul>\n<li>1 - serverapi-versioncertificate-authority  insecure-skip-tls-verify</li>\n<li>2</li>\n<li>3 server </li>\n</ul>\n<p>5</p>\n<ul>\n<li>1 12 kubeconfig </li>\n<li>2 token</li>\n<li>3</li>\n</ul>\n<p>6</p>\n<p>7kubeconfig  kubeconfig  ~/.kube/config </p>\n<p>kubeconfig  kubeconfig </p>\n<h3 id=\"-kubectl-config--kubeconfig\"><a href=\"#-kubectl-config--kubeconfig\" class=\"headerlink\" title=\" kubectl config   kubeconfig\"></a> kubectl config <subcommand>  kubeconfig</subcommand></h3><p> kubeconfig  kubectl config  kubectl/kubectl_config.md </p>\n<p></p>\n<pre><code>$ kubectl config set-credentials myself --username=admin --password=secret\n$ kubectl config set-cluster local-server --server=http://localhost:8080\n$ kubectl config set-context default-context --cluster=local-server --user=myself\n$ kubectl config use-context default-context\n$ kubectl config set contexts.default-context.namespace the-right-prefix\n$ kubectl config view\n</code></pre><p></p>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    server: http://localhost:8080\n  name: local-server\ncontexts:\n- context:\n    cluster: local-server\n    namespace: the-right-prefix\n    user: myself\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers:\n- name: myself\n  user:\n    password: secret\n    username: admin\n</code></pre><p> kubeconfig </p>\n<pre><code>apiVersion: v1\nclusters:\n- cluster:\n    server: http://localhost:8080\n  name: local-server\ncontexts:\n- context:\n    cluster: local-server\n    namespace: the-right-prefix\n    user: myself\n  name: default-context\ncurrent-context: default-context\nkind: Config\npreferences: {}\nusers:\n- name: myself\n  user:\n    password: secret\n    username: admin\n</code></pre><p></p>\n<pre><code>$ kubectl config set preferences.colors true\n$ kubectl config set-cluster cow-cluster --server=http://cow.org:8080 --api-version=v1\n$ kubectl config set-cluster horse-cluster --server=https://horse.org:4443 --certificate-authority=path/to/my/cafile\n$ kubectl config set-cluster pig-cluster --server=https://pig.org:443 --insecure-skip-tls-verify=true\n$ kubectl config set-credentials blue-user --token=blue-token\n$ kubectl config set-credentials green-user --client-certificate=path/to/my/client/cert --client-key=path/to/my/client/key\n$ kubectl config set-context queen-anne-context --cluster=pig-cluster --user=black-user --namespace=saw-ns\n$ kubectl config set-context federal-context --cluster=horse-cluster --user=green-user --namespace=chisel-ns\n$ kubectl config use-context federal-context\n</code></pre><p></p>\n<p> kubeconfig </p>\n<ul>\n<li> api-server  kubeconfig </li>\n<li> api-server endpoint </li>\n<li> api-server green-user api-server </li>\n</ul>\n"},{"title":" kubernetes ","date":"2019-04-22T14:43:30.000Z","type":"kubernetes","_content":"\n kubernetes  kubernetes  cAdvisorHeapstermetrics-serverkube-state-metricsPrometheus  Dashboard PrometheusGrafana  kube-dashboard  prometheus \n\n> kubernetes v1.12\n\n### kubernetes-dashboard \n\n#### 1 kubernetes-dashboard\n\n```golang\n$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml\n\n$ kubectl get svc -n kube-system | grep kubernetes-dashboard\nkubernetes-dashboard   ClusterIP    10.101.203.44   <none>        443/TCP    2h\n\n$ kubectl get pod -n kube-system | grep kubernetes-dashboard\nkubernetes-dashboard-65c76f6c97-8npsv    1/1     Running       0          2h\n```\n\n> [k8s-system-images](https://github.com/gosoon/k8s-system-images)\n\n#### 2 nodePort  kubernetes-dashboard\n\nnodeport kubernetes-dashboard  clusterIP  kubernetes-dashboard svc  nodePort \n\n```\n$ kubectl edit svc -n kube-system\n\t...\n  spec:\n    clusterIP: 10.101.203.44\n    externalTrafficPolicy: Cluster\n    ports:\n    - nodePort: 8004  //  nodeport \n      port: 443\n      protocol: TCP\n      targetPort: 8443\n    selector:\n      k8s-app: kubernetes-dashboard\n    sessionAffinity: None\n    type: NodePort   //  ClusterIP  NodePort\n    ...\n```\n\nnodePort  30000-32767 apiserver  `--service-node-port-range`  nodePort `--service-node-port-range 8000-9000`\n\n#### 3 kubernetes-dashboard \n\n `kubernetes-dashboard-admin.yaml`\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: dashboard-admin\n  namespace: kube-system\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: dashboard-admin\nsubjects:\n  - kind: ServiceAccount\n    name: dashboard-admin\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io\n```\n\n token\n\n```\n$ kubectl apply -f kubernetes-dashboard-admin.yaml\n\n$ kubectl describe secrets `kubectl get secret -n kube-system | grep dashboard-admin | awk '{print $1}'` -n kube-system\n\nName:         dashboard-admin-token-hrhfd\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  kubernetes.io/service-account.name: dashboard-admin\n              kubernetes.io/service-account.uid: 76805bdb-6047-11e9-ba0d-525400c322d9\n\nType:  kubernetes.io/service-account-token\n\nData\n====\nca.crt:     1025 bytes\nnamespace:  11 bytes\ntoken:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4taHJoZmQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNzY4MDViZGItNjA0Ny0xMWU5LWJhMGQtNTI1NDAwYzMyMmQ5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.hJJRyp_O4sGvIULj3BhqidCkkPnD4A2AtnpkXJoEPCALaaQHC8zhCA5-nDNlo2fiEggZ02UZPwiyGxKKFPC57UlKhjTf5zYcMIhELVXlj5FdBmjzCZcCHVFF4tj_rCoOFlZi6fQ3vNCcX8CtLxX_OsH1YXaFVuUmR1gYm97hbyuO382_k3tFIPXFP3QG8zUtc_7QMkeMNEakJZLCvkW8xdlaCuC-GVAMhZl5Kq1MSthuF-8HY7KaXhvqQzfD4DQZrdQ7vf_7NG3rdvhsj8nQ__TTe1W0RjqwkQuxg5YdE4gbAsxwJjkek-N0K9HfnZhkS9WosaUaUe9pZaGZ9akqyQ\n```\n\ntoken  dashboard \n\n\n kube-proxy `kubectl proxy` \n\n```\n$ kubectl proxy --address=IP --disable-filter=true\n```\n\n http://IP:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login\n\n kube-proxy  https://IP:nodePort \n\n![](https://upload-images.jianshu.io/upload_images/1262158-5fefdb4cfa190543.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n token \n\n![](https://upload-images.jianshu.io/upload_images/1262158-4888de572ff9a0c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nDashboard  IngressLet's Encrypt  ssl ssl \n\n\n###  prometheus \n\nprometheus  CNCF  Kubernetes,  Kubernetes prometheus  [kube-prometheus](<https://github.com/coreos/kube-prometheus>)kube-prometheus  prometheus-operatorgrafanakube-state-metrics \n\n```\n$ git clone https://github.com/coreos/kube-prometheus\n\n$ kubectl apply -f manifests/\n```\n\n prometheus  grafana  nodePort \n\n```\n$ kubectl edit svc prometheus-k8s -n monitoring\n\n$ kubectl edit svc grafana -n monitoring\n\n$ kubectl get svc -n monitoring\nNAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\nalertmanager-main       NodePort    10.102.81.118   <none>        9093:8007/TCP       5d1h\nalertmanager-operated   ClusterIP   None            <none>        9093/TCP,6783/TCP   5d1h\ngrafana                 NodePort    10.96.19.82     <none>        3000:8006/TCP       5d1h\nkube-state-metrics      ClusterIP   None            <none>        8443/TCP,9443/TCP   5d1h\nnode-exporter           ClusterIP   None            <none>        9100/TCP            5d1h\nprometheus-adapter      ClusterIP   10.107.103.58   <none>        443/TCP             5d1h\nprometheus-k8s          NodePort    10.110.222.41   <none>        9090:8005/TCP       5d1h\nprometheus-operated     ClusterIP   None            <none>        9090/TCP            5d1h\nprometheus-operator     ClusterIP   None            <none>        8080/TCP            5d1h\n\n$ kubectl get pod -n monitoring\nNAME                                   READY   STATUS    RESTARTS   AGE\nalertmanager-main-0                    2/2     Running   0          4d\nalertmanager-main-1                    2/2     Running   0          4d\nalertmanager-main-2                    2/2     Running   0          4d\ngrafana-9d97dfdc7-qfjts                1/1     Running   0          4d\nkube-state-metrics-74d7dcd7dc-qfz5m    4/4     Running   0          3d11h\nnode-exporter-5cdl2                    2/2     Running   0          4d\nprometheus-adapter-b7d894c9c-dvzzq     1/1     Running   0          4d\nprometheus-k8s-0                       3/3     Running   1          2d2h\nprometheus-k8s-1                       3/3     Running   1          4d\nprometheus-operator-77b8b97459-7qfxj   1/1     Running   0          4d\n```\n\n prometheus  ganfana \n\n![](https://upload-images.jianshu.io/upload_images/1262158-58e439a2407773ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n grafana  web  admin\n\n![](https://upload-images.jianshu.io/upload_images/1262158-b97f2279fadbd3a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\ngrafana  Dashboard grafana  k8s  dashboard \n\n### \n\n kubernetes \n","source":"_posts/k8s_dashboard_prometheus.md","raw":"---\ntitle:  kubernetes \ndate: 2019-04-22 22:43:30\ntags: [\"kube-dashboard\",\"prometheus\"]\ntype: \"kubernetes\"\n\n---\n\n kubernetes  kubernetes  cAdvisorHeapstermetrics-serverkube-state-metricsPrometheus  Dashboard PrometheusGrafana  kube-dashboard  prometheus \n\n> kubernetes v1.12\n\n### kubernetes-dashboard \n\n#### 1 kubernetes-dashboard\n\n```golang\n$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml\n\n$ kubectl get svc -n kube-system | grep kubernetes-dashboard\nkubernetes-dashboard   ClusterIP    10.101.203.44   <none>        443/TCP    2h\n\n$ kubectl get pod -n kube-system | grep kubernetes-dashboard\nkubernetes-dashboard-65c76f6c97-8npsv    1/1     Running       0          2h\n```\n\n> [k8s-system-images](https://github.com/gosoon/k8s-system-images)\n\n#### 2 nodePort  kubernetes-dashboard\n\nnodeport kubernetes-dashboard  clusterIP  kubernetes-dashboard svc  nodePort \n\n```\n$ kubectl edit svc -n kube-system\n\t...\n  spec:\n    clusterIP: 10.101.203.44\n    externalTrafficPolicy: Cluster\n    ports:\n    - nodePort: 8004  //  nodeport \n      port: 443\n      protocol: TCP\n      targetPort: 8443\n    selector:\n      k8s-app: kubernetes-dashboard\n    sessionAffinity: None\n    type: NodePort   //  ClusterIP  NodePort\n    ...\n```\n\nnodePort  30000-32767 apiserver  `--service-node-port-range`  nodePort `--service-node-port-range 8000-9000`\n\n#### 3 kubernetes-dashboard \n\n `kubernetes-dashboard-admin.yaml`\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: dashboard-admin\n  namespace: kube-system\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: dashboard-admin\nsubjects:\n  - kind: ServiceAccount\n    name: dashboard-admin\n    namespace: kube-system\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io\n```\n\n token\n\n```\n$ kubectl apply -f kubernetes-dashboard-admin.yaml\n\n$ kubectl describe secrets `kubectl get secret -n kube-system | grep dashboard-admin | awk '{print $1}'` -n kube-system\n\nName:         dashboard-admin-token-hrhfd\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  kubernetes.io/service-account.name: dashboard-admin\n              kubernetes.io/service-account.uid: 76805bdb-6047-11e9-ba0d-525400c322d9\n\nType:  kubernetes.io/service-account-token\n\nData\n====\nca.crt:     1025 bytes\nnamespace:  11 bytes\ntoken:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4taHJoZmQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNzY4MDViZGItNjA0Ny0xMWU5LWJhMGQtNTI1NDAwYzMyMmQ5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.hJJRyp_O4sGvIULj3BhqidCkkPnD4A2AtnpkXJoEPCALaaQHC8zhCA5-nDNlo2fiEggZ02UZPwiyGxKKFPC57UlKhjTf5zYcMIhELVXlj5FdBmjzCZcCHVFF4tj_rCoOFlZi6fQ3vNCcX8CtLxX_OsH1YXaFVuUmR1gYm97hbyuO382_k3tFIPXFP3QG8zUtc_7QMkeMNEakJZLCvkW8xdlaCuC-GVAMhZl5Kq1MSthuF-8HY7KaXhvqQzfD4DQZrdQ7vf_7NG3rdvhsj8nQ__TTe1W0RjqwkQuxg5YdE4gbAsxwJjkek-N0K9HfnZhkS9WosaUaUe9pZaGZ9akqyQ\n```\n\ntoken  dashboard \n\n\n kube-proxy `kubectl proxy` \n\n```\n$ kubectl proxy --address=IP --disable-filter=true\n```\n\n http://IP:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login\n\n kube-proxy  https://IP:nodePort \n\n![](https://upload-images.jianshu.io/upload_images/1262158-5fefdb4cfa190543.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n token \n\n![](https://upload-images.jianshu.io/upload_images/1262158-4888de572ff9a0c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nDashboard  IngressLet's Encrypt  ssl ssl \n\n\n###  prometheus \n\nprometheus  CNCF  Kubernetes,  Kubernetes prometheus  [kube-prometheus](<https://github.com/coreos/kube-prometheus>)kube-prometheus  prometheus-operatorgrafanakube-state-metrics \n\n```\n$ git clone https://github.com/coreos/kube-prometheus\n\n$ kubectl apply -f manifests/\n```\n\n prometheus  grafana  nodePort \n\n```\n$ kubectl edit svc prometheus-k8s -n monitoring\n\n$ kubectl edit svc grafana -n monitoring\n\n$ kubectl get svc -n monitoring\nNAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE\nalertmanager-main       NodePort    10.102.81.118   <none>        9093:8007/TCP       5d1h\nalertmanager-operated   ClusterIP   None            <none>        9093/TCP,6783/TCP   5d1h\ngrafana                 NodePort    10.96.19.82     <none>        3000:8006/TCP       5d1h\nkube-state-metrics      ClusterIP   None            <none>        8443/TCP,9443/TCP   5d1h\nnode-exporter           ClusterIP   None            <none>        9100/TCP            5d1h\nprometheus-adapter      ClusterIP   10.107.103.58   <none>        443/TCP             5d1h\nprometheus-k8s          NodePort    10.110.222.41   <none>        9090:8005/TCP       5d1h\nprometheus-operated     ClusterIP   None            <none>        9090/TCP            5d1h\nprometheus-operator     ClusterIP   None            <none>        8080/TCP            5d1h\n\n$ kubectl get pod -n monitoring\nNAME                                   READY   STATUS    RESTARTS   AGE\nalertmanager-main-0                    2/2     Running   0          4d\nalertmanager-main-1                    2/2     Running   0          4d\nalertmanager-main-2                    2/2     Running   0          4d\ngrafana-9d97dfdc7-qfjts                1/1     Running   0          4d\nkube-state-metrics-74d7dcd7dc-qfz5m    4/4     Running   0          3d11h\nnode-exporter-5cdl2                    2/2     Running   0          4d\nprometheus-adapter-b7d894c9c-dvzzq     1/1     Running   0          4d\nprometheus-k8s-0                       3/3     Running   1          2d2h\nprometheus-k8s-1                       3/3     Running   1          4d\nprometheus-operator-77b8b97459-7qfxj   1/1     Running   0          4d\n```\n\n prometheus  ganfana \n\n![](https://upload-images.jianshu.io/upload_images/1262158-58e439a2407773ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n grafana  web  admin\n\n![](https://upload-images.jianshu.io/upload_images/1262158-b97f2279fadbd3a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\ngrafana  Dashboard grafana  k8s  dashboard \n\n### \n\n kubernetes \n","slug":"k8s_dashboard_prometheus","published":1,"updated":"2019-04-22T14:44:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjush27wk0000vedvdx535zxu","content":"<p> kubernetes  kubernetes  cAdvisorHeapstermetrics-serverkube-state-metricsPrometheus  Dashboard PrometheusGrafana  kube-dashboard  prometheus </p>\n<blockquote>\n<p>kubernetes v1.12</p>\n</blockquote>\n<h3 id=\"kubernetes-dashboard-\"><a href=\"#kubernetes-dashboard-\" class=\"headerlink\" title=\"kubernetes-dashboard \"></a>kubernetes-dashboard </h3><h4 id=\"1-kubernetes-dashboard\"><a href=\"#1-kubernetes-dashboard\" class=\"headerlink\" title=\"1 kubernetes-dashboard\"></a>1 kubernetes-dashboard</h4><figure class=\"highlight golang\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f https:<span class=\"comment\">//raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get svc -n kube-system | grep kubernetes-dashboard</span><br><span class=\"line\">kubernetes-dashboard   ClusterIP    <span class=\"number\">10.101</span><span class=\"number\">.203</span><span class=\"number\">.44</span>   &lt;none&gt;        <span class=\"number\">443</span>/TCP    <span class=\"number\">2</span>h</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n kube-system | grep kubernetes-dashboard</span><br><span class=\"line\">kubernetes-dashboard<span class=\"number\">-65</span>c76f6c97<span class=\"number\">-8</span>npsv    <span class=\"number\">1</span>/<span class=\"number\">1</span>     Running       <span class=\"number\">0</span>          <span class=\"number\">2</span>h</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><a href=\"https://github.com/gosoon/k8s-system-images\" target=\"_blank\" rel=\"noopener\">k8s-system-images</a></p>\n</blockquote>\n<h4 id=\"2-nodePort--kubernetes-dashboard\"><a href=\"#2-nodePort--kubernetes-dashboard\" class=\"headerlink\" title=\"2 nodePort  kubernetes-dashboard\"></a>2 nodePort  kubernetes-dashboard</h4><p>nodeport kubernetes-dashboard  clusterIP  kubernetes-dashboard svc  nodePort </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl edit svc -n kube-system</span><br><span class=\"line\">\t...</span><br><span class=\"line\">  spec:</span><br><span class=\"line\">    clusterIP: 10.101.203.44</span><br><span class=\"line\">    externalTrafficPolicy: Cluster</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - nodePort: 8004  //  nodeport </span><br><span class=\"line\">      port: 443</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 8443</span><br><span class=\"line\">    selector:</span><br><span class=\"line\">      k8s-app: kubernetes-dashboard</span><br><span class=\"line\">    sessionAffinity: None</span><br><span class=\"line\">    type: NodePort   //  ClusterIP  NodePort</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<p>nodePort  30000-32767 apiserver  <code>--service-node-port-range</code>  nodePort <code>--service-node-port-range 8000-9000</code></p>\n<h4 id=\"3-kubernetes-dashboard-\"><a href=\"#3-kubernetes-dashboard-\" class=\"headerlink\" title=\"3 kubernetes-dashboard \"></a>3 kubernetes-dashboard </h4><p> <code>kubernetes-dashboard-admin.yaml</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-admin</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-admin</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">  - kind: ServiceAccount</span><br><span class=\"line\">    name: dashboard-admin</span><br><span class=\"line\">    namespace: kube-system</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: cluster-admin</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>\n<p> token</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f kubernetes-dashboard-admin.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl describe secrets `kubectl get secret -n kube-system | grep dashboard-admin | awk &apos;&#123;print $1&#125;&apos;` -n kube-system</span><br><span class=\"line\"></span><br><span class=\"line\">Name:         dashboard-admin-token-hrhfd</span><br><span class=\"line\">Namespace:    kube-system</span><br><span class=\"line\">Labels:       &lt;none&gt;</span><br><span class=\"line\">Annotations:  kubernetes.io/service-account.name: dashboard-admin</span><br><span class=\"line\">              kubernetes.io/service-account.uid: 76805bdb-6047-11e9-ba0d-525400c322d9</span><br><span class=\"line\"></span><br><span class=\"line\">Type:  kubernetes.io/service-account-token</span><br><span class=\"line\"></span><br><span class=\"line\">Data</span><br><span class=\"line\">====</span><br><span class=\"line\">ca.crt:     1025 bytes</span><br><span class=\"line\">namespace:  11 bytes</span><br><span class=\"line\">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4taHJoZmQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNzY4MDViZGItNjA0Ny0xMWU5LWJhMGQtNTI1NDAwYzMyMmQ5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.hJJRyp_O4sGvIULj3BhqidCkkPnD4A2AtnpkXJoEPCALaaQHC8zhCA5-nDNlo2fiEggZ02UZPwiyGxKKFPC57UlKhjTf5zYcMIhELVXlj5FdBmjzCZcCHVFF4tj_rCoOFlZi6fQ3vNCcX8CtLxX_OsH1YXaFVuUmR1gYm97hbyuO382_k3tFIPXFP3QG8zUtc_7QMkeMNEakJZLCvkW8xdlaCuC-GVAMhZl5Kq1MSthuF-8HY7KaXhvqQzfD4DQZrdQ7vf_7NG3rdvhsj8nQ__TTe1W0RjqwkQuxg5YdE4gbAsxwJjkek-N0K9HfnZhkS9WosaUaUe9pZaGZ9akqyQ</span><br></pre></td></tr></table></figure>\n<p>token  dashboard </p>\n<p> kube-proxy <code>kubectl proxy</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl proxy --address=IP --disable-filter=true</span><br></pre></td></tr></table></figure>\n<p> <a href=\"http://IP:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login\" target=\"_blank\" rel=\"noopener\">http://IP:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login</a></p>\n<p> kube-proxy  <a href=\"https://IP:nodePort\" target=\"_blank\" rel=\"noopener\">https://IP:nodePort</a> </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-5fefdb4cfa190543.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p> token </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-4888de572ff9a0c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>Dashboard  IngressLets Encrypt  ssl ssl </p>\n<h3 id=\"-prometheus\"><a href=\"#-prometheus\" class=\"headerlink\" title=\" prometheus\"></a> prometheus</h3><p>prometheus  CNCF  Kubernetes,  Kubernetes prometheus  <a href=\"https://github.com/coreos/kube-prometheus\" target=\"_blank\" rel=\"noopener\">kube-prometheus</a>kube-prometheus  prometheus-operatorgrafanakube-state-metrics </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github.com/coreos/kube-prometheus</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl apply -f manifests/</span><br></pre></td></tr></table></figure>\n<p> prometheus  grafana  nodePort </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl edit svc prometheus-k8s -n monitoring</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl edit svc grafana -n monitoring</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get svc -n monitoring</span><br><span class=\"line\">NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">alertmanager-main       NodePort    10.102.81.118   &lt;none&gt;        9093:8007/TCP       5d1h</span><br><span class=\"line\">alertmanager-operated   ClusterIP   None            &lt;none&gt;        9093/TCP,6783/TCP   5d1h</span><br><span class=\"line\">grafana                 NodePort    10.96.19.82     &lt;none&gt;        3000:8006/TCP       5d1h</span><br><span class=\"line\">kube-state-metrics      ClusterIP   None            &lt;none&gt;        8443/TCP,9443/TCP   5d1h</span><br><span class=\"line\">node-exporter           ClusterIP   None            &lt;none&gt;        9100/TCP            5d1h</span><br><span class=\"line\">prometheus-adapter      ClusterIP   10.107.103.58   &lt;none&gt;        443/TCP             5d1h</span><br><span class=\"line\">prometheus-k8s          NodePort    10.110.222.41   &lt;none&gt;        9090:8005/TCP       5d1h</span><br><span class=\"line\">prometheus-operated     ClusterIP   None            &lt;none&gt;        9090/TCP            5d1h</span><br><span class=\"line\">prometheus-operator     ClusterIP   None            &lt;none&gt;        8080/TCP            5d1h</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n monitoring</span><br><span class=\"line\">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">alertmanager-main-0                    2/2     Running   0          4d</span><br><span class=\"line\">alertmanager-main-1                    2/2     Running   0          4d</span><br><span class=\"line\">alertmanager-main-2                    2/2     Running   0          4d</span><br><span class=\"line\">grafana-9d97dfdc7-qfjts                1/1     Running   0          4d</span><br><span class=\"line\">kube-state-metrics-74d7dcd7dc-qfz5m    4/4     Running   0          3d11h</span><br><span class=\"line\">node-exporter-5cdl2                    2/2     Running   0          4d</span><br><span class=\"line\">prometheus-adapter-b7d894c9c-dvzzq     1/1     Running   0          4d</span><br><span class=\"line\">prometheus-k8s-0                       3/3     Running   1          2d2h</span><br><span class=\"line\">prometheus-k8s-1                       3/3     Running   1          4d</span><br><span class=\"line\">prometheus-operator-77b8b97459-7qfxj   1/1     Running   0          4d</span><br></pre></td></tr></table></figure>\n<p> prometheus  ganfana </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-58e439a2407773ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p> grafana  web  admin</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-b97f2279fadbd3a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>grafana  Dashboard grafana  k8s  dashboard </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> kubernetes </p>\n","site":{"data":{}},"excerpt":"","more":"<p> kubernetes  kubernetes  cAdvisorHeapstermetrics-serverkube-state-metricsPrometheus  Dashboard PrometheusGrafana  kube-dashboard  prometheus </p>\n<blockquote>\n<p>kubernetes v1.12</p>\n</blockquote>\n<h3 id=\"kubernetes-dashboard-\"><a href=\"#kubernetes-dashboard-\" class=\"headerlink\" title=\"kubernetes-dashboard \"></a>kubernetes-dashboard </h3><h4 id=\"1-kubernetes-dashboard\"><a href=\"#1-kubernetes-dashboard\" class=\"headerlink\" title=\"1 kubernetes-dashboard\"></a>1 kubernetes-dashboard</h4><figure class=\"highlight golang\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f https:<span class=\"comment\">//raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span></span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get svc -n kube-system | grep kubernetes-dashboard</span><br><span class=\"line\">kubernetes-dashboard   ClusterIP    <span class=\"number\">10.101</span><span class=\"number\">.203</span><span class=\"number\">.44</span>   &lt;none&gt;        <span class=\"number\">443</span>/TCP    <span class=\"number\">2</span>h</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n kube-system | grep kubernetes-dashboard</span><br><span class=\"line\">kubernetes-dashboard<span class=\"number\">-65</span>c76f6c97<span class=\"number\">-8</span>npsv    <span class=\"number\">1</span>/<span class=\"number\">1</span>     Running       <span class=\"number\">0</span>          <span class=\"number\">2</span>h</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><a href=\"https://github.com/gosoon/k8s-system-images\" target=\"_blank\" rel=\"noopener\">k8s-system-images</a></p>\n</blockquote>\n<h4 id=\"2-nodePort--kubernetes-dashboard\"><a href=\"#2-nodePort--kubernetes-dashboard\" class=\"headerlink\" title=\"2 nodePort  kubernetes-dashboard\"></a>2 nodePort  kubernetes-dashboard</h4><p>nodeport kubernetes-dashboard  clusterIP  kubernetes-dashboard svc  nodePort </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl edit svc -n kube-system</span><br><span class=\"line\">\t...</span><br><span class=\"line\">  spec:</span><br><span class=\"line\">    clusterIP: 10.101.203.44</span><br><span class=\"line\">    externalTrafficPolicy: Cluster</span><br><span class=\"line\">    ports:</span><br><span class=\"line\">    - nodePort: 8004  //  nodeport </span><br><span class=\"line\">      port: 443</span><br><span class=\"line\">      protocol: TCP</span><br><span class=\"line\">      targetPort: 8443</span><br><span class=\"line\">    selector:</span><br><span class=\"line\">      k8s-app: kubernetes-dashboard</span><br><span class=\"line\">    sessionAffinity: None</span><br><span class=\"line\">    type: NodePort   //  ClusterIP  NodePort</span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n<p>nodePort  30000-32767 apiserver  <code>--service-node-port-range</code>  nodePort <code>--service-node-port-range 8000-9000</code></p>\n<h4 id=\"3-kubernetes-dashboard-\"><a href=\"#3-kubernetes-dashboard-\" class=\"headerlink\" title=\"3 kubernetes-dashboard \"></a>3 kubernetes-dashboard </h4><p> <code>kubernetes-dashboard-admin.yaml</code></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-admin</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">---</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: dashboard-admin</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">  - kind: ServiceAccount</span><br><span class=\"line\">    name: dashboard-admin</span><br><span class=\"line\">    namespace: kube-system</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: cluster-admin</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>\n<p> token</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl apply -f kubernetes-dashboard-admin.yaml</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl describe secrets `kubectl get secret -n kube-system | grep dashboard-admin | awk &apos;&#123;print $1&#125;&apos;` -n kube-system</span><br><span class=\"line\"></span><br><span class=\"line\">Name:         dashboard-admin-token-hrhfd</span><br><span class=\"line\">Namespace:    kube-system</span><br><span class=\"line\">Labels:       &lt;none&gt;</span><br><span class=\"line\">Annotations:  kubernetes.io/service-account.name: dashboard-admin</span><br><span class=\"line\">              kubernetes.io/service-account.uid: 76805bdb-6047-11e9-ba0d-525400c322d9</span><br><span class=\"line\"></span><br><span class=\"line\">Type:  kubernetes.io/service-account-token</span><br><span class=\"line\"></span><br><span class=\"line\">Data</span><br><span class=\"line\">====</span><br><span class=\"line\">ca.crt:     1025 bytes</span><br><span class=\"line\">namespace:  11 bytes</span><br><span class=\"line\">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4taHJoZmQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiNzY4MDViZGItNjA0Ny0xMWU5LWJhMGQtNTI1NDAwYzMyMmQ5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.hJJRyp_O4sGvIULj3BhqidCkkPnD4A2AtnpkXJoEPCALaaQHC8zhCA5-nDNlo2fiEggZ02UZPwiyGxKKFPC57UlKhjTf5zYcMIhELVXlj5FdBmjzCZcCHVFF4tj_rCoOFlZi6fQ3vNCcX8CtLxX_OsH1YXaFVuUmR1gYm97hbyuO382_k3tFIPXFP3QG8zUtc_7QMkeMNEakJZLCvkW8xdlaCuC-GVAMhZl5Kq1MSthuF-8HY7KaXhvqQzfD4DQZrdQ7vf_7NG3rdvhsj8nQ__TTe1W0RjqwkQuxg5YdE4gbAsxwJjkek-N0K9HfnZhkS9WosaUaUe9pZaGZ9akqyQ</span><br></pre></td></tr></table></figure>\n<p>token  dashboard </p>\n<p> kube-proxy <code>kubectl proxy</code> </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl proxy --address=IP --disable-filter=true</span><br></pre></td></tr></table></figure>\n<p> <a href=\"http://IP:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login\" target=\"_blank\" rel=\"noopener\">http://IP:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login</a></p>\n<p> kube-proxy  <a href=\"https://IP:nodePort\" target=\"_blank\" rel=\"noopener\">https://IP:nodePort</a> </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-5fefdb4cfa190543.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p> token </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-4888de572ff9a0c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>Dashboard  IngressLets Encrypt  ssl ssl </p>\n<h3 id=\"-prometheus\"><a href=\"#-prometheus\" class=\"headerlink\" title=\" prometheus\"></a> prometheus</h3><p>prometheus  CNCF  Kubernetes,  Kubernetes prometheus  <a href=\"https://github.com/coreos/kube-prometheus\" target=\"_blank\" rel=\"noopener\">kube-prometheus</a>kube-prometheus  prometheus-operatorgrafanakube-state-metrics </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git clone https://github.com/coreos/kube-prometheus</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl apply -f manifests/</span><br></pre></td></tr></table></figure>\n<p> prometheus  grafana  nodePort </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ kubectl edit svc prometheus-k8s -n monitoring</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl edit svc grafana -n monitoring</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get svc -n monitoring</span><br><span class=\"line\">NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)             AGE</span><br><span class=\"line\">alertmanager-main       NodePort    10.102.81.118   &lt;none&gt;        9093:8007/TCP       5d1h</span><br><span class=\"line\">alertmanager-operated   ClusterIP   None            &lt;none&gt;        9093/TCP,6783/TCP   5d1h</span><br><span class=\"line\">grafana                 NodePort    10.96.19.82     &lt;none&gt;        3000:8006/TCP       5d1h</span><br><span class=\"line\">kube-state-metrics      ClusterIP   None            &lt;none&gt;        8443/TCP,9443/TCP   5d1h</span><br><span class=\"line\">node-exporter           ClusterIP   None            &lt;none&gt;        9100/TCP            5d1h</span><br><span class=\"line\">prometheus-adapter      ClusterIP   10.107.103.58   &lt;none&gt;        443/TCP             5d1h</span><br><span class=\"line\">prometheus-k8s          NodePort    10.110.222.41   &lt;none&gt;        9090:8005/TCP       5d1h</span><br><span class=\"line\">prometheus-operated     ClusterIP   None            &lt;none&gt;        9090/TCP            5d1h</span><br><span class=\"line\">prometheus-operator     ClusterIP   None            &lt;none&gt;        8080/TCP            5d1h</span><br><span class=\"line\"></span><br><span class=\"line\">$ kubectl get pod -n monitoring</span><br><span class=\"line\">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class=\"line\">alertmanager-main-0                    2/2     Running   0          4d</span><br><span class=\"line\">alertmanager-main-1                    2/2     Running   0          4d</span><br><span class=\"line\">alertmanager-main-2                    2/2     Running   0          4d</span><br><span class=\"line\">grafana-9d97dfdc7-qfjts                1/1     Running   0          4d</span><br><span class=\"line\">kube-state-metrics-74d7dcd7dc-qfz5m    4/4     Running   0          3d11h</span><br><span class=\"line\">node-exporter-5cdl2                    2/2     Running   0          4d</span><br><span class=\"line\">prometheus-adapter-b7d894c9c-dvzzq     1/1     Running   0          4d</span><br><span class=\"line\">prometheus-k8s-0                       3/3     Running   1          2d2h</span><br><span class=\"line\">prometheus-k8s-1                       3/3     Running   1          4d</span><br><span class=\"line\">prometheus-operator-77b8b97459-7qfxj   1/1     Running   0          4d</span><br></pre></td></tr></table></figure>\n<p> prometheus  ganfana </p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-58e439a2407773ca.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p> grafana  web  admin</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/1262158-b97f2279fadbd3a1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>grafana  Dashboard grafana  k8s  dashboard </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> kubernetes </p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjugyyss60004tadv88lq8wq6","tag_id":"cjugyyss90007tadvs0n35rba","_id":"cjugyyssj000etadvoneit0dv"},{"post_id":"cjugyyss60004tadv88lq8wq6","tag_id":"cjugyyssh000btadvxancce66","_id":"cjugyyssl000ftadvmxcey9k1"},{"post_id":"cjugyyss60004tadv88lq8wq6","tag_id":"cjugyyssj000ctadvqbq3p6hh","_id":"cjugyyssl000htadvuzfwdv0e"},{"post_id":"cjugyyss80006tadvflk99uum","tag_id":"cjugyyssj000dtadvrz12jpsj","_id":"cjugyyssm000itadv6dtkz4kp"},{"post_id":"cjugyyssb0008tadv100lgpq4","tag_id":"cjugyyssl000gtadvr464brcd","_id":"cjugyyssm000ktadvrafatdy2"},{"post_id":"cjugyysse0009tadv3ryu0o1f","tag_id":"cjugyyssm000jtadvru5zxb9v","_id":"cjugyyssn000ltadvn21qzaj2"},{"post_id":"cjugyysyi000ntadv90s65k6j","tag_id":"cjugyysyl000ptadvx3jtqb6g","_id":"cjugyysyo000ttadvw2wy5qnb"},{"post_id":"cjugyysyi000ntadv90s65k6j","tag_id":"cjugyysyn000rtadvezfh8yjo","_id":"cjugyysyo000utadv2c4r1nss"},{"post_id":"cjugyysyk000otadvor4e2mrs","tag_id":"cjugyysyn000stadvllzc88rh","_id":"cjugyysyo000wtadv7b3pcyfk"},{"post_id":"cjugyysyl000qtadv1qhhfbc9","tag_id":"cjugyysyo000vtadvje0frfjn","_id":"cjugyysyp000xtadvnqspauk1"},{"post_id":"cjugyyt050011tadv44ecob0h","tag_id":"cjugyysyo000vtadvje0frfjn","_id":"cjugyyt070013tadvwxuogonu"},{"post_id":"cjugyyt060012tadvb4jdkh8m","tag_id":"cjugyysyo000vtadvje0frfjn","_id":"cjugyyt090016tadviyuaythb"},{"post_id":"cjugyyt02000ytadvh7hc5sqh","tag_id":"cjugyyt050010tadvvg2b23dz","_id":"cjugyyt090018tadv151iwqms"},{"post_id":"cjugyyt02000ytadvh7hc5sqh","tag_id":"cjugyyt080015tadvqnn090wm","_id":"cjugyyt090019tadvdejcq8ry"},{"post_id":"cjugyyt04000ztadvl5mm7rse","tag_id":"cjugyyt090017tadvu823llh3","_id":"cjugyyt09001atadvtqungfqw"},{"post_id":"cjugyyt04000ztadvl5mm7rse","tag_id":"cjugyysyo000vtadvje0frfjn","_id":"cjugyyt0a001btadvil9kx7d4"},{"post_id":"cjush27wk0000vedvdx535zxu","tag_id":"cjush27ws0001vedvetbl7d12","_id":"cjush27x20003vedvc3iqt98h"},{"post_id":"cjush27wk0000vedvdx535zxu","tag_id":"cjush27x10002vedv7mxm1ecq","_id":"cjush27x20004vedvzhm3ff0e"}],"Tag":[{"name":"crontab","_id":"cjugyyss90007tadvs0n35rba"},{"name":"wait","_id":"cjugyyssh000btadvxancce66"},{"name":"k8s","_id":"cjugyyssj000ctadvqbq3p6hh"},{"name":"metrics-server","_id":"cjugyyssj000dtadvrz12jpsj"},{"name":"kubernetes v1.12","_id":"cjugyyssl000gtadvr464brcd"},{"name":"kubeconfig","_id":"cjugyyssm000jtadvru5zxb9v"},{"name":"audit","_id":"cjugyysyl000ptadvx3jtqb6g"},{"name":"log","_id":"cjugyysyn000rtadvezfh8yjo"},{"name":"kubeadm","_id":"cjugyysyn000stadvllzc88rh"},{"name":"kubelet","_id":"cjugyysyo000vtadvje0frfjn"},{"name":"leader-election","_id":"cjugyyt050010tadvvg2b23dz"},{"name":"component","_id":"cjugyyt080015tadvqnn090wm"},{"name":"events","_id":"cjugyyt090017tadvu823llh3"},{"name":"kube-dashboard","_id":"cjush27ws0001vedvetbl7d12"},{"name":"prometheus","_id":"cjush27x10002vedv7mxm1ecq"}]}}